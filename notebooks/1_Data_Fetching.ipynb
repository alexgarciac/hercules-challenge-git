{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data fetching and cleaning\n",
    "In this notebook we are going to fetch and perform an initial exploration of the dataset for the Git track of the HÃ©rcules Challenge. This dataset consists of 50 GitHub repositories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "As always, we will begin the notebook by starting the logging system and importing some constants defined in the \"\\_\\_init\\_\\_.py\" file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also define an auxiliary function to print the empty columns of the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_empty_cols(df):\n",
    "    for col in df.columns:\n",
    "        print(col)\n",
    "        print('-' * len(col))\n",
    "        res = df[df[col] == ''].index\n",
    "        print(f\"{len(res)} articles have no value for column {col}\")\n",
    "        print(res)\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will impor the bokeh library to show the charts in the notebook, and we will import the BokehHistogram class from the _herc\\_common_ library to show our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/.envs/edma/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from herc_common import BokehHistogram\n",
    "\n",
    "hist = BokehHistogram(color_fill=\"mediumslateblue\", color_hover=\"slateblue\", bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the repository URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The URL for every repository of the Git dataset is stored in the '_data/repo\\_urls.txt_' file. First of all, we will be loading all the urls from that file into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REPO_URLS_FILE = 'repo_urls.txt'\n",
    "\n",
    "with open(os.path.join(DATA_DIR, REPO_URLS_FILE), 'r') as f:\n",
    "    repo_urls = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "len(repo_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/cmungall/LIRICAL/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_urls[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the URLs of every repository have been saved, we can start calling the [GitHub API](https://developer.github.com/v3/) to obtain information about each repo. Since the API has a limit of 50 requests per hour for non-authorized requests, and we will be making about 200 requests to fetch all the information, we will need to make use of a personal token to make calls to the API. More information about what a personal token is, and how to create one, can be accessed through the [following link](https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token). In the next cell we will be asking for the token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "\n",
    "try:\n",
    "    from secret import GITHUB_TOKEN\n",
    "except ModuleNotFoundError:\n",
    "    GITHUB_TOKEN = getpass.getpass(\"Introduce your personal access token to acces the GitHub API: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now import a series of classes and functions that will be used to fetch information about a given repo and convert it to an instance of the _GitHubRepoData_ class. More information about these functions and classes can be accessed at the _src_ package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import GitHubIssue, GitHubRepoData, parse_repo_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will be creating a list of GitHubRepoData instances with information about every repository from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing repository: https://github.com/mikel-egana-aranguren/FAIRifier:   8%|â         | 4/50 [00:31<06:38,  8.67s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mikel-egana-aranguren-FAIRifier-d69d6a4/extensions/fairifier-rdf-extension/scripts/externals/angular.min.js\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing repository: https://github.com/mikel-egana-aranguren/elda:  10%|â         | 5/50 [02:08<26:29, 35.33s/it]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mikel-egana-aranguren-elda-e9bd9d3/elda-assets/src/main/webapp/openlayers/proj4js-combined.js\n",
      "mikel-egana-aranguren-elda-e9bd9d3/elda-assets/src/main/webapp/velocity/js/vendor/proj4js-combined.js\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing repository: https://github.com/fanavarro/DnaCompress:  24%|âââ       | 12/50 [03:58<07:49, 12.34s/it]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fanavarro DnaCompress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing repository: https://github.com/mbdebian/vimrc:  30%|âââ       | 15/50 [05:03<10:36, 18.20s/it]                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mbdebian vimrc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing repository: https://github.com/pjotrp/genenetwork2:  34%|ââââ      | 17/50 [05:12<06:09, 11.20s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pjotrp-genenetwork2-86d885f/wqflask/wqflask/static/new/javascript/box.js\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing repository: https://github.com/micheldumontier/php-lib:  68%|âââââââ   | 34/50 [17:29<06:33, 24.56s/it]                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micheldumontier php-lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing repository: https://github.com/pauldevos/Basketball_Analytics: 100%|ââââââââââ| 50/50 [23:19<00:00, 27.99s/it]         \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "git_dataset = []\n",
    "pbar = tqdm(repo_urls)\n",
    "for url in pbar:\n",
    "    pbar.set_description(f\"Processing repository: {url}\")\n",
    "    git_dataset.append(parse_repo_url(url, GITHUB_TOKEN))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The instances created before provide a _to\\_dict_ method that can be used to convert the class to a Python dict. This dict can be used to easily create a pandas DataFrame. This DataFrame will be used from now on to explore and interact with the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gh_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>owner_name</th>\n",
       "      <th>languages</th>\n",
       "      <th>readme_text</th>\n",
       "      <th>issues_text</th>\n",
       "      <th>commits_text</th>\n",
       "      <th>filenames</th>\n",
       "      <th>comments_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216602979</td>\n",
       "      <td>LIRICAL</td>\n",
       "      <td>LIkelihood Ratio Interpretation of Clinical Ab...</td>\n",
       "      <td>cmungall</td>\n",
       "      <td>{'Java': 492423, 'FreeMarker': 13149, 'Python'...</td>\n",
       "      <td>LIRICAL.  LIkelihood Ratio Interpretation of C...</td>\n",
       "      <td></td>\n",
       "      <td>Merge pull request #442 from TheJacksonLaborat...</td>\n",
       "      <td>\\nCHANGELOG\\nREADME\\nhoxc13-output\\nlirical-to...</td>\n",
       "      <td>note that the Jannovar dependency does not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199330464</td>\n",
       "      <td>wikidata_ontomatcher</td>\n",
       "      <td>Matches ontology classes against wikidata</td>\n",
       "      <td>cmungall</td>\n",
       "      <td>{'Prolog': 14691, 'Makefile': 1472, 'Dockerfil...</td>\n",
       "      <td>Match an ontology to Wikidata. This applicatio...</td>\n",
       "      <td>Will help with #1 and with https://github.com/...</td>\n",
       "      <td>Adding skos:altLabel\\n\\nhttps://github.com/cmu...</td>\n",
       "      <td>\\nREADME\\ninstall\\npack\\nwikidata ontomatcher\\...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253207181</td>\n",
       "      <td>ro-crate-ruby</td>\n",
       "      <td>A Ruby gem for creating, manipulating and read...</td>\n",
       "      <td>markwilkinson</td>\n",
       "      <td>{'Ruby': 52724, 'HTML': 1319}</td>\n",
       "      <td>ro-crate-ruby. This is a WIP gem for creating,...</td>\n",
       "      <td></td>\n",
       "      <td>Update LICENSE\\nBump version\\nTidy up and chec...</td>\n",
       "      <td>\\n.travis\\nGemfile\\nREADME\\nROCrate\\nContact P...</td>\n",
       "      <td>*\\n * Expands the tree to the target element a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212556220</td>\n",
       "      <td>Misc_Training_scripts</td>\n",
       "      <td>A place for me to keep various miscellanelous ...</td>\n",
       "      <td>markwilkinson</td>\n",
       "      <td>{'Shell': 15815, 'Ruby': 9445}</td>\n",
       "      <td>Misc_Training_scripts. A place for me to keep ...</td>\n",
       "      <td></td>\n",
       "      <td>added new cool 3-federated query\\nfinished edi...</td>\n",
       "      <td>README\\nSpecies Abundance Pub2015\\nSpecies Inf...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155879756</td>\n",
       "      <td>FAIRifier</td>\n",
       "      <td>A tool to make data FAIR</td>\n",
       "      <td>mikel-egana-aranguren</td>\n",
       "      <td>{'Java': 3514431, 'JavaScript': 967765, 'HTML'...</td>\n",
       "      <td>Dependencies: Java 8. Apache Ant. Building. in...</td>\n",
       "      <td></td>\n",
       "      <td>Merge pull request #16 from Shamanou/developme...</td>\n",
       "      <td>\\norg.eclipse.core.resources\\norg.eclipse.jdt....</td>\n",
       "      <td>*\\n * Main class for Refine server application...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gh_id                   name  \\\n",
       "0  216602979                LIRICAL   \n",
       "1  199330464   wikidata_ontomatcher   \n",
       "2  253207181          ro-crate-ruby   \n",
       "3  212556220  Misc_Training_scripts   \n",
       "4  155879756              FAIRifier   \n",
       "\n",
       "                                         description             owner_name  \\\n",
       "0  LIkelihood Ratio Interpretation of Clinical Ab...               cmungall   \n",
       "1          Matches ontology classes against wikidata               cmungall   \n",
       "2  A Ruby gem for creating, manipulating and read...          markwilkinson   \n",
       "3  A place for me to keep various miscellanelous ...          markwilkinson   \n",
       "4                           A tool to make data FAIR  mikel-egana-aranguren   \n",
       "\n",
       "                                           languages  \\\n",
       "0  {'Java': 492423, 'FreeMarker': 13149, 'Python'...   \n",
       "1  {'Prolog': 14691, 'Makefile': 1472, 'Dockerfil...   \n",
       "2                      {'Ruby': 52724, 'HTML': 1319}   \n",
       "3                     {'Shell': 15815, 'Ruby': 9445}   \n",
       "4  {'Java': 3514431, 'JavaScript': 967765, 'HTML'...   \n",
       "\n",
       "                                         readme_text  \\\n",
       "0  LIRICAL.  LIkelihood Ratio Interpretation of C...   \n",
       "1  Match an ontology to Wikidata. This applicatio...   \n",
       "2  ro-crate-ruby. This is a WIP gem for creating,...   \n",
       "3  Misc_Training_scripts. A place for me to keep ...   \n",
       "4  Dependencies: Java 8. Apache Ant. Building. in...   \n",
       "\n",
       "                                         issues_text  \\\n",
       "0                                                      \n",
       "1  Will help with #1 and with https://github.com/...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                        commits_text  \\\n",
       "0  Merge pull request #442 from TheJacksonLaborat...   \n",
       "1  Adding skos:altLabel\\n\\nhttps://github.com/cmu...   \n",
       "2  Update LICENSE\\nBump version\\nTidy up and chec...   \n",
       "3  added new cool 3-federated query\\nfinished edi...   \n",
       "4  Merge pull request #16 from Shamanou/developme...   \n",
       "\n",
       "                                           filenames  \\\n",
       "0  \\nCHANGELOG\\nREADME\\nhoxc13-output\\nlirical-to...   \n",
       "1  \\nREADME\\ninstall\\npack\\nwikidata ontomatcher\\...   \n",
       "2  \\n.travis\\nGemfile\\nREADME\\nROCrate\\nContact P...   \n",
       "3  README\\nSpecies Abundance Pub2015\\nSpecies Inf...   \n",
       "4  \\norg.eclipse.core.resources\\norg.eclipse.jdt....   \n",
       "\n",
       "                                       comments_text  \n",
       "0      note that the Jannovar dependency does not...  \n",
       "1                                                     \n",
       "2  *\\n * Expands the tree to the target element a...  \n",
       "3                                                     \n",
       "4  *\\n * Main class for Refine server application...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([repo.to_dict() for repo in git_dataset])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will be taking an initial look to the values from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>owner_name</th>\n",
       "      <th>languages</th>\n",
       "      <th>readme_text</th>\n",
       "      <th>issues_text</th>\n",
       "      <th>commits_text</th>\n",
       "      <th>filenames</th>\n",
       "      <th>comments_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>bio2rdf-scripts</td>\n",
       "      <td>A PHP utility library</td>\n",
       "      <td>mr-c</td>\n",
       "      <td>{'C#': 15985, 'CSS': 649, 'JavaScript': 34}</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Fixing sorting in usecase\\nFixing warnings in ...</td>\n",
       "      <td>\\nCHANGELOG\\nREADME\\nhoxc13-output\\nlirical-to...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name            description owner_name  \\\n",
       "count                50                     43         50   \n",
       "unique               50                     43         27   \n",
       "top     bio2rdf-scripts  A PHP utility library       mr-c   \n",
       "freq                  1                      1          2   \n",
       "\n",
       "                                          languages readme_text issues_text  \\\n",
       "count                                            50          50          50   \n",
       "unique                                           50          49           6   \n",
       "top     {'C#': 15985, 'CSS': 649, 'JavaScript': 34}                           \n",
       "freq                                              1           2          45   \n",
       "\n",
       "                                             commits_text  \\\n",
       "count                                                  50   \n",
       "unique                                                 50   \n",
       "top     Fixing sorting in usecase\\nFixing warnings in ...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                filenames comments_text  \n",
       "count                                                  50            50  \n",
       "unique                                                 50            27  \n",
       "top     \\nCHANGELOG\\nREADME\\nhoxc13-output\\nlirical-to...                \n",
       "freq                                                    1            24  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, df.columns != 'gh_id'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, altough all the repository names are unique, the other columns have some repeated values. Those repeated values could be empty or null values, so we are going to check if that is the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gh_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>owner_name</th>\n",
       "      <th>languages</th>\n",
       "      <th>readme_text</th>\n",
       "      <th>issues_text</th>\n",
       "      <th>commits_text</th>\n",
       "      <th>filenames</th>\n",
       "      <th>comments_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>57412597</td>\n",
       "      <td>hemodonacion</td>\n",
       "      <td>None</td>\n",
       "      <td>fanavarro</td>\n",
       "      <td>{'Perl': 97370, 'R': 36211}</td>\n",
       "      <td>Lost in Translation. Structure. This repositor...</td>\n",
       "      <td></td>\n",
       "      <td>delete files\\nnew execution\\nReadme updated\\nr...</td>\n",
       "      <td>\\nREADME\\n11 12 2016\\n19 04 2018\\n26 04 2017\\n...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>161862375</td>\n",
       "      <td>biohack18</td>\n",
       "      <td>None</td>\n",
       "      <td>leechuck</td>\n",
       "      <td>{'Groovy': 14573}</td>\n",
       "      <td>biohack18.</td>\n",
       "      <td></td>\n",
       "      <td>initial commit\\nInitial commit</td>\n",
       "      <td>Clean OPA\\nFLOPOTsne\\nMake Plants Plot\\nMake P...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>171842501</td>\n",
       "      <td>biosample_jsonld</td>\n",
       "      <td>None</td>\n",
       "      <td>inutano</td>\n",
       "      <td>{'Ruby': 9183, 'Shell': 3171, 'Dockerfile': 226}</td>\n",
       "      <td>BioSample records in JSON-LD. BioSample is a d...</td>\n",
       "      <td></td>\n",
       "      <td>mkdir\\nremove postgres lib\\nremove comment whi...</td>\n",
       "      <td>\\nGemfile\\nREADME\\nbiosample ld\\ndocker-compos...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>151696606</td>\n",
       "      <td>JavaTermiteStarter</td>\n",
       "      <td>None</td>\n",
       "      <td>SciBiteLabs</td>\n",
       "      <td>{'Java': 16959}</td>\n",
       "      <td>JavaTermiteStarter. Set of basic code to get y...</td>\n",
       "      <td></td>\n",
       "      <td>Create README.md\\nRefactoring\\nRefactoring\\nMe...</td>\n",
       "      <td>\\nREADME\\nasm-1.0-RC3\\ncommons-codec-1.8\\ncomm...</td>\n",
       "      <td>*\\n * This class was created by simon on 03/09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>42526998</td>\n",
       "      <td>pythonontologysearch</td>\n",
       "      <td>None</td>\n",
       "      <td>jamesmalone</td>\n",
       "      <td>{'JavaScript': 194124, 'Python': 5748, 'HTML':...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>remove test message\\nChange call to ontology_i...</td>\n",
       "      <td>\\nmisc\\nmodules\\nontologysearch\\nvcs\\nmanage\\n...</td>\n",
       "      <td>****\\n****\\n****\\n****\\n****\\n****\\n****\\n****...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>238953196</td>\n",
       "      <td>my-react-form</td>\n",
       "      <td>None</td>\n",
       "      <td>twhetzel</td>\n",
       "      <td>{'JavaScript': 35896, 'CSS': 6855, 'HTML': 1271}</td>\n",
       "      <td>React Form Demos. Description. Demo project to...</td>\n",
       "      <td></td>\n",
       "      <td>remove file App.css\\nadd more example forms\\na...</td>\n",
       "      <td>\\nREADME\\npackage-lock\\npackage\\nfavicon\\ninde...</td>\n",
       "      <td>eslint-disable jsx-a11y/heading-has-content \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>157134523</td>\n",
       "      <td>python-ecology-lesson-es-1</td>\n",
       "      <td>None</td>\n",
       "      <td>agbeltran</td>\n",
       "      <td>{'Jupyter Notebook': 4579723, 'HTML': 60649, '...</td>\n",
       "      <td>Canal de Slack en espaÃ±ol LecciÃ³n de Data Carp...</td>\n",
       "      <td></td>\n",
       "      <td>Update fechas-progreso.md\\nMerge pull request ...</td>\n",
       "      <td>\\nISSUE TEMPLATE\\nPULL REQUEST TEMPLATE\\n.trav...</td>\n",
       "      <td>[if lt IE 9]&gt;\\n  &lt;script src=\"http://html5shim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gh_id                        name description   owner_name  \\\n",
       "11   57412597                hemodonacion        None    fanavarro   \n",
       "23  161862375                   biohack18        None     leechuck   \n",
       "24  171842501            biosample_jsonld        None      inutano   \n",
       "29  151696606          JavaTermiteStarter        None  SciBiteLabs   \n",
       "39   42526998        pythonontologysearch        None  jamesmalone   \n",
       "40  238953196               my-react-form        None     twhetzel   \n",
       "41  157134523  python-ecology-lesson-es-1        None    agbeltran   \n",
       "\n",
       "                                            languages  \\\n",
       "11                        {'Perl': 97370, 'R': 36211}   \n",
       "23                                  {'Groovy': 14573}   \n",
       "24   {'Ruby': 9183, 'Shell': 3171, 'Dockerfile': 226}   \n",
       "29                                    {'Java': 16959}   \n",
       "39  {'JavaScript': 194124, 'Python': 5748, 'HTML':...   \n",
       "40   {'JavaScript': 35896, 'CSS': 6855, 'HTML': 1271}   \n",
       "41  {'Jupyter Notebook': 4579723, 'HTML': 60649, '...   \n",
       "\n",
       "                                          readme_text issues_text  \\\n",
       "11  Lost in Translation. Structure. This repositor...               \n",
       "23                                         biohack18.               \n",
       "24  BioSample records in JSON-LD. BioSample is a d...               \n",
       "29  JavaTermiteStarter. Set of basic code to get y...               \n",
       "39                                                                  \n",
       "40  React Form Demos. Description. Demo project to...               \n",
       "41  Canal de Slack en espaÃ±ol LecciÃ³n de Data Carp...               \n",
       "\n",
       "                                         commits_text  \\\n",
       "11  delete files\\nnew execution\\nReadme updated\\nr...   \n",
       "23                     initial commit\\nInitial commit   \n",
       "24  mkdir\\nremove postgres lib\\nremove comment whi...   \n",
       "29  Create README.md\\nRefactoring\\nRefactoring\\nMe...   \n",
       "39  remove test message\\nChange call to ontology_i...   \n",
       "40  remove file App.css\\nadd more example forms\\na...   \n",
       "41  Update fechas-progreso.md\\nMerge pull request ...   \n",
       "\n",
       "                                            filenames  \\\n",
       "11  \\nREADME\\n11 12 2016\\n19 04 2018\\n26 04 2017\\n...   \n",
       "23  Clean OPA\\nFLOPOTsne\\nMake Plants Plot\\nMake P...   \n",
       "24  \\nGemfile\\nREADME\\nbiosample ld\\ndocker-compos...   \n",
       "29  \\nREADME\\nasm-1.0-RC3\\ncommons-codec-1.8\\ncomm...   \n",
       "39  \\nmisc\\nmodules\\nontologysearch\\nvcs\\nmanage\\n...   \n",
       "40  \\nREADME\\npackage-lock\\npackage\\nfavicon\\ninde...   \n",
       "41  \\nISSUE TEMPLATE\\nPULL REQUEST TEMPLATE\\n.trav...   \n",
       "\n",
       "                                        comments_text  \n",
       "11                                                     \n",
       "23                                                     \n",
       "24                                                     \n",
       "29  *\\n * This class was created by simon on 03/09...  \n",
       "39  ****\\n****\\n****\\n****\\n****\\n****\\n****\\n****...  \n",
       "40   eslint-disable jsx-a11y/heading-has-content \\...  \n",
       "41  [if lt IE 9]>\\n  <script src=\"http://html5shim...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    note that the Jannovar dependency does not need to be explicitly entered here, we are getting it\\n       from the Exomiser dependency. \\n https://mvnrepository.com/artifact/org.tukaani/xz\\n          XZ data compression in pure Java. We just use this (indirectly) in some test cases.\\n         \\n https://mvnrepository.com/artifact/org.codehaus.mojo/versions-maven-plugin\\n        Unplug to check version of plugins-\\n        mvn versions:display-dependency-updates\\n        <dependency>\\n            <groupId>org.codehaus.mojo</groupId>\\n            <artifactId>versions-maven-plugin</artifactId>\\n            <version>2.7</version>\\n            <exclusions>\\n                <exclusion>\\n                    <groupId>org.apache.maven.doxia</groupId>\\n                    <artifactId>doxia-site-renderer</artifactId>\\n                </exclusion>\\n                <exclusion>\\n                    <groupId>org.apache.maven.doxia</groupId>\\n                    <artifactId>doxia-sink-api</artifactId>\\n                </exclusion>\\n                <exclusion>\\n                    <groupId>org.apache.maven</groupId>\\n                    <artifactId>maven-plugin-api</artifactId>\\n                </exclusion>\\n                <exclusion>\\n                    <groupId>org.apache.maven</groupId>\\n                    <artifactId>maven-core</artifactId>\\n                </exclusion>\\n                <exclusion>\\n                    <groupId>commons-io</groupId>\\n                    <artifactId>commons-io</artifactId>\\n                </exclusion>\\n                <exclusion>\\n                    <groupId>org.apache.maven.wagon</groupId>\\n                    <artifactId>wagon-provider-api</artifactId>\\n                </exclusion>\\n            </exclusions>\\n        </dependency> \\n\\n             <plugin>\\n                 <groupId>org.apache.maven.plugins</groupId>\\n                 <artifactId>maven-enforcer-plugin</artifactId>\\n                 <version>3.0.0-M2</version>\\n                 <executions>\\n                     <execution>\\n                         <id>enforce</id>\\n                         <configuration>\\n                             <rules>\\n                                 <DependencyConvergence/>\\n                             </rules>\\n                         </configuration>\\n                         <goals>\\n                             <goal>enforce</goal>\\n                         </goals>\\n                     </execution>\\n                 </executions>\\n             </plugin>\\n\\n             \\n*\\n * This is the central class that coordinates the phenotype/Genotype2LR likelihood ratio test.\\n * @author Peter Robinson\\n * @version 0.9.1 (2019-01-02)\\n \\n*\\n * This class collects and organizes the variants found to be present in a given gene.\\n * It provides functions that can be used to calculate the genotype likelihood ratio.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* The NCBI Entrez Gene ID of this gene. \\n* The symbol of this gene. \\n* List of all of the variants found in this gene. \\n* Sum of variants in the pathogenic bin, weighted by their predicted pathogenicity. \\n* It simplifies the use of this class to have an object that indicates that NO VARIANT\\n     * was found in the gene (no variant in the gene was present in teh VCF file).    \\n*\\n     *\\n     * @param id gene ID of this gene\\n     * @param sym symbol of this gene\\n     \\n* @return true iff there is a variant with a pathogenic ClinVar interpretation. \\n*\\n * This class is responsible for parsing the VCF file and extracting variants and genotypes. Its\\n * main org.monarchinitiative.lirical.output is the map in {@link #gene2genotypeMap}.\\n *\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n*\\n     * Path to the VCF file with the exome/genome of the proband.\\n     \\n*\\n     * Prefix for the NCBI Entrez Gene data.\\n     \\n*\\n     * We will assume a frequency of 1:100,000 if no frequency data is available.\\n     \\n*\\n     * Reference to the Jannovar transcript file data for annotating the VCF file.\\n     \\n*\\n     * Reference dictionary that is part of {@link #jannovarData}.\\n     \\n*\\n     * Map of Chromosomes, used in the annotation.\\n     \\n*\\n     * A Jannovar object to report progress of VCF parsing.\\n     \\n*\\n     * Should be hg37 or hg38\\n     \\n* Number of variants that were not filtered. \\n* Number of variants that were removed because of the quality filter. \\n*\\n     * Key: an EntrezGene gene id; value a {@link Gene2Genotype} obhject with variants/genotypes in this gene.\\n     \\n* Number of samples in the VCF file. \\n* Name of the proband in the VCF file. \\n* List of all names in the VCF file \\n*\\n     * A map with data from the Exomiser database.\\n     \\n*\\n     * A set of interpretation classes from ClinVar that we will regard as pathogenic.\\n     \\n*\\n     * Read the VCF file and extract genotype\\n     * @return\\n     \\n*\\n     * Calculate a pathogenicity score for the current variant in the same way that the Exomiser does.\\n     *\\n     * @param variantEffect     class of variant such as Missense, Nonsense, Synonymous, etc.\\n     * @param pathogenicityData Object representing the predicted pathogenicity of the data.\\n     * @return the predicted pathogenicity score.\\n     \\n*\\n * Simulator that injects variants defined from {@link Phenopacket} among variants present in single VCF file.\\n \\n* Path to the file into which we will inject a mutation from a Phenopacket. \\n*\\n     * @param templateVcfPath {@link Path} to possibly un-indexed VCF file\\n     \\n*\\n     * Map {@link Phenopacket} to {@link VariantContext}s. Genotypes in variant contexts are modified so that they\\n     * will contain phenopacket subject\\'s id.\\n     \\n*\\n     *\\n     * @param subjectId identifier of the proband in the VCF file\\n     * @param variants List of variants we will add to the VCF file\\n     * @return HtsFile object\\n     * @throws IOException if the template VCF file cannot be read\\n     \\n* Classes to create an SVG graphic representing the result of likelihood raio analysis of one HPO Case.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n*\\n * Download a number of files needed for the analysis. We download by default to a subdirectory called\\n * {@code data}, which is created if necessary. We download the files {@code hp.obo}, {@code phenotype.hpoa},\\n * {@code Homo_sapiencs_gene_info.gz}, and {@code mim2gene_medgen}.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n*\\n * Run a grid search over number of terms and number of noise terms for\\n * phenotype-only LIRICAL. Can be run with or with imprecision.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* Directory that contains {@code hp.obo} and {@code phenotype.hpoa} files. \\n*\\n * This command is used to generate the background frequency files. It is not needed to run LIRICAL on exome/genome\\n * data, but may be interesting for those who desire to use a population frequency data source other than gnomAD. The\\n * heavy lifting is done by {@link GenicIntoleranceCalculator}.\\n * To run the command enter\\n * <pre>\\n *     java -jar LIRICAL.jar gt2git -e <path to Exomiser database> -g <hg19 or hg38>\\n * </pre>\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* One of HG38 (default) or HG19. \\n* Name of the output file (e.g., background-hg19.tsv). Determined automatically based on genome build..\\n* Path of the Jannovar file. Note this can be taken from the Exomiser distribution, e.g.,\\n     * {@code exomiser/1802_hg19/1802_hg19_transcripts_refseq.ser}. \\n* SHould be one of hg19 or hg38. \\n* If true, calculate the distribution of ClinVar pathogenicity scores. \\n* Directory that contains {@code hp.obo} and {@code phenotype.hpoa} files. In the current implementation this\\n     * is required to initialize the {@link LiricalFactory} object, but the data in this directory is not actually\\n     * needed for this analysis.\\n*\\n * Download a number of files needed for LIRICAL analysis\\n *\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* Reference to HPO object. \\n*\\n     * If true, the phenopacket contains the path of a VCF file.\\n     \\n*\\n     * List of HPO terms observed in the subject of the investigation.\\n     \\n*\\n     * List of excluded HPO terms in the subject.\\n     \\n*\\n     * String representing the genome build (hg19 or hg38). We get this from the Phenopacket\\n     \\n*\\n     * Path to the VCF file (if any).\\n     \\n*\\n     * Run an analysis of a phenopacket that contains a VCF file.\\n     \\n*\\n     * Run an analysis of a phenopacket that only has Phenotype data\\n     \\n*\\n * This is a common superclass for {@link YamlCommand} and {@link PhenopacketCommand}.\\n * Its purpose is to provide command line parameters and variables that are used\\n * in the same way by both of the subclasses.\\n \\n* Directory where various files are downloaded/created. \\n* Discard any candidate disease with no known disease gene or for which no predicted pathogenic variant\\n     * was found in the corresponding disease gene. \\n* The threshold for showing a differential diagnosis in the main section (posterior probability of 1%).\\n* If true, the program will not output an HTML file but will output a Tab Separated Values file instead.\\n* Prefix of the output file. For instance, if the user enters {@code -x sample1} and an HTML file is output,\\n     * the name of the HTML file will be {@code sample1.html}. If a TSV file is output, the name of the file will\\n     * be {@code sample1.tsv}. \\n* An object that contains parameters from the YAML file for configuration. \\n* Key: an EntrezGene id; value: corresponding gene symbol. \\n* Various metadata that will be used for the HTML org.monarchinitiative.lirical.output. \\n*\\n * Simulate one or multiple VCFs from a Phenopacket that has HPO terms and a gene mutation. The mutation will\\n * be \"injected\" into a template VCF file (this should be a \"normal\" VCF file), and LIRICAL will be run, and\\n * the rank of the original diagnosis from the Phenopacket will be recorded. To run a single case,\\n * <pre>\\n *     java -jar LIRICAL.jar -p sample-phenopacket.json -e path/to/exomiser-datadir -v template.vcf\\n * </pre>\\n * Use the -m 25 option to show at least 25 differential diagnosis (by default, only diseases with posterior\\n * probability above 1% are displayed).\\n * <p></p>\\n * In order to perform simulation on an entire directory of phenopackets, replace the -p option with\\n * the --phenopacket-dir option.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* If true, output HTML or TSV \\n* Each entry in this list represents one simulated case with various data about the simulation. \\n* The number of counts a certain rank was assigned \\n* key-- rank in a simulation; value -- number of times the rank was achieved. \\n*\\n     * No-op constructor meant to demo the phenotype LIRICAL algorithm by simulating some case based on\\n     * a phenopacket and a \"normal\" VCF file.\\n     \\n*\\n     * This method coordinates\\n     * @param phenopacketFile File with the Phenopacket we are currently analyzing\\n     \\n*\\n     * Run one or multiple simulations that are driven from one or multiple phenopackets. Each simulation\\n     * will add pathogenic allele(s) from the phenopacket to the otherwise background VCF file at\\n     * {@link #templateVcfPath}. The function {@link #runOneVcfAnalysis(File)} will determine the\\n     * rank of the correct diagnosis as represented in the Phenopacket.\\n     \\n*\\n     * This can be run in a single phenopacket mode (in which case phenopacketPath needs to be defined) or in\\n     * multi-phenopacket mode (in which case phenopacketDir needs to be defined).\\n     \\n*\\n * This class coordinates simulation of cases with only phenotype.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* Directory that contains {@code hp.obo} and {@code phenotype.hpoa} files. \\n* No-op constructor meant to demo the phenotype LIRICAL algorithm by simulating some case based on\\n     * randomly chosen diseases and HPO terms.\\n     \\n*\\n * This class coordinates the main analysis of a VCF file plus list of observed HPO terms. This\\n * analysis is driven by a YAML file.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* Reference to the HPO. \\n* If true, run with VCF file, otherwise, perform phenotype-only analysis. \\n*\\n     * Command pattern to coordinate analysis of a VCF file with LIRICAL.\\n     \\n*\\n     * Parse the YAML file and put the results into an {@link LiricalFactory} object.\\n     *\\n     * @param yamlPath Path to the YAML file for the VCF analysis\\n     * @return An {@link LiricalFactory} object with various settings.\\n     \\n*\\n * Not a full implementation of the factory pattern but rather a convenience class to create objects of various\\n * classes that we need as singletons with the various commands.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* Path to the {@code phenotype.hpoa} file. \\n* UCSC, RefSeq, Ensembl. \\n* Path to the {@code Homo_sapiens_gene_info.gz} file. \\n* Path to the mimgene/medgen file with MIM to gene associations. \\n* Path to the VCF file that is be evaluated. \\n* List of HPO terms (phenotypic abnormalities) observed in the person being evaluated. \\n* List of HPO terms that were excluded in the person being evaluated. \\n* The directory in which several files are stored. \\n* The directory with the Exomiser database and Jannovar transcript files. \\n* Number of variants that were not removed because of the quality filter. \\n* Number of variants that were removed because of the quality filter. \\n* The path to the Exomiser database file, e.g., {@code 1811_hg19_variants.mv.db}. \\n* genotype matching for likelihood ratio calculation\". \\n* retain candidates even if no candidate variant is found \\n* An object representing the Exomiser database. \\n* Key: the TermId of a gene. Value. Its background frequency in the current genome build. This variable\\n     * is only initialized for runs with a VCF file. \\n* If true, filter VCF lines by the FILTER column (variants pass if there is no entry, i.e., \".\",\\n     * or if the value of the field is FALSE. Variant also fail if a reason for the not passing the\\n     * filter is given in the column, i.e., for allelic imbalance. This is true by default. Filtering\\n     * can be turned off by entering {@code -q false} or {@code --quality} false. \\n* Path of the Jannovar UCSC transcript file (from the Exomiser distribution) \\n* Path of the Jannovar Ensembl transcript file (from the Exomiser distribution) \\n* Path of the Jannovar RefSeq transcript file (from the Exomiser distribution) \\n* Name of sample in VCF file, if any. The default value is n/a to indicate this field has not been initiatilized. \\n* Used as a flag to pick the right constructor in {@link Builder#buildForGt2Git()}. \\n*\\n     * This constructor is used to build Gt2Git. The BuildType argument is used as a flag.\\n     \\n*\\n     * @return a list of observed HPO terms (from the YAML/Phenopacket file)\\n     * @throws LiricalException if one of the terms is not in the HPO Ontology\\n     \\n*\\n     * @return a list of observed HPO terms (from the YAML/Phenopacket file)\\n     * @throws LiricalException if one of the terms is not in the HPO Ontology\\n     \\n* @return the genome assembly corresponding to the VCF file. Can be null. \\n* @return HpoOntology object. \\n* returns \"n/a if {@link #transcriptdatabase} was not initialized (should not happen). \\n*\\n     * This is called if the user passes the {@code --exomiser/-e} option. We expect there to be\\n     * the Jannovar and the MVStore files in the directory and want to construct the paths here.\\n     \\n* @return MVStore object with Exomiser data on variant pathogenicity and frequency. \\n* @return a multimap with key: a gene CURIE such as NCBIGene:123; value: a collection of disease CURIEs such as OMIM:600123. \\n* @return multimap with key:disease CURIEs such as OMIM:600123; value: a collection of gene CURIEs such as NCBIGene:123.  \\n* @return a map with key:a gene id, e.g., NCBIGene:2020; value: the corresponding gene symbol. \\n*\\n     * Create a {@link GenotypeLikelihoodRatio} object that will be used to calculated genotype likelhood ratios.\\n     * A runtime exception will be thrown if the file cannot be found.\\n     * @return a {@link GenotypeLikelihoodRatio} object\\n     \\n*\\n     * Deserialize the Jannovar transcript data file that comes with Exomiser. Note that Exomiser\\n     * uses its own ProtoBuf serializetion and so we need to use its Deserializser. In case the user\\n     * provides a standard Jannovar serialzied file, we try the legacy deserializer if the protobuf\\n     * deserializer doesn\\'t work.\\n     * @return the object created by deserializing a Jannovar file. \\n* @return a map with key: a disease id (e.g., OMIM:654321) and key the corresponding {@link HpoDisease} object.\\n* @return a string with today\\'s date in the format yyyy/MM/dd. \\n*\\n     * This is used by the Builder to check that all of the necessary files in the Data directory are present.\\n     * It writes one line to the logger for each file it checks, and throws a RunTime exception if a file is\\n     * missing (in this case we cannot continue with program execution).\\n     \\n*\\n     * This method checks whether the background frequency data was initialized\\n     \\n*\\n     * Perform Q/C of the input variables to try to ensure that the correct (matching) genome build is being used.\\n     \\n*\\n     * A convenience Builder class for creating {@link LiricalFactory} objects\\n     \\n* path to hp.obo file.\\n* The default transcript database is UCSC> \\n* If this constructor is used, the the build method will attempt to load the HPO\\n         * based on its file location in datadir. If it is not possible, we will die gracefully.\\n         \\n* @return an {@link org.monarchinitiative.exomiser.core.genome.GenomeAssembly} object representing the genome build.\\n* Initializes the paths to the four files that should be in the data directory. This method\\n         * should be called only after {@link #liricalDataDir} has been set.\\n         \\n*\\n * This class is used to input the YAML configuration file.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n*\\n     * This is a map in the YAML file that contains the following items:\\n     * genomeAssembly, vcf,jannovar, hp.obo, phenotype.hpoa,\\n     * gene_info, medgen, background_freq, datadir, mvstore, orphanet\\n     * In each case, the item is a path to a file that is needed (except for\\n     * genomeAssembly, which should be {@code hg19} or {@code hg38}).\\n     *\\n     * @return map with analysis parameters\\n     \\n* @return name (prefix) of the output file \\n* @return list of HPO ids observed in the proband. \\n*\\n * This class is meant to hold all of the data on a population background for the GNOMAD/ExAC datasets\\n * (e.g., one object of this class might hold data for GNOMAD_E_FIN).\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* An object that represents the source of frequency data (a population background, e.g., GNOMAD_E_FIN). \\n* key: A gene symbol; value: corresponding {@link org.monarchinitiative.lirical.gt2git.Gene2Bin} object. \\n* @return an optional containing the {@link org.monarchinitiative.lirical.gt2git.Gene2Bin} object for the gene symbol.\\n*\\n * This class represents one of two bins associated with each gene. Bin A is for the \"pathogenic\" variants, i.e.,\\n * with a pathogenicity score of 0.8-1, and bin B is for the \"non-pathogenic\" variants, i.e.,\\n * with a pathogenicity score of 0-0.8. Note that we do not record the frequency ranges for the bin within\\n * the bin itself -- this bookkeeping is done in the class {@link Gene2Bin}.\\n * It is important to note that the Exomiser reports frequencies as percentages and not as proportions, and so\\n * this class takes care of that.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* A small constant added to avoid division by zero. \\n* The sumOfPerc of the percentages (100*frequency) of all of the variants associated with this bin of this gene. \\n* The total number (count) of variants associated with this bin of this gene. \\n*\\n     *  Initialize this bin. Add a count of epsilon*100 as a pseudocount to avoid division by zero.\\n     \\n*\\n     * This function is called to add the data for one new variant to the bin.\\n     * We note that the Exomiser reports its frequency data as percentages.\\n     * @param percentage The percentage-reported population frequency of the variant\\n     \\n*\\n     * We return the frequency rather than the percentage. Note that this is the TOTAL frequency (sum of individual frequencies).\\n     * @return The sum of the frequency of all of the variants associated with this bin of this gene. \\n* @return The total number of variants associated with this bin of this gene. \\n*\\n * This class represents the collection of pathogenicity values that are observed for a specific gene. The pathogenicity\\n * values are divided up into two bins: 0-80% (benign) and 80-100% (predicted pathogenic).\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* The HGNC gene symbol for the current gene. \\n* The Entrez Gene id for the current gene. \\n* The {@link Bin} for pathogenicity scores from 0-80% .\\n* The {@link Bin} for pathogenicity scores from 80-100% .\\n* Lower limit of pathogenic bin--80 percent pathogenicity score \\n*\\n     * Set the symbol and id and initialize the two bins.\\n     * @param symbol a gene symbol\\n     * @param id the corresponding (Entrez Gene) Id.\\n     \\n*\\n     * Add the population freqeuncy (as percentage) and predicted pathogenicity for one variant\\n     * @param percentage population frequency expressed as percentage\\n     * @param pathogenicity predicted pathogenicity of some variant.\\n     \\n* @return the gene ID (e.g., EntrezGene number) of the gene. \\n* @return the header that will be used to write the results for all Gene2Bin objects to file. \\n* @return the sum of the frequencies of all variants in the pathogenic bin for the current gene. \\n*\\n * This class calculates the relative proportions of variants assessed as having a certain degree of pathogenicity\\n * by Exomiser. We examine all of the variants and place them into two pathogenicity bins: predicted benign (0-0.8)\\n * and predicted pathogenic (0.8-1.0). We then calculate the sum of all predicted pathogenic variant frequencies using\\n * the population background from the Exomiser database (gnomAD, TOPMed, others, but filtering out variants that are listed\\n * in ClinVar).\\n *\\n * @author <a href=\"mailto:j.jacobsen@qmul.ac.uk>Jules Jacobsen</a>\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* We will assume a frequency of 1:100,000 if no frequency data is available. \\n* The Exomiser reports the frequencies as percentages -- thus we need to convert here, because we want the default frequency to be 1:100_000. \\n* A set of interpretation classes from ClinVar that we will regard as pathogenic. \\n* Ordered list of the populations included in the calculations. \\n* The header of the org.monarchinitiative.lirical.output file that shows the populations included in the calculation. \\n* File name for the file that will contain the frequencies of predicted pathogenic variants in the\\n     * population background, i.e., from gnomAD  from the Exomiser database.\\n* An Exomiser class that annotates an arbitrary variant with frequency and pathogenicity information. \\n* Exomiser data store. \\n* If true, calculate the distribution of ClinVar pathogenicity scores. \\n*\\n     * @param variantAnnotator Object to annotate an arbitrary variant\\n     * @param alleleStore Exomiser data resource\\n     * @param fname name of org.monarchinitiative.lirical.output file (background-hg38.txt or background-hg19.tsv).\\n     * @param doClinvar flag that if true will cause the analysis to calculate the distribution of Clinvar pathogenicity scores\\n     \\n* Key: a {@link FrequencySource}, representing a population; value: corresponding {@link Background} with background frequency for genes. \\n* Set of all gene symbols used in our calculations. \\n* Key: a gene symbol value: corresponding EntrezGene id \\n*\\n     * This function inputs the data from the MV store, bins each variant into one of four categories,\\n     * normalizes the frequencies, and writes the results to a file that can be used elsewhere.\\n     \\n* We initialize bins for the major GNOMAD populations, Gnomad exome AFR, AMR, ASJ,EAS,FIN,NFE, and SAS.\\n     * We will calculate overall frequencies separately for each population and also take the average.\\n     \\n*\\n     * Add a single variant\\'s frequency/pathogenicity values to the appropriate bin\\n     * @param genesymbol The symbol of the gene that harbors the variant\\n     * @param geneId The Entrez Gene id of the gene that harbors the variant\\n     * @param frequency The frequency of the variant in the cohort represented by g2bmap\\n     * @param pathogenicity The pathogenicity of the variant as predicted by Exomiser\\n     \\n*\\n     * This function writes all of the pathogenicity scores for any variant classified as pathogenic by ClinVar to\\n     * a file.\\n     \\n*\\n     * This method goes through all of the Exomiser\\'s variants and records the frequencies of variants in the\\n     * predicted pathogenic bin (i.e., Exomiser score of 0.8 to 1.0). Note that we disregard off-exome\\n     * variants. We first try to find the frequency in GNOMAD_E (exome), under the assumption that this data\\n     * source will be the most accurate for exonic variants. Failing that, we take the corresponding\\n     * GNOMAD_G (genome) data.\\n     \\n*\\n     * Calculate a pathogenicity score for the current variant in the same way that the Exomiser does.\\n     * @param variantEffect class of variant such as Missense, Nonsense, Synonymous, etc.\\n     * @param pathogenicityData Object representing the predicted pathogenicity of the data.\\n     * @return the predicted pathogenicity score.\\n     \\n*\\n     * Output one line of the background pathogenicity data file for one gene. We write the mean value\\n     * across the populations listed in {@link #orderedSources}.\\n     * @param writer A file handle\\n     * @param genesymbol The symbol of the gene for which we will write the frequency data in this line\\n     * @throws IOException if there is a problem writing to file\\n     \\n*\\n     * Write the results of our calculations to file\\n     \\n*\\n * Convenience class to represent the age of a proband. Note that if (@link #initialized} is false,\\n * then we are representing the fact that we do not know the age and we will disregard the feature\\n * in our calculations. We will represent prenatal age as negative values.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n*\\n * Represents a single case and the HPO terms assigned to the case (patient), as well as the results of the\\n * likelihood ratio analysis.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n * @version 0.0.2 (2018-04-04)\\n \\n* List of Hpo terms for our case. \\n* List of excluded Hpo terms for our case. \\n* One of Male, Female, Unknown. See {@link Sex}. \\n* Age of the proband, if known. \\n* @return A list of the HPO terms representing the phenotypic abnormalities in the person being evaluated.\\n* @return A list of the HPO terms representing abnormalities that were excluded in the person being evaluated.\\n* @return the sex of the person being evaluated. \\n* The {@link Age} of the person being evaluated.\\n* @return Sort List of {@link TestResult} objects for each diseases in the differential diagnosis. \\n* * @return total number of positive and negative phenotype observations for this case.\\n*\\n     * The argument to the function is the TermId (e.g., OMIM:600100) of a disease. This function checks to\\n     * see what rank the disease was assigned by LIRICAL; the ranks are stored in {@link #disease2resultMap}.\\n     * Note that in some cases, the correct disease may be completely removed from the list of results. This can\\n     * be the case, fo instance, if we are using the {@code strict} option and only return diseases for which\\n     * LIRICAL finds a predicted pathogenic variant in a gene associated with the disease.\\n     * Therefore, we return an Optional. If it is not-present, then the disease was not found.\\n     * @param diseaseId CURIE (e.g., OMIM:600100) of the disease whose rank we want to know\\n     * @return the rank of the disease within all of the test results.\\n     *\\n     \\n*\\n     * If a disease is unranked, then it is tied for the rank after the last rank of the ranked diseases\\n     * @return (tied) rank of an unranked disease\\n     \\n* Convenience class to construct an {@link HpoCase} object. \\n* List of Hpo terms for our case. \\n* List of excluded Hpo terms for our case. \\n* List of results . \\n* One of Male, Female, Unknown. See {@link Sex}. \\n* Age of the proband, if known. \\n*\\n * Helper class for downloading files over HTTP and FTP.\\n *\\n * The implementation of FTP downloads is more complex since we need passive FTP transfer through firewalls. This is not\\n * possible when just opening a stream through an {@link URL} object with Java\\'s builtin features.\\n *\\n * @author <a href=\"mailto:manuel.holtgrewe@charite.de\">Manuel Holtgrewe</a>\\n \\n*\\n     * Configuration for the {@link FileDownloader}.\\n     \\n* configuration for the downloader \\n* Initializer FileDownloader with the given options string \\n* Downloader with default options \\n*\\n     * This method downloads a file to the specified local file path. If the file already exists, it will\\n     * overwrite it and emit a warning.\\n     *\\n     * @param src\\n     *            {@link URL} with file to download\\n     * @param dest\\n     *            {@link File} with destination path\\n     * @return <code>true</code> if the file was downloaded and <code>false</code> if not.\\n     * @throws FileDownloadException\\n     *             on problems with downloading\\n     \\n*\\n     * Copy contents of a URL to a file using the {@link URL} class.\\n     *\\n     * This works for the HTTP and the HTTPS protocol and for FTP through a proxy. For plain FTP, we need to use the\\n     * passive mode.\\n     \\n*\\n     * Set system properties from {@link #options}.\\n     \\n*\\n * This class coordinates the input of the background frequency file. Note that this file is added as a resource to the\\n * JAR file, i.e., {@code LIRICAL.jar!/background/background-hg19.tsv} (or -hg38.tsv), and so it cannot be opened using\\n * a path. The user is allowed to provide their own background file, in which case a path is used. There are two\\n * factory methods, one for the path and one for the name of a resource (both are strings).\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* Key: the TermId of a gene. Value. Its background frequency in the current genome build. This variable\\n     * is only initialized for runs with a VCF file. \\n*\\n     * symbol\\tgeneID\\tfreqsum-benign\\tcount-benign\\tfreqsum-path\\tcount-path\\n     \\n*\\n * Command to download the {@code hp.obo} and {@code phenotype.hpoa} files that\\n * we will need to run the LIRICAL approach.\\n \\n* Directory to which we will download the files. \\n* If true, download new version whether or not the file is already present. \\n* URL of the hp.obo file. \\n* URL of the annotation file phenotype.hpoa. \\n* Basename of the phenotype annotation file. \\n*\\n     * Download the files unless they are already present.\\n     \\n*\\n * This class ingests a phenopacket, which is required to additionally contain the\\n * path of a VCF file that will be used for the analysis.\\n * @author Peter Robinson\\n \\n* The Phenopacket that represents the individual being sequenced in the current run. \\n* Object representing the VCF file with variants identified in the subject of this Phenopacket. \\n* Name of the proband of the Phenopacket (corresponds to the {@code id} element of the phenopacket). \\n* Reference to HPO ontology \\n*\\n     * Factory method to obtain a PhenopacketImporter object starting from a phenopacket in Json format\\n     * @param pathToJsonPhenopacketFile -- path to the phenopacket\\n     * @return {@link PhenopacketImporter} object corresponding to the PhenoPacket\\n     \\n*\\n     * The path to the VCF file may be a string such as file:/path/to/examples/BBS1.vcf\\n     * In this case, remove the prefix \\'path:\\', otherwise return the original URI\\n     * @return URI of VCF file mentioned in the Phenopacket\\n     \\n* This method extracts the VCF file and the corresponding GenomeBuild. We assume that\\n     * the phenopacket contains a single VCF file and that this file is for a single person. \\n*\\n * A simple status bar that only work on terminals where \"\\\\r\" has an affect.\\n *\\n * The progress is done/shown in the closed interval <code>[min, max]</code>.\\n *\\n * @author <a href=\"mailto:manuel.holtgrewe@charite.de\">Manuel Holtgrewe</a>\\n \\n* smallest value \\n* largest value \\n* whether or not to print \\n* Initialize progress bar with the given settings \\n* Initialize progress bar with the given settings \\n* @return smallest value to represent \\n* @return largest value to represent \\n* @return <code>true</code> if the progress bar has printing enabled \\n* print progress up to position <code>pos</code>, if {@link #doPrint} \\n*\\n * This class ingests a YAML file with parameters that will be used for the analysis.\\n * @author Peter Robinson\\n \\n* THe path to which LIRICAL will download data such as hp.obo by default. \\n*\\n     * The YAML file is allowed to have an element called analysis/background for the background\\n     * frequency file. If it is present, we return in in an Optional object. Usually, users should use\\n     * the default files and not include this element in the yaml file.\\n     * @return path to the background-frequency path if present, otherwise an empty Optional object.\\n     \\n*\\n     * @return path to the approprioate Jannovar transcript file (UCSC, Ensembl, or RefSeq).\\n     * @throws LiricalException if there is an error retrieving the Jannovar data object\\n     \\n*\\n     * In most cases, users should use the default data directory (\"data\") that is created by the LIRICAL download\\n     * command by default. If users choose another path, they should enter a datadir element in the YAML file.\\n     * An empty Optional object is return if nothing is present in the YAML file, indicating that the default\\n     * should be used\\n     * @return Path of non-default data directory or default. Trailing slash (if present) will be removed\\n     \\n*\\n     * The Yaml file should have an entry {@code exomiser: /some/path/} in the analysis\\n     * section if the user wants to run a VCF-based analysis (this requires the Exomiser database). If there is\\n     * {@code mode: vcf} or if there is no entry, we will run a VCF analysis\\n     * @return true if phenotype only analysis should be performed.\\n     \\n*@return A String representing the genome assembly of the VCF file (should be hg19 or hg38). \\n*\\n     * The user can choose to run LIRICAL without a VCF file. Then, a phenotype only analysis is performed.\\n     * In this case, we return an empty Optional object.\\n     * @return Path to VCF file, if present.\\n     \\n*\\n     * @return list of Strings representing HPOs, e.g., HP:0001234,HPO:0002345\\n     \\n* @return list of Strings with excluded (negated) HPO terms. \\n* @return true if the YAML analysis section contains a KV pair keep:true \\n*\\n     * If the analysis section of the YAML file has a valid threshold entry, return it\\n     * @return threshold (may be empty)\\n     \\n*\\n * Likelihood ratio evaluator. This class coordinates the performance of the likelihood ratio test\\n * and returns one {@link HpoCase} object with the results by the method {@link #evaluate()}.\\n *\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n*\\n     * List of abnormalities seen in the person being evaluated.\\n     \\n*\\n     * Map of the observed genotypes in the VCF file. Key is an EntrezGene is, and the value is the average pathogenicity score times the\\n     * count of all variants in the pathogenic bin.\\n     \\n*\\n     * key: a disease CURIE, e.g., OMIM:600100; value-corresponding disease object.\\n     \\n key: a gene CURIE such as NCBIGene:123; value: a collection of disease CURIEs such as OMIM:600123; \\n*\\n     * Probability of diseases before testing (e.g., prevalence or 1/N).\\n     \\n*\\n     * Object used to calculate phenotype likelihood ratios.\\n     \\n*\\n     * Object used to calculate genotype-based likelihood ratio.\\n     \\n*\\n     * Reference to the Human Phenotype Ontology object.\\n     \\n*\\n     * retain candidates even if no candidate variant is found\\n     \\n*\\n     * If true, then genotype information is available for the analysis. Otherwise, skip it.\\n     \\n*\\n     * List of abnormalities excluded in the person being evaluated.\\n     \\n*\\n     * Key: an EntrezGene id; value: corresponding gene symbol.\\n     \\n*\\n     * This constructor is used for phenotype-only cases.\\n     *\\n     * @param hpoTerms             List of phenotypic abnormalityes observed in the patient\\n     * @param ontology             Reference to HPO ontology\\n     * @param diseaseMap           key: disease CURIE, e.h., OMIM:600100; value: HpoDisease object\\n     * @param phenotypeLrEvaluator class to evaluate phenotype likelihood ratios.\\n     \\n*\\n     * Constructor for LIRICAL anaysis with a VCF file.\\n     *\\n     * @param hpoTerms             list of observed abnormalities\\n     * @param negatedHpoTerms      list of excluded abnormalities\\n     * @param ontology             reference to HPO ontology\\n     * @param diseaseMap           map to HPO disease objects\\n     * @param disease2geneMultimap map from disease id to the corresponding gene symbols\\n     * @param phenotypeLrEvaluator reference to object that evaluates the phenotype LR\\n     * @param genotypeLrEvalutator reference to object that evaluates the genotype LR\\n     * @param genotypeMap          Map of gene symbol to genotype evaluations\\n     * @param keep                 if true, do not discard candidates if they do not have a candidate variant\\n     \\nlogger.error(\"{}: {} {} [{}]\",\\n                    ,\\n                    ontology.getTermMap().get(tid).getName(),\\n                    lrwe.getLR(),\\n                    lrwe.getExplanation(ontology));\\n*\\n     * Perform the evaluation of the current case based only on phenotype evidence\\n     *\\n     * @return map with key=disease idea and value=corresponding {@link TestResult}\\n     \\n*\\n     * This method calculates the likelihood ratio based only on phenotype. It is inteded to be used\\n     * for analyses where we do not have an exome or genome. Note that we return an optional because\\n     * with some user settings some differentials will be skipped.\\n     *\\n     * @param diseaseId The disease being tested\\n     * @return The corresponding TestResult.\\n     \\n*\\n     * This method is used to calculate the likelihood ratio based on both phenotype and genotype\\n     * It should be used for analyses where we have an exome or genome. This method is used if\\n     * the user has indicated that they want to see all differential diagnoses, including those\\n     * that do not have a known disease gene and those where no pathogenic variant was found\\n     * in the exome/genome VCF file.\\n     *\\n     * @param diseaseId The disease being tested\\n     * @return The corresponding TestResult.\\n     \\n*\\n     * Convenience function to create an explanation for the genotype score that we show in the HTML output\\n     *\\n     * @param g2g              The gene in question\\n     * @param inheritancemodes Modes of inheritance of diseases associated with this gene\\n     * @param geneId           The NCBI Gene id\\n     * @return the explanation for the score.\\n     \\n*\\n     * Calculate the likelihood ratio for diseaseId. If there is no predicted pathogenic variant in the exome/genome file,\\n     * then we will return Optional.empty(), which will cause this diseases to be skipped in the differential diagnosis.\\n     *\\n     * @param diseaseId an Id for a disease entry, e.g., OMIM:157000.\\n     * @return A TestResult for diseaseId, or Optional.empty() if no pathogenic variant was found in the associated gene(s).\\n     \\n*\\n     * Perform the evaluation of the current case based on phenotype and genotype evidence\\n     * If {@link #keepIfNoCandidateVariant} is true, then we also rank differential diagnoses even\\n     * if (i) no disease gene is known or (ii) the disease gene is known but we did not find a\\n     * pathogenic variant. In the latter case, the candidate will be downranked, but can still score\\n     * highly if the phenotype evidence is very strong.\\n     *\\n     * @return map with key=disease idea and value=corresponding {@link TestResult}\\n     \\n*\\n     * This method evaluates the likelihood ratio for each disease in\\n     * {@link #diseaseMap}. After this, it sorts the results (the best hit is then at index 0, etc).\\n     \\n*\\n     * This function sets the rank of the {@link TestResult} objects.\\n     *\\n     * @param resultMap The objects of the resultMap are not not set wrt rank before thie function is called\\n     * @return same resultMap, but the TestResult objects have their ranks set.\\n     \\n*\\n     * Convenience class for building a {@link CaseEvaluator} object--mainly to avoid having\\n     * a constructor with an extremely long list of arguments.\\n     \\n*\\n         * The abnormalities observed in the individual being investigated.\\n         \\n*\\n         * These abnormalities were excluded in the proband (i.e., normal).\\n         \\n*\\n         * Key: diseaseID, e.g., OMIM:600321; value: Corresponding HPO disease object.\\n         \\n key: a gene CURIE such as NCBIGene:123; value: a collection of disease CURIEs such as OMIM:600123; \\n*\\n         * An object that calculates the foreground frequency of an HPO term in a disease as well as the background frequency\\n         \\n*\\n         * Key: geneId (e.g., NCBI Entrez Gene); value: observed variants/genotypes as {@link org.monarchinitiative.lirical.analysis.Gene2Genotype} object.\\n         \\n*\\n         * retain candidates even if no candidate variant is found (default: false)\\n         \\n*\\n         * Key: an EntrezGene id; value: corresponding gene symbol.\\n         \\n*\\n * This class is responsible for calculating the genotype-based likelihood ratio.\\n *\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n Default frequency of called-pathogenic variants in the general population (gnomAD). In the vast majority of\\n     * cases, we can derive this information from gnomAD. This constant is used if for whatever reason,\\n     * data was not available.\\n     \\n* A small-ish number to avoid dividing by zero. \\n* Use strict penalties if the genotype does not match the disease model in terms of number of called\\n     * pathogenic alleles.\\n*\\n     * Entrez gene Curie, e.g., NCBIGene:2200; value--corresponding background frequency (ie.,\\n     * lambda-background), the sum of pathogenic bin variants in the population (gnomAD).\\n     \\n*\\n     * This is a Poisson distribution object that is used to help calculate the genotype likelihood ratio for cases\\n     * with autosomal recessive inheritance. We can construct this object once and reuse it. This is\\n     * lambda-disease with lambda=2\\n     \\n*\\n     * This is a Poisson distribution object that is used to help calculate the genotype likelihood ratio for cases\\n     * with autosomal dominant inheritance. We can construct this object once and reuse it. This is\\n     * lambda-disease with lambda=1\\n     \\n*\\n     * @param g2background background frequencies of called pathogenic variants in genes.\\n     \\n*\\n     * @param g2background background frequencies of called pathogenic variants in genes.\\n     * @param str strictness of genotype likelihood ratio (see {@link #strict}).\\n     \\n*\\n     * If no pathogenic variant at all was identified in the gene of interest, we use a heuristic score that\\n     * intends to represent the probability of missing the variant for technical reasons. We will estimate\\n     * this probability to be 5%. For autosomal recessive diseases, we will estimate the probability at\\n     * 5% * 5%.\\n     *\\n     * @param inheritancemodes List of all inheritance modes associated with this disease (usually a single one)\\n     * @return genotype likelihood ratio for situation where no variant at all was found in a gene\\n     \\n*\\n     * Check if the optional has a value already. If not, set it to val. Otherwise, set it to the maximum\\n     * @param val New value\\n     * @param opt Optional that may or may not already have a value\\n     * @return an optional with val or with the max of val and opt.get() if opt has a value\\n     \\n*\\n     * Calculate the genotype likelihood ratio using lambda_disease=1 for autosomal dominant and lambda_disease=2\\n     * for autosomal recessive.\\n     *\\n     * @param g2g              {@link Gene2Genotype} object with list of variants in current gene. Can be null if no variants were found in the gene\\n     * @param inheritancemodes list of modes of inheritance associated with disease being investigated (usually with just one entry).\\n     * @param geneId           EntrezGene id of the gene we are investigating.\\n     * @return likelihood ratio of the genotype given the disease/geniId combination\\n     \\n*\\n     * This method is intended to explain the score that is produced by {@link #evaluateGenotype}, and\\n     * produces a shoprt summary that can be displayed in the org.monarchinitiative.lirical.output file. It is intended to be used for the\\n     * best candidates, i.e., those that will be displayed on the org.monarchinitiative.lirical.output page.\\n     *\\n     * @param g2g {@link Gene2Genotype} object with variants/genotypes in the current gene.\\n     * @param inheritancemodes           List of all inheritance modes associated with this disease (usually has one element,rarely multiple)\\n     * @param geneId                     EntrezGene id of the current gene.\\n     * @return short summary of the genotype likelihood ratio score.\\n     \\n*\\n * For some calculations of the phenotype likelihood ratio, we need to traverse the graph induced by the HPO terms to\\n * which a disease is annotated. It is cheaper to create this graph once and reuse it for each of the query terms. This\\n * class organizes that calculation. Note that this class is only used if there are no direct matches, so there is\\n * no need to store the directly annotated diseases here.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* reference to HPO ontology object. \\n*\\n     * If a disease is negative for say Abnormal serum creatinine kinase level\\n     * and the parent term Elevated serum creatinine kinase, was excluded in\\n     * the patient, then we can say that the patient must be negative for all of the\\n     * children of Abnormal serum creatinine kinase. We can therefore tak the induced\\n     * ancestor graph of Abnormal serum creatinine kinase level (which includes\\n     * Abnormal serum creatinine kinase), and if any of the patient negated terms are\\n     * in this graph, then they are excluded both in the patient and in the disease.\\n     \\n*\\n     * An inner class that represents a term together with the minimum path length to any\\n     * term that directly annotates {@link #disease}.\\n     \\n*\\n     * Create the induced graph of the HPO terms used to annotate the disease. We weight the frequency downwards\\n     * according to the number of links (path length). That is, if the path length from a direct annotation to\\n     * an ancestor is k, then we multiple the frequency of the annotation by (1/k).\\n     * @param hpoDisease The disease we are currently investigating.\\n     * @param ontology Reference to HPO ontology object\\n     \\n*\\n     * See comments about {@link #inducedNegativeGraph}.\\n     * @param tid A term that was negated in a patient\\n     * @return true if the term is also negated in the disease.\\n     \\n*\\n     * Get the terms that annotates disease (or is an ancestor of one of the terms) that are\\n     * closest to tid in terms of path length. Return the best hits (list if more than one\\n     * terms has a closest path length\\n     * @param tid a query term\\n     * @return The best hit\\n     \\n*\\n * There are five possible ways that a query term can match a disease term. The likelihood ratio\\n * is calculated differently for each of these match types (see {@link MatchType}).This class\\n * captures sufficient information about each match to provide an explanation for the HTML output.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n*\\n     * Get versions of the string that will work in HTML\\n     * @param ontology reference to HPO ontology\\n     * @return an HTML string that explains this phenotypic LR result.\\n     \\n*\\n     * Sort the {@link LrWithExplanation} objects in decreasing order according to likelihood ratio score.\\n     * This will match the order of the bars in the SVG plot.\\n     * @param that Other object\\n     * @return integer indicating sort order\\n     \\n*\\n * This class is designed to calculate the background and foreground frequencies of any HPO term in any disease\\n * (This is calculated by {@link #initializeFrequencyMap()} and stored in {@link #hpoTerm2OverallFrequency}).\\n * The main entry point into this class is the function {@link #getLikelihoodRatio}, which is called by\\n * {@link HpoCase} once for each HPO term to which the case is annotation; it calls it once for each disease in our\\n * database and calculates the likelihood ratio for each HPO term in the query for each of the diseases.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* The HPO ontology with all of its subontologies. \\n* This map has one entry for each disease in our database. Key--the disease ID, e.g., OMIM:600200.\\n* Overall, i.e., background frequency of each HPO term. \\n*\\n     * This is the probability of a finding if the disease is not annotated to it and there\\n     * is no common ancestor except the root. There are many possible causes of findings called\\n     * to be \"false-positive\". The annotations of the disease can be incomplete. A finding such\\n     * as renal insufficiency can manifest with proteinuria etc, but the disease annotation might\\n     * be renal insufficiency and the patient might just be reported to have proteinuria. Currently,\\n     * our software is not smart enough to make possible connections such as this. Finally, it\\n     * may be truly false positive because there is a secondary etiology. We assume arbitrary\\n     * small probability (one in ten thousand)\\n     \\n*\\n     * The default probability for an HPO term annotating a disease if we cannot find in the dataset.\\n     \\n* The default likelihood ratio for a query term that is explicitly excluded in a disease.\\n* The default likelihood ratio for an excluded query term that is explicitly excluded in a disease.\\n*\\n     * @param onto The HPO ontology object\\n     * @param diseases List of all diseases for this simulation\\n     \\n*\\n     * Calculate and return the likelihood ratio of observing the HPO feature queryTid in an individual\\n     * with the disease idg (note that the InducedDiseaseGraph contains information about the annotations\\n     * of the disease that we use to calculate the likelihood ratios).\\n     * @param queryTid An HPO phenotypic abnormality\\n     * @param idg The {@link InducedDiseaseGraph} of the disease\\n     * @return A {@link LrWithExplanation} object with an explanation and the likelihood ratio of observing the HPO term in the disease corresponding to idg\\n     \\n*\\n     * Calculate and return the likelihood ratio of an EXCLUDED HPO feature tid in an individual\\n     * with the disease \"diseaseId\"\\n     * @param queryTid An HPO phenotypic abnormality\\n     * @param idg An {@link InducedDiseaseGraph} created for the disease\\n     * @return the likelihood ratio of an EXCLUDED HPO term in the diseases\\n     \\n*\\n     * @param queryTid TermId of an HPO term\\n     * @param disease the disease being studied\\n     * @param ontology reference to HPO Ontology\\n     * @return true if the disease has a direct (explicit) or indirect (implicit) annotation to tid\\n     \\n*\\n     * Get the frequency of a term in the disease. This includes if any disease term is an ancestor of the\\n     * query term -- we take the maximum of any ancestor term.\\n     * @param queryTid Term ID of an HPO term whose frequency we want to know\\n     * @param disease The disease in which we want to know the frequency of tid\\n     * @param ontology Reference to the HPO ontology\\n     * @return frequency of the term in the disease (including annotation propagation)\\n     \\n* The intuition is that a patient has been observed to have a phenotype to which the disease\\n     * is not annotated. We will model this as being more likely if the phenotype is common amongst\\n     * the entire corpus of diseases. If the feature is maximally rare, i.e., 1/diseases.size(), then\\n     * we will estimate this frequency as being 1:500. If the feature is very common (at least 10%),\\n     * then we will estimate it as being 1:10.\\n     * @param tid TermId of a term for which the disease has no annotations (nothing in common except root)\\n     * @return Estimate probability of this (\"false-positive\") finding\\n     \\n*\\n     * Get the overall proportion of the frequency that is made up by the query term, given that\\n     * query term is a descendant of the diseaseTerm (which should be checked before this method is called).\\n     * @param queryTid A term used in the query (i.e., an annotation of the HpoCase proband)\\n     * @param diseaseTid A term that is annotated to the disease we are investigating\\n     * @return the proportion of the frequency of diseaseTerm that is attributable to query\\n     \\n*\\n     * This function estimates the probability of a test finding (the HP term is present) given that the\\n     * disease is not present -- we call this the background frequency.\\n     * @return the estimate background frequency (note: bf \\\\in [0,1])\\n     \\n*\\n     * Initialize the {@link #hpoTerm2OverallFrequency} object that has the background frequencies of each of the\\n     * HPO terms in the ontology. \\n* @return the number of diseases we are using for the calculations. \\n*\\n * Convenience class for returning a term and its corresponding frequency\\n \\n*\\n * This class organizes information about the result of a test. The class is intended to be used together\\n * with the class {@link HpoCase}, which contains lists of observed and excluded HPO terms. For each\\n * disease in the database, the likelihood ratios of these phenotypes is calculated, and the result\\n * for each disease is stored in an object of this class. The order of the individual phenotypes in\\n * {@link HpoCase} is the same as the order of the corresponding test rests in this class: {@link #results}\\n * for the observed phenotypes and {@link #excludedResults} for the phenotypes that were excluded in\\n * the patient. This object can include the result of a likelihood ratio for a genotype test. However,\\n * not every disease is associated with a known disease gene. Therefore, if no genotype is available,\\n * {@link #genotypeLR} and {@link #entrezGeneId} are null.\\n *\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n * @version 0.4.5 (2019-10-28)\\n \\n*A list of results for the tests performed on observed phenotypes for {@link #hpoDisease}.\\n* A list of test results for phenotypes that were excluded.\\n* Result of the likelhood ratio test for the genotype. \\n* The id of the gene associated with ths disease being tested here. \\n* This is the product of the individual test results. \\n* Reference to the the disease that we are testing (e.g., OMIM:600100).\\n* The probability of some result before the first test is done.\\n* The probability of some result after testing.\\n* The overall rank of the the result withint the differential diagnosis. \\n* An optional setGenotypeExplanation of the genotype result, intended for display \\n* An setGenotypeExplanation of the phenotype score. \\n*\\n     * The constructor initializes the variables and calculates {@link #compositeLR}\\n     *\\n     * @param reslist list of individual test results for observed phenotypes\\n     * @param excllist list of individual test results for excluded phenotypes\\n     * @param diseaseId name of the disease being tested\\n     * @param pretest pretest probability of the disease\\n     \\n*\\n     * This constructor should be used if we have a genotype for this gene/disease.\\n     * @param reslist list of individual test results for observed phenotypes\\n     * @param excllist list of individual test results for excluded phenotypes\\n     * @param diseaseId name of the disease being tested\\n     * @param genotypeLr LR result for the genotype\\n     * @param geneId gene id of the gene being tested\\n     * @param pretest pretest probability of the disease\\n     \\n* @return the composite likelihood ratio (product of the LRs of the individual tests).\\n* @return the total count of tests performed (excluding genotype).\\n* @return the pretest odds.\\n* @return the post-test odds. \\n*\\n     * Compare two TestResult objects based on their {@link #compositeLR} value.\\n     * @param other the \"other\" TestResult being compared.\\n     * @return comparison result\\n     \\n*\\n     * @param i index of the test we are interested in for an observed phenotype\\n     * @return the likelihood ratio of the i\\'th test\\n     \\n*\\n     * @param i index of the test we are interested in for an excluded phenotype\\n     * @return the likelihood ratio of the i\\'th test\\n     \\n* @return name of the disease being tested. \\n* @return the name of the disease, e.g., Marfan syndrome. \\n*@return true if a genotype likelihood ratio was assigned to this test result. \\n*\\n * This class stores all the information we need for a detailed differential diagnosis -- the major\\n * candidates. It is intended to be used as a Java Bean for the FreeMarker HTML template.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* The CURIE-like identifier of the disease, e.g., OMIM:600123 \\n* This is the anchor that will be used on the HTML page. \\n* The rank of this disease in the current analysis. \\n* The base-10 logarithm of the likelihood ratio. \\n* SVG string illustrating the contributions of each feature to the overall score. \\n* Set this to yes as a flag for the template to indicate we can show some variants. \\n* The answer to this string is used by the FreeMarker template to determine whether or not to show\\n     * a table with variants.\\n     * @return \"yes\" if this differential diagnosis has variants.\\n     \\n*\\n     * We are getting the disease names from OMIM (actually from our small files), and so some of them are long and\\n     * unweildly strings such as the following:\\n     * {@code }#101200 APERT SYNDROME;;ACROCEPHALOSYNDACTYLY, TYPE I; ACS1;;ACS IAPERT-CROUZON DISEASE,\\n     * INCLUDED;;ACROCEPHALOSYNDACTYLY, TYPE II, INCLUDED;;ACS II, INCLUDED;;VOGT CEPHALODACTYLY, INCLUDED}. We want to\\n     * remove any leading numbers and only show the first part of the name (before the first \";;\").\\n     * @param originalName original possibly verbose disease name with synonyms\\n     * @return prettified disease name intended for display on HTML page\\n     \\n* @param a An HTML anchor that is used for the HTML template. \\n* @return An HTML anchor that is used for the HTML template. \\n* @return An genotypeExplanation of how the genotype score was calculated (for the HTML template). \\n* @param genotypeExplanation An genotypeExplanation of how the genotype score was calculated (for the HTML template). \\n* @return true iff this differential diagnosis has an genotypeExplanation about the genotype score. \\n*\\n * This class coordinates getting the data from the analysis into the FreeMark org.monarchinitiative.lirical.output templates.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* Threshold posterior probability to show a differential diagnosis in detail. \\n* Have the HTML output show at least this many differntials (default: 5). \\n*\\n     * Constructor to initialize the data that will be needed to output an HTML page.\\n     * @param hcase The individual (case) represented in the VCF file\\n     * @param ontology The HPO ontology\\n     * @param genotypeMap A map of genotypes for all genes with variants in the VCF file\\n     * @param geneid2sym A map from the Entrez Gene id to the gene symbol\\n     * @param metadat Metadata about the analysis.\\n     * @param thres threshold posterior probability to show differential in detail\\n     \\n*\\n     * Constructor to initialize the data that will be needed to output an HTML page.\\n     * Used for when we have no genetic data\\n     * @param hcase The individual (case) represented in the VCF file\\n     * @param ontology The HPO ontology\\n\\n     * @param metadat Metadata about the analysis.\\n     * @param thres threshold posterior probability to show differential in detail\\n     \\n*\\n * This class arranges data for genes that do not have a probable differential diagnosis. The FreeMarker template\\n * will show all of them as a table.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n*\\n     * Construct a data opbject for display in FreeMarker template (which requires a public constructor)\\n     * @param name Name of the disease\\n     * @param id database id of the disease\\n     * @param gene affected gene\\n     * @param ptprob posterior probability\\n     * @param count number of variants in {@code gene}\\n     \\n*\\n * This class encapsulates information about the result of LIRICAL analysis, roughly corresponding\\n * to one line of the TSV output file with the rank of the originally simulated disease. This\\n * class is intended to be used only for the Vcf/Phenopacket simulations.\\n \\n* Numerator: Number of diseases with posterior probability over 50%; denominator: total number of diseases tested. \\n*\\n * This is the superclass for {@link TsvTemplate} and {@link HtmlTemplate}, and provides common methods for\\n * setting up the data prior to output as either tab-separated values (TSV) or HTML.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* Map of data that will be used for the FreeMark template. \\n* FreeMarker configuration object. \\n* This map contains the names of the top differential diagnoses that we will show as a list at the\\n     * top of the page together with anchors to navigate to the detailed analysis.\\n* Anchors that are used in the HTML output to navigate to the top differential diagnoses. \\n* Key: an EntrezGene id; value: corresponding gene symbol. \\n* Some of our name strings contain multiple synonyms. This function removes all but the first.\\n* Set this to yes as a flag for the template to indicate we can show some variants. \\n*\\n     * We are getting the disease names from OMIM (actually from our small files), and so some of them are long and\\n     * unweildly strings such as the following:\\n     * {@code }#101200 APERT SYNDROME;;ACROCEPHALOSYNDACTYLY, TYPE I; ACS1;;ACS IAPERT-CROUZON DISEASE,\\n     * INCLUDED;;ACROCEPHALOSYNDACTYLY, TYPE II, INCLUDED;;ACS II, INCLUDED;;VOGT CEPHALODACTYLY, INCLUDED}. We want to\\n     * remove any leading numbers and only show the first part of the name (before the first \";;\").\\n     * @param originalName original possibly verbose disease name with synonyms\\n     * @return prettified disease name intended for display on HTML page\\n     \\n*\\n * This class coordinates the output of a TSV file that contains a suymmary of the analysis results.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n*\\n     * Constructor for when we do the analysis without genetic data\\n     * @param hcase The current HPO case whose results we are about to output\\n     * @param ontology Reference toHPO Ontology object\\n     * @param metadat Reference to a map of \"metadata\"-information we will use for the output file\\n     \\n*\\n     * <a href=\"http://en.wikipedia.org/wiki/Euler-Mascheroni_constant\">Euler-Mascheroni constant</a>\\n     * @since 2.0\\n     \\n*\\n     * The value of the {@code g} constant in the Lanczos approximation, see\\n     * {@link #lanczos(double)}.\\n     * @since 3.1\\n     \\n* Maximum allowed numerical error. \\n* Lanczos coefficients \\n* Avoid repeated computation of log of 2 PI in logGamma \\n\\n     * Constants for the computation of double invGamma1pm1(double).\\n     * Copied from DGAM1 in the NSWC library.\\n     \\n* The constant {@code A0} defined in {@code DGAM1}. \\n* The constant {@code A1} defined in {@code DGAM1}. \\n* The constant {@code B1} defined in {@code DGAM1}. \\n* The constant {@code B2} defined in {@code DGAM1}. \\n* The constant {@code B3} defined in {@code DGAM1}. \\n* The constant {@code B4} defined in {@code DGAM1}. \\n* The constant {@code B5} defined in {@code DGAM1}. \\n* The constant {@code B6} defined in {@code DGAM1}. \\n* The constant {@code B7} defined in {@code DGAM1}. \\n* The constant {@code B8} defined in {@code DGAM1}. \\n* The constant {@code P0} defined in {@code DGAM1}. \\n* The constant {@code P1} defined in {@code DGAM1}. \\n* The constant {@code P2} defined in {@code DGAM1}. \\n* The constant {@code P3} defined in {@code DGAM1}. \\n* The constant {@code P4} defined in {@code DGAM1}. \\n* The constant {@code P5} defined in {@code DGAM1}. \\n* The constant {@code P6} defined in {@code DGAM1}. \\n* The constant {@code Q1} defined in {@code DGAM1}. \\n* The constant {@code Q2} defined in {@code DGAM1}. \\n* The constant {@code Q3} defined in {@code DGAM1}. \\n* The constant {@code Q4} defined in {@code DGAM1}. \\n* The constant {@code C} defined in {@code DGAM1}. \\n* The constant {@code C0} defined in {@code DGAM1}. \\n* The constant {@code C1} defined in {@code DGAM1}. \\n* The constant {@code C2} defined in {@code DGAM1}. \\n* The constant {@code C3} defined in {@code DGAM1}. \\n* The constant {@code C4} defined in {@code DGAM1}. \\n* The constant {@code C5} defined in {@code DGAM1}. \\n* The constant {@code C6} defined in {@code DGAM1}. \\n* The constant {@code C7} defined in {@code DGAM1}. \\n* The constant {@code C8} defined in {@code DGAM1}. \\n* The constant {@code C9} defined in {@code DGAM1}. \\n* The constant {@code C10} defined in {@code DGAM1}. \\n* The constant {@code C11} defined in {@code DGAM1}. \\n* The constant {@code C12} defined in {@code DGAM1}. \\n* The constant {@code C13} defined in {@code DGAM1}. \\n*\\n     * Default constructor.  Prohibit instantiation.\\n     \\n*\\n     * <p>\\n     * Returns the value of log&nbsp;&Gamma;(x) for x&nbsp;&gt;&nbsp;0.\\n     * </p>\\n     * <p>\\n     * For x &le; 8, the implementation is based on the double precision\\n     * implementation in the <em>NSWC Library of Mathematics Subroutines</em>,\\n     * {@code DGAMLN}. For x &gt; 8, the implementation is based on\\n     * </p>\\n     * <ul>\\n     * <li><a href=\"http://mathworld.wolfram.com/GammaFunction.html\">Gamma\\n     *     Function</a>, equation (28).</li>\\n     * <li><a href=\"http://mathworld.wolfram.com/LanczosApproximation.html\">\\n     *     Lanczos Approximation</a>, equations (1) through (5).</li>\\n     * <li><a href=\"http://my.fit.edu/~gabdo/gamma.txt\">Paul Godfrey, A note on\\n     *     the computation of the convergent Lanczos complex Gamma\\n     *     approximation</a></li>\\n     * </ul>\\n     *\\n     * @param x Argument.\\n     * @return the value of {@code log(Gamma(x))}, {@code Double.NaN} if\\n     * {@code x <= 0.0}.\\n     \\n*\\n     * <p>\\n     * Returns the Lanczos approximation used to compute the gamma function.\\n     * The Lanczos approximation is related to the Gamma function by the\\n     * following equation\\n     * <center>\\n     * {@code gamma(x) = sqrt(2 * pi) / x * (x + g + 0.5) ^ (x + 0.5)\\n     *                   * exp(-x - g - 0.5) * lanczos(x)},\\n     * </center>\\n     * where {@code g} is the Lanczos constant.\\n     * </p>\\n     *\\n     * @param x Argument.\\n     * @return The Lanczos approximation.\\n     * @see <a href=\"http://mathworld.wolfram.com/LanczosApproximation.html\">Lanczos Approximation</a>\\n     * equations (1) through (5), and Paul Godfrey\\'s\\n     * <a href=\"http://my.fit.edu/~gabdo/gamma.txt\">Note on the computation\\n     * of the convergent Lanczos complex Gamma approximation</a>\\n     * @since 3.1\\n     \\n*\\n     * Returns the value of 1 / &Gamma;(1 + x) - 1 for -0&#46;5 &le; x &le;\\n     * 1&#46;5. This implementation is based on the double precision\\n     * implementation in the <em>NSWC Library of Mathematics Subroutines</em>,\\n     * {@code DGAM1}.\\n     *\\n     * @param x Argument.\\n     * @return The value of {@code 1.0 / Gamma(1.0 + x) - 1.0}.\\n     * @throws NumberIsTooSmallException if {@code x < -0.5}\\n     * @throws NumberIsTooLargeException if {@code x > 1.5}\\n     * @since 3.1\\n     \\n*\\n     * Returns the value of log &Gamma;(1 + x) for -0&#46;5 &le; x &le; 1&#46;5.\\n     * This implementation is based on the double precision implementation in\\n     * the <em>NSWC Library of Mathematics Subroutines</em>, {@code DGMLN1}.\\n     *\\n     * @param x Argument.\\n     * @return The value of {@code log(Gamma(1 + x))}.\\n     * @throws NumberIsTooSmallException if {@code x < -0.5}.\\n     * @throws NumberIsTooLargeException if {@code x > 1.5}.\\n     * @since 3.1\\n     \\n*\\n * This class and the other classes in this package were adapted and mainly copied from the\\n * Apache Math package. There were two goals of the adaptation -- to allow double values\\n * (apache just allows integers) and to avoid having to import the entire Apache package\\n * into LIRICAL.\\n \\n*\\n     * Get the mean for the distribution.\\n     *\\n     * @return the mean for the distribution.\\n     \\n* {@inheritDoc} \\n* Archimede\\'s constant PI, ratio of circle circumference to diameter. \\n* 1/2 * log(2 &#960;). \\n* exact Stirling expansion error for certain values. \\n 0.0 \\n 0.5 \\n 1.0 \\n 1.5 \\n 2.0 \\n 2.5 \\n 3.0 \\n 3.5 \\n 4.0 \\n 4.5 \\n 5.0 \\n 5.5 \\n 6.0 \\n 6.5 \\n 7.0 \\n 7.5 \\n 8.0 \\n 8.5 \\n 9.0 \\n 9.5 \\n 10.0 \\n 10.5 \\n 11.0 \\n 11.5 \\n 12.0 \\n 12.5 \\n 13.0 \\n 13.5 \\n 14.0 \\n 14.5 \\n 15.0 \\n*\\n         * Default constructor.\\n         \\n*\\n         * Compute the error of Stirling\\'s series at the given value.\\n         * <p>\\n         * References:\\n         * <ol>\\n         * <li>Eric W. Weisstein. \"Stirling\\'s Series.\" From MathWorld--A Wolfram Web\\n         * Resource. <a target=\"_blank\"\\n         * href=\"http://mathworld.wolfram.com/StirlingsSeries.html\">\\n         * http://mathworld.wolfram.com/StirlingsSeries.html</a></li>\\n         * </ol>\\n         * </p>\\n         *\\n         * @param z the value.\\n         * @return the Striling\\'s series error.\\n         \\n*\\n         * A part of the deviance portion of the saddle point approximation.\\n         * <p>\\n         * References:\\n         * <ol>\\n         * <li>Catherine Loader (2000). \"Fast and Accurate Computation of Binomial\\n         * Probabilities.\". <a target=\"_blank\"\\n         * href=\"http://www.herine.net/stat/papers/dbinom.pdf\">\\n         * http://www.herine.net/stat/papers/dbinom.pdf</a></li>\\n         * </ol>\\n         * </p>\\n         *\\n         * @param x the x value.\\n         * @param mu the average.\\n         * @return a part of the deviance.\\n         \\n*\\n         * Compute the logarithm of the PMF for a binomial distribution\\n         * using the saddle point expansion.\\n         *\\n         * @param x the value at which the probability is evaluated.\\n         * @param n the number of trials.\\n         * @param p the probability of success.\\n         * @param q the probability of failure (1 - p).\\n         * @return log(p(x)).\\n         \\n*\\n * This is a demonstration of the likelihood ratio algorithm that uses simulated cases to assess the performance of the\\n * algorithm.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* key: a disease id such as OMIM:654321; value: coirresponding {@link HpoDisease} object. \\n* Reference to HPO ontology object. \\n* Number of cases to be simulated for any given parameter combination \\n* SHould we exchange the terms with their parents to simulate \"imprecise\" data entry? \\n*\\n     * Perform a grid search with the indicated number of simulated cases. We will simulate from\\n     * one to ten HPO terms with from zero to four \"random\" (noise) terms, and write the results to\\n     * a file that can be input by R.\\n     * @param ontology Reference to the HPO ontology\\n     * @param diseaseMap Map of HPO Disease models\\n     * @param n_cases Number of cases to simulate\\n     * @param imprecision if true, use \"imprecision\" to change HPO terms to a parent term\\n     \\n*\\n     * Perform a grid search over varying numbers of terms and random terms\\n     * both with and without moving the terms to parent terms (imprecision).\\n     * @throws LiricalException upon I/O problems with the annotations\\n     \\n* Directory where various files are downloaded/created. \\n*\\n * This classes simulates cases with and without \"NOT\" annotations and examines the effect of NOT annotations\\n * on differential diagnosis\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* An object representing the Human Phenotype Ontology \\n* An object that calculates the foreground frequency of an HPO term in a disease as well as the background frequency \\n* A list of all HPO term ids in the Phenotypic abnormality subontology. \\n* Key: diseaseID, e.g., OMIM:600321; value: Corresponding HPO disease object. \\n* If true, we exchange each of the non-noise terms with a direct parent except if that would mean going to\\n     * the root of the phenotype ontology.\\n* The proportion of cases at rank 1 in the current simulation \\n* This array will hold the TermIds from the disease map in order -- this will allow us to\\n     * get random indices for the simulations. \\n* Root term id in the phenotypic abnormality subontology. \\n* Number of HPO terms to use for each simulated case. \\n* Number of \"noise\" (unrelated) HPO terms to use for each simulated case. \\n* Number of cases to simulate. \\n*\\n     * The constructor initializes {@link #ontology} and {@link #diseaseMap} and {@link #phenotypeterms}. This\\n     * constructor sets \"imprecision\" to false.\\n     * @param ontology reference to HPO Ontology object\\n     * @param diseaseMap Map containing (usuallu) all diseases in the corpus\\n     \\n*\\n     * Represents a pair of diseases where one disease has a certain HPO term and the\\n     * other disease is explicitly annotated NOT to have that HPO term.\\n     \\n* disease id., e.g., OMIM:600123, of a disease that is annotated to {@link #hpoId} .\\n* disease id., e.g., OMIM:600125, of a disease for which {@link #hpoId} is excluded.\\n* Term id of an HPO term. \\n* @return a non-root random parent of term tid. It could be empty. \\n*\\n     * This is a term that was observed in the simulated patient (note that it should not be a HpoTermId, which\\n     * contains metadata about the term in a disease entity, such as overall frequency. Instead, we are simulating an\\n     * individual patient and this is a definite observation.\\n     * @return a random term from the phenotype subontology.\\n     \\n*\\n     * This creates a simulated, phenotype-only case based on our annotations for the disease\\n     * @param disease Disease for which we will simulate the case\\n     * @return HpoCase object with a randomized selection of phenotypes from the disease\\n     \\n* Various metadata that will be used for the HTML org.monarchinitiative.lirical.output. \\n* Rank of simulated disease \\n* Rank of simulated disease gene (best rank of any disease associated with the correct disease gene). \\n* The posttest probability of the simulated disease. \\n* If true, replace the HPO terms with random terms (both the observed and the included). \\n* A list of all HPO term ids in the Phenotypic abnormality subontology. \\n*\\n     *\\n     * @param phenopacket A GA4GH Phenopacket with information about a case\\n     * @param vcfpath Path to a template VCF file we will add a mutation to\\n     * @param factory {@link LiricalFactory} object\\n     * @param rand if true, randomize the HPO terms in the phenopacket\\n     \\n*\\n     * This is a term that was observed in the simulated patient (note that it should not be a HpoTermId, which\\n     * contains metadata about the term in a disease entity, such as overall frequency. Instead, we are simulating an\\n     * individual patient and this is a definite observation.\\n     * @return a random term from the phenotype subontology.\\n     \\n*\\n     * This method coordinates\\n     \\n* Various metadata that will be used for the HTML org.monarchinitiative.lirical.output. \\n* Rank of simulated disease \\n*\\n * A simulator that simulates cases from the {@link HpoDisease} objects by choosing a subset of terms\\n * and adding noise terms.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* An object representing the Human Phenotype Ontology \\n* An object that calculates the foreground frequency of an HPO term in a disease as well as the background frequency \\n* A list of all HPO term ids in the Phenotypic abnormality subontology. \\n* Key: diseaseID, e.g., OMIM:600321; value: Corresponding HPO disease object. \\n* Number of HPO terms to use for each simulated case. \\n* Number of \"noise\" (unrelated) HPO terms to use for each simulated case. \\n* Number of cases to simulate. \\n* If true, we exchange each of the non-noise terms with a direct parent except if that would mean going to\\n     * the root of the phenotype ontology.\\n* The proportion of cases at rank 1 in the current simulation \\n* This array will hold the TermIds from the disease map in order -- this will allow us to\\n     * get random indices for the simulations. \\n* If true, show lots of results in STDOUT while we are calculating. \\n* Root term id in the phenotypic abnormality subontology. \\n*\\n     * The constructor initializes {@link #ontology} and {@link #diseaseMap} and {@link #phenotypeterms}. This\\n     * constructor sets \"imprecision\" to false.\\n     * @param ontology reference to HPO Ontology object\\n     * @param diseaseMap Map containing (usuallu) all diseases in the corpus\\n     * @param cases_to_simulate Number of individual simulations to perform\\n     * @param terms_per_case Number of HPO terms per case\\n     * @param noise_terms Number of \"noise\" (random, unrelated) terms to add per case\\n     \\n*\\n     * @param ontology reference to HPO Ontology object\\n     * @param diseaseMap Map containing (usuallu) all diseases in the corpus\\n     * @param cases_to_simulate Number of individual simulations to perform\\n     * @param terms_per_case Number of HPO terms per case\\n     * @param noise_terms Number of \"noise\" (random, unrelated) terms to add per case\\n     * @param imprecise Whether or not to use imprecision\\n     \\n* @return the proportion of all simulated cases at rank 1.\\n* This will run simulations according to the parameters {@link #n_cases_to_simulate},\\n     * {@link #n_terms_per_case} and {@link #n_noise_terms}.\\n     * @throws LiricalException if there is an issue running the simulation\\n     \\n*\\n     * This is a term that was observed in the simulated patient (note that it should not be a HpoTermId, which\\n     * contains metadata about the term in a disease entity, such as overall frequency. Instead, we are simulating an\\n     * individual patient and this is a definite observation.\\n     * @return a random term from the phenotype subontology.\\n     \\n* @return a random parent of term tid. \\n* @return a non-root random parent of term tid. It could be empty. \\n*\\n     * This creates a simulated, phenotype-only case based on our annotations for the disease\\n     * @param disease Disease for which we will simulate the case\\n     * @return HpoCase object with a randomized selection of phenotypes from the disease\\n     \\n*\\n * This class creates an SVG file representing the results of likelihood ratio analysis of an HPO case.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* An object representing the Human Phenotype Ontology \\n* This is the object that represents the case being analyzed with all results. \\n* We show the results as an SVG diagram for this disease. \\n* This is the name (label) of the disease. \\n* If applicable, the gene symbol associated with {@link #diseaseCURIE}.\\n* This is the {@link TestResult} object that corresponds to {@link #diseaseCURIE} being displayed as SVG. \\n* Height of entire image in px \\n* width of the bars part of the image in px \\n* additional width of the text part of the image in px \\n* minimum distance to top of image of graphic elements \\n* distance between two adjacent \"boxes\" \\n* The middle line is the central line around which the likelihood ratio \\'bars\\' will be drawn. This\\n     * variable is calculated as the height that this bar will need to have in order to show all of the\\n     * likelihood ratio bars.\\n     \\n*\\n     * Constructor to draw an SVG representation of the phenotype and genotype likelihood ratios\\n     * @param hcase The proband (case) we are analyzing\\n     * @param diseaseId The current differential diagnosis id (e.g., OMIM:600123)\\n     * @param originalDiseaseName  The current differential diagnosis name\\n     * @param ont Reference to HPO ontology\\n     * @param symbol Gene symbol (if any, can be null)\\n     \\n*\\n     * This method shortens items such as #101200 APERT SYNDROME;;ACROCEPHALOSYNDACTYLY, TYPE I; ACS1;;ACS IAPERT-CROUZON DISEASE, INCLUDED;;\\n     * to simply APERT SYNDROME\\n     * @param originalDiseaseName original String from HPO database, derived from OMIM and potentially historic\\n     * @return simplified and prettified name\\n     \\n*\\n     * This function determines the vertical dimension of the SVG that we will org.monarchinitiative.lirical.output.\\n     \\n*\\n     * This method can be used to output the SVG code to any Java Writer. Currently,\\n     * we use this with a StringWriter to include the code in the HTML output (see {@link #getSvgString()}).\\n     * @param writer Handle to a Writer object\\n     * @throws IOException If there is an IO error\\n     \\n*\\n     * Writes a horizontal scale (\"X axis\") with tick points.\\n     * @param writer File handle\\n     * @param maxAmp maximum amplitude of the likelihood ratio on a long10 scale\\n     * @param scaling proportion of width that should be taken up by the scale\\n     * @throws IOException if there is an issue writing the SVG code\\n     \\n* If the LR score is 1, then we draw a diamond around the middle axis. \\n*\\n     * Writes the set of boxes representing the log10 amplitudes of the likelihood ratios for individual\\n     * features.\\n     * @param writer File handle\\n     * @throws IOException if there is an issue writing the SVG code\\n     \\n* The height of the middle line is the number of boxes times (BOX_HEIGHT + BOX_OFFSET)\\n     * plus one additional BOX_OFFSET on top.\\n     * @return Where to place the line underneath the boxes.\\n     \\n*\\n     * Draw the central line around which the likelihood ratio \\'bars\\' will be drawn.\\n     * @param writer file handle\\n     * @throws IOException if we cannot write the SVG file.\\n     \\n*\\n * This class encapsulates data about a variant and its classification as ClinVar pathogenic or likely\\n * pathogenic.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* A set of interpretation classes from ClinVar that we will regard as pathogenic. \\n* The threshold predicted pathogenicity score for being in the pathogenic bin. \\n* Must be either hg19 or hg38 -- we are using this for the UCSC URL. \\n* This is the exomiser-style pathogenicity score: the predicted pathogenicity multiplied by a frequency factor.\\n* This can be set so that we will correctly build the URL to view the location of mutation in UCSC. \\n*\\n     * @return true if the predicted pathogenicity of this variant is above {@link #PATHOGENICITY_THRESHOLD}.\\n     \\n*\\n     * Count the number of pathogenic alleles. If this variant is not in the pathogenic bin, then\\n     * the count is always zero. If the variant is in the pathogenic bin, then the count is 2\\n     * if the variant is homozygous, otherwise the count in 1.\\n     * @return\\n     \\n*\\n     * Count the number of ClinVar-pathogenic alleles. If this variant is not called Pathogenic in ClinVar, then\\n     * the count is always zero. If the variant is ClinVar-pathogenic, then the count is 2\\n     * if the variant is homozygous, otherwise the count in 1.\\n     * @return\\n     \\n*@return chromosome on which this variant is located. Returns a String such as chr1 or chrY \\n* This function sorts variants in descending order of pathogenicity. \\n* @return a string such as NM_000141.4:c.1694A>C:p.(Glu565Ala).\\n*\\n     * This is the frequency factor used for the Exomiser like pathogenicity score. It penalizes variants that have a higher\\n     * population frequency, with anything above 2% getting a factor of zero.\\n     * @return The Exomiser-style frequency factor\\n     \\n*\\n     * This method generates an HTML link to the UCSC genome browser that shows the general neighborhood of this variant\\n     * @return A String with an HTML link to the UCSC Genome browser.\\n     \\n*\\n     * Test calculation of pathogenicity score. This depends on the Exomiser\\n     * frequency score,\\n     * <pre>\\n     * private double frequencyScore() {\\n     *   if (frequency <= 0) {\\n     *     return 1f;\\n     *   } else if (frequency > 2) {\\n     *     return 0f;\\n     *   } else {\\n     *     return 1.13533f - (0.13533f * (float) Math.exp(frequency));\\n     *   }\\n     * }\\n     * In R, which we used to check this, we used: {@code f <- function(x) { 1.13533 - (0.13533 *exp(x))}}\\n     * </pre>\\n     \\n* Test that we can retrieve ClinVar pathogenic variants, and a few other simple getters.\\n*\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* Test frequencies. Also, note that the bin gets precentages as input (0-100)\\n     * but it returns the overall freuqencies (divided by 100).\\n     \\n*\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n*\\n * Test whether we can successfully create HpoCaseOld objects.\\n \\n* Name of the disease we are simulating in this test, i.e., OMIM:108500. \\n parse ontology \\n these are the phenotypic abnormalties of our \"case\" \\n*\\n     * Our test case has\\n     * OMIM:108500\\n     HP:0006855\\n     HP:0000651\\n     HP:0010545\\n     HP:0001260\\n     Thus there are five Hpo annotations.\\n     \\n*\\n * This test class tests the ingest of the BBS1.json (phenotpacket) and BBS1.yml files.\\n * They should provide equivalent information (although the Phenopacket provides richer information)\\n \\n*\\n     * Note that the YAML Parser removes the trailing slash of the exomiser data directory path, if present.\\n     \\n*\\n     * This test is disabled on windows because it depends on the File separator (/ vs \\\\).\\n     \\n*\\n     * In the YAML file, the exomiser path is given as\\n     * exomiser: /home/robinp/data/exomiserdata/1811_hg19.\\n     * Here we test if we can extract the correct mvstore and Jannovar files\\n     * This test is disabled on windows because it depends on the File separator (/ vs \\\\).\\n     \\n*\\n     * The default path for the background frequency is src/main/resources/background/ but it can be\\n     * overrridden in the YAML file\\n     \\n*\\n     * The default path for the background frequency is src/main/resources/background/ but it can be\\n     * overrridden in the YAML file\\n     \\n* example2.yml does not indicate the background frequency and thus isPresent should be false.\\n*\\n     * If we find one variant that is listed as pathogenic in ClinVar, then we return the genotype\\n     * likelihood ratio of 1000 to 1.\\n     \\n*\\n     * If we find two variants listed as pathogenic in ClinVar, then we return the genotype\\n     * likelihood ratio of 1000*1000 to 1.\\n     \\n*\\n     * We want to test what happens with a gene that has lots of variants but a pathogenic variant count sum of zero,\\n     * a lambda-disease of 1, and a lambda-background of 8.7. This numbers are taken from the HLA-B gene.\\n     \\n*\\n     * We want to test what happens with a gene that has lots of variants but a pathogenic variant count sum of zero,\\n     * a lambda-disease of 2, and a lambda-background of 8.7. This numbers are taken from a made-up  gene.\\n     \\n*\\n * Simple test that we get the right frequencies. There are 37 annotations in the file\\n * small.hpoa. Each annotation is unique.\\n \\n*\\n     * $ cut -f 2 small_phenotype.hpoa | sort | uniq | wc -l\\n     3\\n     \\n*\\n     * cut -f 5 small_phenoannot.tab | sort\\n     * shows that there is only one instance of Atrial cardiomyopathy, HP:0200127. The frequency should\\n     * be 1/196 -- there are no frequency modifiers in {@code small_phenoannot.tab}, so we do not need to worry about\\n     * weighting\\n     \\n* HP:0000035 is an ancestor of \"HP:0000028\" (which has an explicit annotation in small_phenotyoe.hpoa),\\n     *  and of \"HP:0000047\" (but both in the same disease), and therefore\\n     * its background frequency should be 1/3\\n     \\n*\\n     * The term HP:0001265 is a phenotype term in the disease 103100. The frequency of term in disease is 1.\\n     \\n*\\n * Some of this test class is based on the data and cases presented in\\n * https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2683447/ (Likelihood ratio calculations)\\n * Note -- the authors of that paper rounded results and this class does not!\\n \\n* Test that the private function prettifyDiseaseName (which is called from the constructor)\\n     * can remove all of the grunge from this long original disease name.\\n     \\n* Test that the leading number is removed from the disease name. \\n* Test that we are correctly setting the flag that is used by the FreeMarker to show variants. \\n*\\n * This is just testing that our adaptation of the Apache math Poisson implemention is working.\\n * The expected values were calculated in R with commands such as {@code dpois(3,2.2)}.\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n*\\n * @author <a href=\"mailto:peter.robinson@jax.org\">Peter Robinson</a>\\n \\n* Test {@link org.monarchinitiative.lirical.vcf.SimpleVariant#isClinVarPathogenic()}  for pathogenic variants. \\n* Test {@link org.monarchinitiative.lirical.vcf.SimpleVariant#isClinVarPathogenic()}  for benign variants. '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df['comments_text'].values\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "org.eclipse.core.resources\n",
      "org.eclipse.jdt.core\n",
      "org.eclipse.jdt.ui\n",
      "org.eclipse.wst.jsdt.core\n",
      "org.eclipse.wst.jsdt.ui\n",
      "org.eclipse.wst.jsdt.ui.super Type\n",
      ".travis\n",
      "Refine with extensions\n",
      "Refine-codetemplates\n",
      "Refine\n",
      "Refine.style\n",
      "LICENSE\n",
      "README\n",
      "com.google.appengine.eclipse.core.project Validator\n",
      "com.google.gdt.eclipse.core.web App Project Validator\n",
      "com.google.appengine.eclipse.core\n",
      "com.google.gdt.eclipse.core\n",
      "appengine-web\n",
      "cron\n",
      "jdoconfig\n",
      "slf4j-jdk14-1.5.6\n",
      "logging\n",
      "module\n",
      "App Engine Client Connection\n",
      "App Engine Client Connection Manager\n",
      "App Engine Refine Broker Impl\n",
      "Refine Broker Tests\n",
      "butterfly\n",
      "modules\n",
      "web\n",
      "je.license\n",
      "bdb-je-4.0.103-sources\n",
      "bdb-je-4.0.103\n",
      "Refine Broker\n",
      "Refine Broker Impl\n",
      "tests\n",
      "tests.log4j\n",
      "build\n",
      "openrefine.l4j\n",
      "pmd.rules\n",
      "Http Utils\n",
      "config\n",
      "controller\n",
      "Cell Blank Node\n",
      "Cell Literal Node\n",
      "Cell Node\n",
      "Cell Resource Node\n",
      "Constant Blank Node\n",
      "Constant Literal Node\n",
      "Constant Resource Node\n",
      "Link\n",
      "Node\n",
      "Prefix\n",
      "Rdf Schema\n",
      "Resource Node\n",
      "Util\n",
      "Application Context\n",
      "Initilization Command\n",
      "Add Prefix Command\n",
      "Add Prefix From File Command\n",
      "Get Default Prefixes Command\n",
      "Preview Rdf Command\n",
      "Preview Rdf Value Expression Command\n",
      "Rdf Command\n",
      "Refresh Prefix Command\n",
      "Remove Prefix Command\n",
      "Save Base URICommand\n",
      "Save Prefixes Command\n",
      "Save Rdf Schema Command\n",
      "Suggest Prefix Uri Command\n",
      "Suggest Term Command\n",
      "Rdf Exporter\n",
      "Rdf Binder\n",
      "Urlify\n",
      "Rdf Expression Util\n",
      "Save Rdf Schema Operation\n",
      "IPredefined Vocabulary Manager\n",
      "IVocabulary Searcher\n",
      "Prefix Exist Exception\n",
      "Prefix Manager\n",
      "RDFNode\n",
      "RDFSClass\n",
      "RDFSProperty\n",
      "Search Result Item\n",
      "Vocabulary\n",
      "Vocabulary Import Exception\n",
      "Vocabulary Importer\n",
      "Vocabulary Index Exception\n",
      "Vocabulary Save Exception\n",
      "Predefined Vocabulary Manager\n",
      "Vocabulary Searcher\n",
      "predefined vocabs\n",
      "prefixes\n",
      "GRefine Service Manager\n",
      "Service Registry\n",
      "Abstract Add Service Command\n",
      "Add Service Command\n",
      "Add Sindice Service\n",
      "Add Stanbol Service Command\n",
      "Initialization Command\n",
      "Initialize Services Command\n",
      "Sindice Guess Type Command\n",
      "Upload File And Add Service Command\n",
      "Abstract Reconciliation Service\n",
      "Reconciliation Candidate\n",
      "Reconciliation Request\n",
      "Reconciliation Request Context\n",
      "Reconciliation Response\n",
      "Reconciliation Service\n",
      "Reconciliation Stanbol Site\n",
      "Rdf Reconciliation Service\n",
      "Plain Sparql Query Endpoint\n",
      "Query Endpoint\n",
      "Query Endpoint Factory\n",
      "Query Endpoint Impl\n",
      "Dump Query Executor\n",
      "Query Executor\n",
      "Remote Query Executor\n",
      "Virtuoso Remote Query Executor\n",
      "Abstract Sparql Query Factory\n",
      "Big Owl Im Sparql Query Factory\n",
      "Jena Text Sparql Query Factory\n",
      "Plain Sparql Query Factory\n",
      "Preview Resource Canned Query\n",
      "Sparql Query Factory\n",
      "Virtuoso Sparql Query Factory\n",
      "preview properties\n",
      "Sindice Broker\n",
      "Sindice Query Endpoint\n",
      "Sindice Reconciliation Candidate\n",
      "Sindice Service\n",
      "GRefine Json Utilities\n",
      "GRefine Json Utilities Impl\n",
      "Rdf Utilities\n",
      "Rdf Utilities Impl\n",
      "Result Set Wrapping Util\n",
      "String Utils\n",
      "Detect File Format Command\n",
      "Ftp Resource\n",
      "Get Fair Data Point Info Command\n",
      "Get Metadata Push Configuration Command\n",
      "Get RDFCommand\n",
      "Language Getter Command\n",
      "Layer Unavailable Exception\n",
      "License Getter Command\n",
      "Post Fair Data To Fair Data Point\n",
      "Push Fair Data To Resource Adapter\n",
      "Resource\n",
      "Virtuoso Resource\n",
      "apache-any23-api-0.8.0\n",
      "apache-any23-core-0.8.0\n",
      "apache-any23-encoding-0.8.0\n",
      "apache-any23-mime-0.8.0\n",
      "apache-mime4j-core-0.7.2\n",
      "apache-mime4j-dom-0.7.2\n",
      "commons-codec-1.6\n",
      "commons-httpclient-3.0.1\n",
      "commons-io-1.3.2\n",
      "commons-io-2.4\n",
      "commons-logging-1.1.1\n",
      "commons-net-3.3\n",
      "fairmetadata4j-0.1-beta\n",
      "guava-r07\n",
      "htmlparser-1.3\n",
      "jackson-core-asl-1.9.5\n",
      "jackson-mapper-asl-1.9.5\n",
      "java-rdfa-0.4.1\n",
      "jcl-over-slf4j-1.6.4\n",
      "jena-arq-2.11.1\n",
      "jena-core-2.11.1\n",
      "jena-iri-1.0.1\n",
      "jena-sdb-1.4.1\n",
      "jena-tdb-1.0.1\n",
      "jena-text-1.0.1\n",
      "log4j-api-2.7\n",
      "log4j-core-2.7\n",
      "lucene-analyzers-common-4.3.1\n",
      "lucene-core-4.3.1\n",
      "lucene-queryparser-4.3.1\n",
      "nekohtml-1.9.14\n",
      "rdf4j-model-2.1.6\n",
      "rdf4j-query-2.1.6\n",
      "rdf4j-repository-api-2.1.6\n",
      "rdf4j-repository-sail-2.1.6\n",
      "rdf4j-rio-api-2.1.6\n",
      "rdf4j-rio-datatypes-2.1.6\n",
      "rdf4j-rio-languages-2.1.6\n",
      "rdf4j-rio-nquads-2.1.6\n",
      "rdf4j-rio-ntriples-2.1.6\n",
      "rdf4j-rio-rdfxml-2.1.6\n",
      "rdf4j-rio-trig-2.1.6\n",
      "rdf4j-rio-turtle-2.1.6\n",
      "rdf4j-sail-api-2.1.6\n",
      "rdf4j-sail-memory-2.1.6\n",
      "rdf4j-util-2.1.6\n",
      "sesame-http-client-2.7.5\n",
      "sesame-http-protocol-2.7.5\n",
      "sesame-model-2.7.5\n",
      "sesame-query-2.7.5\n",
      "sesame-queryalgebra-evaluation-2.7.5\n",
      "sesame-queryalgebra-model-2.7.5\n",
      "sesame-queryparser-api-2.7.5\n",
      "sesame-queryparser-serql-2.7.5\n",
      "sesame-queryparser-sparql-2.7.5\n",
      "sesame-queryresultio-api-2.7.5\n",
      "sesame-queryresultio-sparqlxml-2.7.5\n",
      "sesame-repository-api-2.7.5\n",
      "sesame-repository-sail-2.7.5\n",
      "sesame-repository-sparql-2.7.5\n",
      "sesame-rio-api-2.7.5\n",
      "sesame-rio-datatypes-2.7.5\n",
      "sesame-rio-languages-2.7.5\n",
      "sesame-rio-n3-2.7.5\n",
      "sesame-rio-ntriples-2.7.5\n",
      "sesame-rio-rdfxml-2.7.5\n",
      "sesame-rio-trix-2.7.5\n",
      "sesame-rio-turtle-2.7.5\n",
      "sesame-sail-api-2.7.5\n",
      "sesame-sail-inferencer-2.7.5\n",
      "sesame-sail-memory-2.7.5\n",
      "sesame-sail-nativerdf-2.7.5\n",
      "sesame-util-2.7.5\n",
      "simmetrics jar v1 6 2 d07 02 07\n",
      "slf4j-api-1.7.21\n",
      "slf4j-api-1.7.5\n",
      "slf4j-ext-1.7.21\n",
      "slf4j-simple-1.7.21\n",
      "solr-solrj-4.3.1\n",
      "tika-core-1.4\n",
      "tika-parsers-1.4\n",
      "menu-bar-extensions\n",
      "common\n",
      "angular.min\n",
      "bootstrap\n",
      "jquery.min\n",
      "jquery.slim.min\n",
      "ui-bootstrap-tpls.min\n",
      "ui-bootstrap.min\n",
      "fair Datapoint Post-catalog\n",
      "fair Datapoint Post-dataset\n",
      "fair Datapoint Post-distribution\n",
      "fair Datapoint Post\n",
      "new-prefix-widget\n",
      "rdf-data-table-view\n",
      "rdf-schema-alignment-ui-link\n",
      "rdf-schema-alignment-ui-node\n",
      "rdf-schema-alignment\n",
      "rdf-schema-manage-vocabs-widget\n",
      "rdf-schema-new-prefix-widget\n",
      "rdf-schema-vocabulary-manager\n",
      "rdf-service-dialog\n",
      "sindice-dialog\n",
      "sparql-service-dialog\n",
      "stanbol-service\n",
      "suggestterm.suggest\n",
      "org.eclipse.wst.common.project.facet.core\n",
      "gdata-java-client.LICENSE\n",
      "COPYRIGHT\n",
      "gdata-base-1.0\n",
      "gdata-client-1.0\n",
      "gdata-client-meta-1.0\n",
      "gdata-core-1.0\n",
      "gdata-docs-3.0\n",
      "gdata-docs-meta-3.0\n",
      "gdata-media-1.0\n",
      "gdata-spreadsheet-3.0\n",
      "gdata-spreadsheet-meta-3.0\n",
      "google-api-client-1.20.0\n",
      "google-api-client-servlet-1.20.0\n",
      "google-api-services-drive-v2-rev168-1.20.0\n",
      "google-api-services-fusiontables-v2-rev3-1.20.0\n",
      "google-http-client-1.20.0\n",
      "google-http-client-jackson2-1.20.0\n",
      "google-oauth-client-1.20.0\n",
      "google-oauth-client-servlet-1.20.0\n",
      "httpclient-4.0.1\n",
      "httpcore-4.0.1\n",
      "jackson-core-2.1.3\n",
      "jsr305-1.3.9\n",
      "mail\n",
      "transaction-api-1.1\n",
      "authorize\n",
      "authorized\n",
      "index\n",
      "translation-default\n",
      "translation-en\n",
      "translation-fr\n",
      "translation-it\n",
      "macros\n",
      "gdata-extension\n",
      "gdata-fusion-tables-parsing-panel\n",
      "gdata-parsing-panel\n",
      "gdata-source-ui\n",
      "import-from-gdata-form\n",
      "importing-controller\n",
      "exporters\n",
      "project-injection\n",
      "theme\n",
      "De Authorize Command\n",
      "Fusion Table Handler\n",
      "Fusion Table Importer\n",
      "Fusion Table Serializer\n",
      "GData Extension\n",
      "GData Importer\n",
      "GData Importing Controller\n",
      "Token Cookie\n",
      "Upload Command\n",
      "jython-standalone-2.5.3\n",
      "Jython Evaluable\n",
      "Jython Has Fields Wrapper\n",
      "Jython Object Wrapper\n",
      "Jython Evaluable Test\n",
      "pc-axis-parser-ui\n",
      "PCAxis Importer\n",
      "PCAxis Table Data Reader\n",
      "Sample Util\n",
      "tutorial-1\n",
      "tutorial-10\n",
      "tutorial-11\n",
      "tutorial-2\n",
      "tutorial-3\n",
      "tutorial-4\n",
      "tutorial-5\n",
      "tutorial-6\n",
      "tutorial-7\n",
      "tutorial-8\n",
      "tutorial-9\n",
      "big-check\n",
      "checks-map\n",
      "cop\n",
      "dmg background\n",
      "edit-map\n",
      "open-refine-120px\n",
      "open-refine-128px\n",
      "open-refine-200px\n",
      "open-refine-256px\n",
      "open-refine-512px\n",
      "menu-dropdown\n",
      "path-delimiter\n",
      "row-groups\n",
      "slider-brackets\n",
      "small-checks\n",
      "star-flag-map\n",
      "star\n",
      "apache2.0.LICENSE\n",
      "arithcode.LICENSE\n",
      "chrome frame.LICENSE\n",
      "cos.LICENSE\n",
      "datejs.LICENSE\n",
      "dom4j.LICENSE\n",
      "freebase suggest.LICENSE\n",
      "icu4j.LICENSE\n",
      "imgareaselect.LICENSE\n",
      "jquery.LICENSE\n",
      "jquery.eventstack.LICENSE\n",
      "jquery ui.LICENSE\n",
      "jrdf.LICENSE\n",
      "json.LICENSE\n",
      "jsoup.LICENSE\n",
      "marc4j.LICENSE\n",
      "mockito.LICENSE\n",
      "secondstring.LICENSE\n",
      "sesame.LICENSE\n",
      "simile-ajax.2.3.0.LICENSE\n",
      "simile.LICENSE\n",
      "slf4j.LICENSE\n",
      "Refine Tests\n",
      "manifest\n",
      "build-impl\n",
      "genfiles\n",
      "project\n",
      "Client Side Resource Manager\n",
      "Http Responder\n",
      "Inter Project Model\n",
      "Jsonizable\n",
      "Project Manager\n",
      "Project Metadata\n",
      "Refine Servlet\n",
      "Decorated Value\n",
      "Engine\n",
      "Filtered Records\n",
      "Filtered Rows\n",
      "Record Filter\n",
      "Record Visitor\n",
      "Row Filter\n",
      "Row Visitor\n",
      "Facet\n",
      "List Facet\n",
      "Nominal Facet Choice\n",
      "Range Facet\n",
      "Scatterplot Drawing Row Visitor\n",
      "Scatterplot Facet\n",
      "Text Search Facet\n",
      "Time Range Facet\n",
      "All Rows Record Filter\n",
      "Any Row Record Filter\n",
      "Dual Expressions Number Comparison Row Filter\n",
      "Expression Equal Row Filter\n",
      "Expression Number Comparison Row Filter\n",
      "Expression String Comparison Row Filter\n",
      "Expression Time Comparison Row Filter\n",
      "Conjunctive Filtered Records\n",
      "Conjunctive Filtered Rows\n",
      "Expression Based Row Evaluable\n",
      "Expression Nominal Value Grouper\n",
      "Expression Numeric Value Binner\n",
      "Expression Time Value Binner\n",
      "Filtered Records As Filtered Rows\n",
      "Numeric Bin Index\n",
      "Numeric Bin Record Index\n",
      "Numeric Bin Row Index\n",
      "Row Evaluable\n",
      "Row Visitor As Record Visitor\n",
      "Time Bin Index\n",
      "Time Bin Record Index\n",
      "Time Bin Row Index\n",
      "Clusterer\n",
      "Binning Clusterer\n",
      "Cologne Phonetic Keyer\n",
      "Double Metaphone Keyer\n",
      "Fingerprint Keyer\n",
      "Keyer\n",
      "Metaphone3\n",
      "Metaphone3Keyer\n",
      "Metaphone Keyer\n",
      "NGram Fingerprint Keyer\n",
      "Soundex Keyer\n",
      "k NNClusterer\n",
      "Command\n",
      "Engine Dependent Command\n",
      "Get All Preferences Command\n",
      "Get Preference Command\n",
      "Get Version Command\n",
      "Http Utilities\n",
      "Open Workspace Dir Command\n",
      "Set Preference Command\n",
      "Authorize Command\n",
      "Compute Clusters Command\n",
      "Compute Facets Command\n",
      "Get Scatterplot Command\n",
      "Blank Down Command\n",
      "Edit One Cell Command\n",
      "Fill Down Command\n",
      "Join Multi Value Cells Command\n",
      "Key Value Columnize Command\n",
      "Mass Edit Command\n",
      "Split Multi Value Cells Command\n",
      "Text Transform Command\n",
      "Transpose Columns Into Rows Command\n",
      "Transpose Rows Into Columns Command\n",
      "Add Column By Fetching URLs Command\n",
      "Add Column Command\n",
      "Get Columns Info Command\n",
      "Move Column Command\n",
      "Remove Column Command\n",
      "Rename Column Command\n",
      "Reorder Columns Command\n",
      "Split Column Command\n",
      "Get Expression History Command\n",
      "Get Expression Language Info Command\n",
      "Get Starred Expressions Command\n",
      "Log Expression Command\n",
      "Preview Expression Command\n",
      "Toggle Starred Expression Command\n",
      "Apply Operations Command\n",
      "Cancel Processes Command\n",
      "Get History Command\n",
      "Get Operations Command\n",
      "Get Processes Command\n",
      "Undo Redo Command\n",
      "Cancel Importing Job Command\n",
      "Create Importing Job Command\n",
      "Get Importing Configuration Command\n",
      "Get Importing Job Status Command\n",
      "Importing Controller Command\n",
      "Get Languages Command\n",
      "Load Language Command\n",
      "Create Project Command\n",
      "Delete Project Command\n",
      "Export Project Command\n",
      "Export Rows Command\n",
      "Get Models Command\n",
      "Get Project Metadata Command\n",
      "Import Project Command\n",
      "Rename Project Command\n",
      "Guess Types Of Column Command\n",
      "Recon Clear One Cell Command\n",
      "Recon Clear Similar Cells Command\n",
      "Recon Copy Across Columns Command\n",
      "Recon Discard Judgments Command\n",
      "Recon Judge One Cell Command\n",
      "Recon Judge Similar Cells Command\n",
      "Recon Mark New Topics Command\n",
      "Recon Match Best Candidates Command\n",
      "Recon Match Specific Topic Command\n",
      "Reconcile Command\n",
      "Annotate One Row Command\n",
      "Annotate Rows Command\n",
      "Denormalize Command\n",
      "Get Rows Command\n",
      "Remove Rows Command\n",
      "Reorder Rows Command\n",
      "Get All Project Metadata Command\n",
      "Csv Exporter\n",
      "Customizable Tabular Exporter Utilities\n",
      "Exporter\n",
      "Exporter Registry\n",
      "Html Table Exporter\n",
      "Ods Exporter\n",
      "Stream Exporter\n",
      "Tabular Serializer\n",
      "Templating Exporter\n",
      "Url Exporter\n",
      "Writer Exporter\n",
      "Xls Exporter\n",
      "Binder\n",
      "Cell Tuple\n",
      "Eval Error\n",
      "Evaluable\n",
      "Expression Utils\n",
      "Has Fields\n",
      "Has Fields List\n",
      "Has Fields List Impl\n",
      "Language Specific Parser\n",
      "Meta Parser\n",
      "Parsing Exception\n",
      "Wrapped Cell\n",
      "Wrapped Row\n",
      "Cross\n",
      "Facet Count\n",
      "Get\n",
      "Has Field\n",
      "Jsonize\n",
      "Length\n",
      "Slice\n",
      "To Date\n",
      "To Number\n",
      "To String\n",
      "Type\n",
      "Args To Array\n",
      "Join\n",
      "Reverse\n",
      "Sort\n",
      "Uniques\n",
      "And\n",
      "Not\n",
      "Or\n",
      "Xor\n",
      "Date Part\n",
      "Inc\n",
      "Now\n",
      "Html Attr\n",
      "Html Text\n",
      "Inner Html\n",
      "Own Text\n",
      "Parse Html\n",
      "Select Html\n",
      "ACos\n",
      "ASin\n",
      "ATan\n",
      "ATan2\n",
      "Abs\n",
      "Ceil\n",
      "Combin\n",
      "Cos\n",
      "Cosh\n",
      "Degrees\n",
      "Even\n",
      "Exp\n",
      "Fact\n",
      "Fact N\n",
      "Floor\n",
      "Greatest Common Denominator\n",
      "Least Common Multiple\n",
      "Ln\n",
      "Log\n",
      "Max\n",
      "Min\n",
      "Mod\n",
      "Multinomial\n",
      "Odd\n",
      "Pow\n",
      "Quotient\n",
      "Radians\n",
      "Round\n",
      "Sin\n",
      "Sinh\n",
      "Sum\n",
      "Tan\n",
      "Tanh\n",
      "Chomp\n",
      "Contains\n",
      "Diff\n",
      "Ends With\n",
      "Escape\n",
      "Fingerprint\n",
      "Index Of\n",
      "Last Index Of\n",
      "MD5\n",
      "Match\n",
      "NGram\n",
      "NGram Fingerprint\n",
      "Parse Json\n",
      "Partition\n",
      "Phonetic\n",
      "RPartition\n",
      "Reinterpret\n",
      "Replace\n",
      "Replace Chars\n",
      "SHA1\n",
      "Smart Split\n",
      "Split\n",
      "Split By Char Type\n",
      "Split By Lengths\n",
      "Starts With\n",
      "To Lowercase\n",
      "To Titlecase\n",
      "To Uppercase\n",
      "Trim\n",
      "Unescape\n",
      "Unicode\n",
      "Unicode Type\n",
      "Calendar Parser\n",
      "Calendar Parser Exception\n",
      "Control\n",
      "Control Function Registry\n",
      "Function\n",
      "Parser\n",
      "Scanner\n",
      "Control Call Expr\n",
      "Field Accessor Expr\n",
      "Function Call Expr\n",
      "Literal Expr\n",
      "Operator Call Expr\n",
      "Variable Expr\n",
      "Filter\n",
      "For Each\n",
      "For Each Index\n",
      "For Non Blank\n",
      "For Range\n",
      "If\n",
      "Is Blank\n",
      "Is Error\n",
      "Is Non Blank\n",
      "Is Not Null\n",
      "Is Null\n",
      "Is Numeric\n",
      "Is Test\n",
      "With\n",
      "Change\n",
      "Change Sequence\n",
      "History\n",
      "History Entry\n",
      "History Entry Manager\n",
      "History Process\n",
      "Binary Format Guesser\n",
      "Excel Importer\n",
      "Fixed Width Importer\n",
      "Import Exception\n",
      "Importer Utilities\n",
      "Importing Parser Base\n",
      "Json Importer\n",
      "Line Based Format Guesser\n",
      "Line Based Importer\n",
      "Marc Importer\n",
      "Ods Importer\n",
      "Rdf Triple Importer\n",
      "Rdf Xml Triple Importer\n",
      "Separator Based Importer\n",
      "Tabular Importing Parser Base\n",
      "Text Format Guesser\n",
      "Xml Importer\n",
      "Import Column\n",
      "Import Column Group\n",
      "Import Parameters\n",
      "Import Record\n",
      "Import Vertical\n",
      "Record Element Candidate\n",
      "Tree Import Utilities\n",
      "Tree Importing Parser Base\n",
      "Tree Reader\n",
      "Tree Reader Exception\n",
      "Xml Import Utilities\n",
      "Default Importing Controller\n",
      "Format Guesser\n",
      "Importing Controller\n",
      "Importing Job\n",
      "Importing Manager\n",
      "Importing Parser\n",
      "Importing Utilities\n",
      "Url Rewriter\n",
      "File History Entry Manager\n",
      "File Project Manager\n",
      "Project Metadata Utilities\n",
      "Project Utilities\n",
      "Indenting Layout\n",
      "Abstract Operation\n",
      "Cell\n",
      "Column\n",
      "Column Group\n",
      "Column Model\n",
      "Model Exception\n",
      "Overlay Model\n",
      "Project\n",
      "Recon\n",
      "Recon Candidate\n",
      "Recon Stats\n",
      "Record\n",
      "Record Model\n",
      "Row\n",
      "Cell At Row\n",
      "Cell Change\n",
      "Column Addition Change\n",
      "Column Change\n",
      "Column Move Change\n",
      "Column Removal Change\n",
      "Column Rename Change\n",
      "Column Reorder Change\n",
      "Column Split Change\n",
      "Mass Cell Change\n",
      "Mass Change\n",
      "Mass Recon Change\n",
      "Mass Row Change\n",
      "Mass Row Column Change\n",
      "Recon Change\n",
      "Row Flag Change\n",
      "Row Removal Change\n",
      "Row Reorder Change\n",
      "Row Star Change\n",
      "Recon Config\n",
      "Recon Job\n",
      "Standard Recon Config\n",
      "Authorization Header Signing Strategy\n",
      "Credentials\n",
      "Google Provider\n",
      "OAuth Utilities\n",
      "Provider\n",
      "Engine Dependent Mass Cell Operation\n",
      "Engine Dependent Operation\n",
      "On Error\n",
      "Operation Registry\n",
      "Blank Down Operation\n",
      "Fill Down Operation\n",
      "Key Value Columnize Operation\n",
      "Mass Edit Operation\n",
      "Multi Valued Cell Join Operation\n",
      "Multi Valued Cell Split Operation\n",
      "Text Transform Operation\n",
      "Transpose Columns Into Rows Operation\n",
      "Transpose Rows Into Columns Operation\n",
      "Column Addition By Fetching URLs Operation\n",
      "Column Addition Operation\n",
      "Column Move Operation\n",
      "Column Removal Operation\n",
      "Column Rename Operation\n",
      "Column Reorder Operation\n",
      "Column Split Operation\n",
      "Recon Clear Similar Cells Operation\n",
      "Recon Copy Across Columns Operation\n",
      "Recon Discard Judgments Operation\n",
      "Recon Judge Similar Cells Operation\n",
      "Recon Mark New Topics Operation\n",
      "Recon Match Best Candidates Operation\n",
      "Recon Match Specific Topic Operation\n",
      "Recon Operation\n",
      "Denormalize Operation\n",
      "Row Flag Operation\n",
      "Row Removal Operation\n",
      "Row Reorder Operation\n",
      "Row Star Operation\n",
      "Preference Store\n",
      "Top List\n",
      "Long Running Process\n",
      "Process\n",
      "Process Manager\n",
      "Quick History Entry Process\n",
      "Base Sorter\n",
      "Boolean Criterion\n",
      "Criterion\n",
      "Date Criterion\n",
      "Number Criterion\n",
      "Sorting Record Visitor\n",
      "Sorting Row Visitor\n",
      "String Criterion\n",
      "Dynamic Fragment\n",
      "Fragment\n",
      "Static Fragment\n",
      "Template\n",
      "Cookies Utilities\n",
      "IOUtils\n",
      "Indent Writer\n",
      "JSONUtilities\n",
      "JSObject\n",
      "Parsing Utilities\n",
      "Pool\n",
      "Tracking Input Stream\n",
      "log4j\n",
      "facets\n",
      "initialize\n",
      "Wpi Data\n",
      "birds\n",
      "example-latin1\n",
      "example-linebreaks-in-cells\n",
      "example-utf8\n",
      "food\n",
      "food.small\n",
      "government contracts\n",
      "movies-condensed\n",
      "movies\n",
      "nobel-prize-winners\n",
      "ozone 8hr dmax\n",
      "ozone sites\n",
      "presidents\n",
      "mockito-all-1.9.5-sources\n",
      "testng-6.8-sources\n",
      "mockito-all-1.9.5\n",
      "testng-6.8\n",
      "Transpose Tests\n",
      "History Entry Manager Stub\n",
      "Project Manager Stub\n",
      "Project Manager Tests\n",
      "Refine Servlet Stub\n",
      "Refine Servlet Tests\n",
      "Refine Test\n",
      "Keyer Tests\n",
      "Command Stub\n",
      "Command Tests\n",
      "Cancel Processes Command Tests\n",
      "Csv Exporter Tests\n",
      "Html Exporter Tests\n",
      "Templating Exporter Tests\n",
      "Tsv Exporter Tests\n",
      "Xls Exporter Tests\n",
      "Function Tests\n",
      "Boolean Tests\n",
      "Diff Tests\n",
      "Fingerprint Tests\n",
      "String Case Tests\n",
      "To From Conversion Tests\n",
      "Trim Tests\n",
      "Grel Tests\n",
      "History Tests\n",
      "Excel Importer Tests\n",
      "Fixed Width Importer Tests\n",
      "Importer Test\n",
      "Importer Utilities Tests\n",
      "Json Importer Tests\n",
      "Rdf Triple Importer Tests\n",
      "Tsv Csv Importer Tests\n",
      "Xml Import Utilities Stub\n",
      "Xml Import Utilities Tests\n",
      "Xml Importer Tests\n",
      "excel95\n",
      "Cache Tests\n",
      "Project Stub\n",
      "Recon Tests\n",
      "Row Tests\n",
      "Mass Change Tests\n",
      "Parsing Utilities Tests\n",
      "Test Utils\n",
      "ant-tools-1.8.0-sources\n",
      "arithcode-1.1-sources\n",
      "butterfly-1.0.1-sources\n",
      "commons-codec-1.6-sources\n",
      "commons-fileupload-1.2.1-sources\n",
      "commons-lang-2.5-sources\n",
      "httpclient-4.2.5-sources\n",
      "httpcore-4.2.4-sources\n",
      "icu4j-4.2.1-sources\n",
      "jackson-src-1.9.9\n",
      "jcl-over-slf4j-1.5.6-sources\n",
      "jrdf-0.5.6-sources\n",
      "json-20100208-sources\n",
      "jsoup-1.4.1-sources\n",
      "log4j-1.2.15-sources\n",
      "odfdom-java-0.8.7-sources\n",
      "opencsv-2.4-SNAPSHOT-sources\n",
      "json-20100208\n",
      "secondstring-20100303-sources\n",
      "signpost-commonshttp4-1.2.1.2-sources\n",
      "signpost-core-1.2.1.2-sources\n",
      "slf4j-api-1.5.6-sources\n",
      "slf4j-log4j12-1.5.6-sources\n",
      "vicino-1.1-sources\n",
      "ant-tools-1.8.0\n",
      "arithcode-1.1\n",
      "butterfly-1.0.1\n",
      "clojure-1.5.1-slim\n",
      "commons-collections-3.2.1\n",
      "commons-fileupload-1.2.1\n",
      "commons-io-1.4\n",
      "commons-lang-2.5\n",
      "dom4j-1.6.1\n",
      "fluent-hc-4.2.5\n",
      "guava-13.0\n",
      "httpclient-4.2.5\n",
      "httpcore-4.2.4\n",
      "httpmime-4.2.5\n",
      "icu4j-4.2.1\n",
      "jackson-core-asl-1.9.12\n",
      "jcl-over-slf4j-1.5.6\n",
      "jrdf-0.5.6\n",
      "jsoup-1.4.1\n",
      "lessen-trunk-r8\n",
      "log4j-1.2.15\n",
      "marc4j-2.4\n",
      "odfdom-java-0.8.7\n",
      "opencsv-2.4-SNAPSHOT\n",
      "poi-3.13-20150929\n",
      "poi-ooxml-3.13-20150929\n",
      "poi-ooxml-schemas-3.13-20150929\n",
      "resolver\n",
      "rhino-1.7R2\n",
      "secondstring-20100303\n",
      "serializer\n",
      "signpost-commonshttp4-1.2.1.2\n",
      "signpost-core-1.2.1.2\n",
      "slf4j-api-1.5.6\n",
      "slf4j-log4j12-1.5.6\n",
      "velocity-1.5\n",
      "vicino-1.1\n",
      "xerces Impl-2.11.0.SP5\n",
      "xmlbeans-2.3.0\n",
      "velocity\n",
      "about\n",
      "error\n",
      "date\n",
      "imgareaselect-default\n",
      "jquery.imgareaselect\n",
      "jquery-1.11.1\n",
      "jquery-1.9.1\n",
      "jquery-migrate-1.2.1\n",
      "jquery-migrate-1.2.1.min\n",
      "animated-overlay\n",
      "ui-bg diagonals-thick 18 b81900 40x40\n",
      "ui-bg diagonals-thick 20 666666 40x40\n",
      "ui-bg flat 10 000000 40x100\n",
      "ui-bg glass 100 f6f6f6 1x400\n",
      "ui-bg glass 100 fdf5ce 1x400\n",
      "ui-bg glass 65 ffffff 1x400\n",
      "ui-bg gloss-wave 35 f6a828 500x100\n",
      "ui-bg highlight-soft 100 eeeeee 1x100\n",
      "ui-bg highlight-soft 75 ffe45c 1x100\n",
      "ui-icons 222222 256x240\n",
      "ui-icons 228ef1 256x240\n",
      "ui-icons ef8c08 256x240\n",
      "ui-icons ffd27a 256x240\n",
      "ui-icons ffffff 256x240\n",
      "jquery-ui-1.10.3.custom\n",
      "jquery-ui-1.10.3.custom.min\n",
      "jquery.cookie\n",
      "jquery.i18n\n",
      "suggest-4 3\n",
      "suggest-4 3.min\n",
      "underscore-min\n",
      "arrow-end\n",
      "arrow-start\n",
      "close-map\n",
      "close\n",
      "collapsed\n",
      "down-arrow\n",
      "expanded\n",
      "facet-resize-handle\n",
      "logo-gem-150\n",
      "logo-gem-40\n",
      "logo-openrefine-30\n",
      "logo-openrefine-40\n",
      "large-spinner\n",
      "logo-gem-150.png\n",
      "logo-gem-40.png\n",
      "logo-openrefine-30.png\n",
      "logo-openrefine-40.png\n",
      "menu-opener\n",
      "right-arrow\n",
      "scatterplot-icons\n",
      "slider-handle\n",
      "small-spinner\n",
      "up-arrow\n",
      "translation-es\n",
      "translation-jp\n",
      "translation-zh\n",
      "preferences\n",
      "clustering-dialog\n",
      "column-reordering-dialog\n",
      "custom-tabular-exporter-dialog\n",
      "expression-preview-dialog\n",
      "scatterplot-dialog\n",
      "templating-exporter-dialog\n",
      "list-facet\n",
      "range-facet\n",
      "scatterplot-facet\n",
      "text-search-facet\n",
      "timerange-facet\n",
      "create-project-error-panel\n",
      "create-project-progress-panel\n",
      "create-project-ui-source-selection\n",
      "create-project-ui\n",
      "file-selection-panel\n",
      "parsing-panel\n",
      "import-from-clipboard-form\n",
      "import-from-computer-form\n",
      "import-from-web-form\n",
      "sources\n",
      "import-project-ui\n",
      "lang-settings-ui\n",
      "open-project-ui\n",
      "excel-parser-ui\n",
      "fixed-width-parser-ui\n",
      "json-parser-select-ui\n",
      "json-parser-ui\n",
      "line-based-parser-ui\n",
      "preview-table\n",
      "rdf-triples-parser-ui\n",
      "separator-based-parser-ui\n",
      "xml-parser-select-ui\n",
      "xml-parser-ui\n",
      "select-encoding-dialog\n",
      "browsing-engine\n",
      "extension-bar\n",
      "history-apply-dialog\n",
      "history-entry\n",
      "history-extract-dialog\n",
      "history-panel\n",
      "process-panel\n",
      "progress-panel\n",
      "scripting\n",
      "summary-bar\n",
      "add-namespaced-service-dialog\n",
      "add-standard-service-dialog\n",
      "freebase-query-panel\n",
      "recon-dialog\n",
      "recon-manager\n",
      "standard-service-panel\n",
      "ajax\n",
      "custom-suggest\n",
      "date-time\n",
      "dialog\n",
      "dom\n",
      "encoding\n",
      "menu\n",
      "misc\n",
      "sign\n",
      "string\n",
      "url\n",
      "add-column-by-fetching-urls-dialog\n",
      "add-column-dialog\n",
      "cell-editor\n",
      "cell-recon-preview-popup-header\n",
      "cell-recon-search-for-match\n",
      "cell-ui\n",
      "column-header-ui\n",
      "column-header\n",
      "copy-recon-across-columns-dialog\n",
      "data-table-view\n",
      "key-value-columnize\n",
      "menu-edit-cells\n",
      "menu-edit-column\n",
      "menu-facets\n",
      "menu-reconcile\n",
      "sorting-criterion-dialog\n",
      "split-column-dialog\n",
      "text-transform-dialog\n",
      "transpose-columns-into-rows\n",
      "histogram-widget\n",
      "slider-widget\n",
      "default-importing-controller\n",
      "default-importing-file-selection-panel\n",
      "default-importing-parsing-panel\n",
      "default-importing-sources\n",
      "jquery-ui-overrides\n",
      "process\n",
      "sidebar\n",
      "pure\n",
      "metadata-form\n",
      "Thumbs\n",
      "add\n",
      "configure\n",
      "delete\n",
      "import\n",
      "information\n",
      "no\n",
      "question Mark Icon\n",
      "question Mark Icon2\n",
      "refresh\n",
      "spinner\n",
      "stanbol\n",
      "yes\n",
      "jquery.form\n",
      "flyout\n",
      "main\n",
      "rdf-reconcile-service\n",
      "rdf-schema-alignment-dialog\n",
      "HISTORY\n",
      "package\n",
      "after-test\n",
      "readme\n",
      "beep\n",
      "multi line\n",
      "non unicode\n",
      "slice-buffer\n",
      "errors\n",
      "reader\n",
      "types\n",
      "writer\n",
      "reader.test\n",
      "writer.test\n",
      "CHANGES\n",
      "assert\n",
      "CHANGELOG\n",
      "apply\n",
      "apply Each\n",
      "apply Each Series\n",
      "asyncify\n",
      "auto\n",
      "auto Inject\n",
      "bower\n",
      "cargo\n",
      "compose\n",
      "concat\n",
      "concat Series\n",
      "constant\n",
      "detect\n",
      "detect Limit\n",
      "detect Series\n",
      "dir\n",
      "do During\n",
      "do Until\n",
      "do Whilst\n",
      "during\n",
      "each\n",
      "each Limit\n",
      "each Of\n",
      "each Of Limit\n",
      "each Of Series\n",
      "each Series\n",
      "ensure Async\n",
      "every\n",
      "every Limit\n",
      "every Series\n",
      "filter\n",
      "filter Limit\n",
      "filter Series\n",
      "forever\n",
      "Doubly Linked List\n",
      "break Loop\n",
      "console Func\n",
      "create Tester\n",
      "do Limit\n",
      "do Parallel\n",
      "do Parallel Limit\n",
      "do Series\n",
      "find Get Result\n",
      "get Iterator\n",
      "initial Params\n",
      "iterator\n",
      "map\n",
      "not Id\n",
      "once\n",
      "only Once\n",
      "parallel\n",
      "queue\n",
      "reject\n",
      "rest\n",
      "set Immediate\n",
      "without Index\n",
      "log\n",
      "map Limit\n",
      "map Series\n",
      "map Values\n",
      "map Values Limit\n",
      "map Values Series\n",
      "memoize\n",
      "next Tick\n",
      "parallel Limit\n",
      "priority Queue\n",
      "race\n",
      "reduce\n",
      "reduce Right\n",
      "reflect\n",
      "reflect All\n",
      "reject Limit\n",
      "reject Series\n",
      "retry\n",
      "retryable\n",
      "seq\n",
      "series\n",
      "some\n",
      "some Limit\n",
      "some Series\n",
      "sort By\n",
      "timeout\n",
      "times\n",
      "times Limit\n",
      "times Series\n",
      "transform\n",
      "unmemoize\n",
      "until\n",
      "waterfall\n",
      "whilst\n",
      "bench\n",
      "abort\n",
      "async\n",
      "defer\n",
      "iterate\n",
      "readable asynckit\n",
      "readable parallel\n",
      "readable serial\n",
      "readable serial ordered\n",
      "state\n",
      "streamify\n",
      "terminator\n",
      "serial\n",
      "serial Ordered\n",
      "stream\n",
      "aws4\n",
      "lru\n",
      "Readme\n",
      "component\n",
      "base64-arraybuffer\n",
      "base64id\n",
      "example\n",
      "binary-extensions\n",
      "bl\n",
      "test\n",
      ".zuul\n",
      "changelog\n",
      "bluebird.core\n",
      "bluebird.core.min\n",
      "bluebird\n",
      "bluebird.min\n",
      "any\n",
      "bind\n",
      "call get\n",
      "cancel\n",
      "catch filter\n",
      "context\n",
      "debuggability\n",
      "direct resolve\n",
      "es5\n",
      "finally\n",
      "generators\n",
      "join\n",
      "method\n",
      "nodeback\n",
      "nodeify\n",
      "promise\n",
      "promise array\n",
      "promisify\n",
      "props\n",
      "schedule\n",
      "settle\n",
      "synchronous inspection\n",
      "thenables\n",
      "timers\n",
      "using\n",
      "util\n",
      "read\n",
      "json\n",
      "raw\n",
      "text\n",
      "urlencoded\n",
      ".coveralls\n",
      "karma.conf\n",
      "node\n",
      "browser\n",
      "debug\n",
      ".jscs\n",
      "formats\n",
      "parse\n",
      "stringify\n",
      "utils\n",
      "CONTRIBUTING\n",
      "boom\n",
      "clean\n",
      "list\n",
      "help\n",
      "home\n",
      "info\n",
      "init\n",
      "install\n",
      "link\n",
      "login\n",
      "lookup\n",
      "prune\n",
      "register\n",
      "search\n",
      "uninstall\n",
      "unregister\n",
      "update\n",
      "version\n",
      "Manager\n",
      "Package Repository\n",
      "Resolve Cache\n",
      "resolver Factory\n",
      "Fs Resolver\n",
      "Git Fs Resolver\n",
      "Git Hub Resolver\n",
      "Git Remote Resolver\n",
      "Git Resolver\n",
      "Resolver\n",
      "Svn Resolver\n",
      "Url Resolver\n",
      "plugin Resolver Factory\n",
      "scripts\n",
      "abbrev\n",
      "amdefine\n",
      "intercept\n",
      "ansicolors\n",
      "holes\n",
      "sum\n",
      "buf\n",
      "vars\n",
      "loop\n",
      "small\n",
      "bu\n",
      "deferred\n",
      "dots\n",
      "eof\n",
      "flush\n",
      "from buffer\n",
      "get buffer\n",
      "immediate\n",
      "interval\n",
      "into buffer\n",
      "into stream\n",
      "loop scan\n",
      "lu\n",
      "negbs\n",
      "negls\n",
      "nested\n",
      "not enough buf\n",
      "not enough parse\n",
      "peek\n",
      "pipe\n",
      "posbs\n",
      "posls\n",
      "scan\n",
      "scan buf\n",
      "scan buf null\n",
      "skip\n",
      "split\n",
      "2015-01-30\n",
      "duplex\n",
      " stream duplex\n",
      " stream passthrough\n",
      " stream readable\n",
      " stream transform\n",
      " stream writable\n",
      "passthrough\n",
      "readable\n",
      "writable\n",
      "Config\n",
      "defaults\n",
      "expand\n",
      "paths\n",
      "proxy\n",
      "rc\n",
      "array\n",
      "append\n",
      "collect\n",
      "combine\n",
      "compact\n",
      "contains\n",
      "difference\n",
      "equals\n",
      "find\n",
      "find Index\n",
      "find Last\n",
      "find Last Index\n",
      "flatten\n",
      "for Each\n",
      "group By\n",
      "index Of\n",
      "indices Of\n",
      "insert\n",
      "intersection\n",
      "invoke\n",
      "last\n",
      "last Index Of\n",
      "max\n",
      "min\n",
      "pick\n",
      "pluck\n",
      "range\n",
      "remove\n",
      "remove All\n",
      "reverse\n",
      "shuffle\n",
      "slice\n",
      "sort\n",
      "take\n",
      "to Lookup\n",
      "union\n",
      "unique\n",
      "xor\n",
      "zip\n",
      "collection\n",
      "make \n",
      "size\n",
      "day Of The Year\n",
      "diff\n",
      "de-DE\n",
      "en-US\n",
      "pt-BR\n",
      "i18n \n",
      "is Leap Year\n",
      "is Same\n",
      "parse Iso\n",
      "quarter\n",
      "start Of\n",
      "strftime\n",
      "timezone Abbr\n",
      "timezone Offset\n",
      "total Days In Month\n",
      "total Days In Year\n",
      "week Of The Year\n",
      "function\n",
      "lang\n",
      "math\n",
      "number\n",
      "object\n",
      "query String\n",
      "random\n",
      "time\n",
      "after\n",
      "await Delay\n",
      "debounce\n",
      "func\n",
      "identity\n",
      "make Iterator \n",
      "partial\n",
      "prop\n",
      "throttle\n",
      "wrap\n",
      "GLOBAL\n",
      "clone\n",
      "create Object\n",
      "ctor Apply\n",
      "deep Clone\n",
      "deep Equals\n",
      "inherit Prototype\n",
      "is\n",
      "is Arguments\n",
      "is Array\n",
      "is Boolean\n",
      "is Date\n",
      "is Empty\n",
      "is Finite\n",
      "is Function\n",
      "is Integer\n",
      "is Kind\n",
      "is Na N\n",
      "is Null\n",
      "is Number\n",
      "is Object\n",
      "is Plain Object\n",
      "is Primitive\n",
      "is Reg Exp\n",
      "is String\n",
      "is Undefined\n",
      "isnt\n",
      "kind Of\n",
      "to Array\n",
      "to Number\n",
      "to String\n",
      "ceil\n",
      "clamp\n",
      "count Steps\n",
      "floor\n",
      "in Range\n",
      "is Near\n",
      "lerp\n",
      "norm\n",
      "overflow\n",
      "round\n",
      "MAX INT\n",
      "MAX SAFE INTEGER\n",
      "MAX UINT\n",
      "MIN INT\n",
      "abbreviate\n",
      "currency Format\n",
      "enforce Precision\n",
      "nth\n",
      "ordinal\n",
      "pad\n",
      "rol\n",
      "ror\n",
      "to Int\n",
      "to UInt\n",
      "to UInt31\n",
      "bind All\n",
      "deep Fill In\n",
      "deep Matches\n",
      "deep Mix In\n",
      "fill In\n",
      "for In\n",
      "for Own\n",
      "functions\n",
      "get\n",
      "has\n",
      "has Own\n",
      "keys\n",
      "matches\n",
      "merge\n",
      "mix In\n",
      "namespace\n",
      "omit\n",
      "result\n",
      "set\n",
      "unset\n",
      "values\n",
      "decode\n",
      "encode\n",
      "get Param\n",
      "get Query\n",
      "set Param\n",
      "choice\n",
      "guid\n",
      "rand\n",
      "rand Bit\n",
      "rand Bool\n",
      "rand Hex\n",
      "rand Int\n",
      "rand Sign\n",
      "rand String\n",
      "WHITE SPACES\n",
      "camel Case\n",
      "crop\n",
      "ends With\n",
      "escape Html\n",
      "escape Reg Exp\n",
      "escape Unicode\n",
      "hyphenate\n",
      "interpolate\n",
      "lower Case\n",
      "lpad\n",
      "ltrim\n",
      "make Path\n",
      "normalize Line Breaks\n",
      "pascal Case\n",
      "proper Case\n",
      "remove Non ASCII\n",
      "remove Non Word\n",
      "repeat\n",
      "replace\n",
      "replace Accents\n",
      "rpad\n",
      "rtrim\n",
      "sentence Case\n",
      "slugify\n",
      "starts With\n",
      "strip Html Tags\n",
      "trim\n",
      "truncate\n",
      "typecast\n",
      "un Camel Case\n",
      "underscore\n",
      "unescape Html\n",
      "unescape Unicode\n",
      "unhyphenate\n",
      "upper Case\n",
      "convert\n",
      "now\n",
      "parse Ms\n",
      "to Time String\n",
      "create Error\n",
      "is Asset\n",
      "is Component\n",
      "Logger\n",
      "Client\n",
      "Cache\n",
      "md5\n",
      "pow\n",
      "chmod\n",
      "clobber\n",
      "mkdirp\n",
      "perm\n",
      "perm sync\n",
      "rel\n",
      "return\n",
      "return sync\n",
      "root\n",
      "sync\n",
      "umask\n",
      "umask sync\n",
      "border-characters\n",
      "license\n",
      "splice\n",
      "buffers\n",
      "builtin-modules\n",
      "static\n",
      "cdl\n",
      "cardinal\n",
      "highlight-json\n",
      "highlight-self-hide-semicolons\n",
      "highlight-self\n",
      "highlight-string\n",
      "highlight\n",
      "highlight File\n",
      "highlight File Sync\n",
      "settings\n",
      "cardinal-highlight-block-comment\n",
      "cardinal-highlight-diff-spike\n",
      "cardinal-highlight-file-async\n",
      "cardinal-highlight-file-sync\n",
      "cardinal-highlight-git-diff\n",
      "cardinal-highlight-json-file-async\n",
      "cardinal-highlight-json-file-sync\n",
      "cardinal-highlight-json\n",
      "cardinal-highlight-string\n",
      "cardinal-smoke\n",
      "block-comment\n",
      "custom\n",
      "foo-with-errors\n",
      "foo\n",
      "git-diff\n",
      "svn-diff\n",
      "themes\n",
      "default\n",
      "empty\n",
      "hide-semicolons\n",
      "tomorrow-night\n",
      "utl\n",
      "add do\n",
      "prompt\n",
      "chainsaw\n",
      "chmodr\n",
      "coverage\n",
      "base\n",
      "index.js\n",
      "prettify\n",
      "sort-arrow-sprite\n",
      "sorter\n",
      "lcov\n",
      "center\n",
      "meat\n",
      "break\n",
      "idleness\n",
      "cliui\n",
      "combined stream\n",
      "float\n",
      "core\n",
      "dashdash.bash completion\n",
      "dashdash\n",
      "decompress-zip\n",
      "extractors\n",
      "file-details\n",
      "signatures\n",
      "structures\n",
      "deep-extend\n",
      "delayed stream\n",
      "ec\n",
      "sec\n",
      ".verbrc\n",
      "index-of\n",
      "last-index-of\n",
      "re-exec\n",
      "re-search\n",
      "re-test\n",
      "substr\n",
      "substring\n",
      "while\n",
      "lorem1\n",
      "lorem2\n",
      "esparse\n",
      "esvalidate\n",
      "esprima\n",
      "compat\n",
      "run\n",
      "runner\n",
      "ext-list\n",
      "cli\n",
      "Makefile\n",
      "simple\n",
      "jsl.node\n",
      "extsprintf\n",
      "findup-sync\n",
      "glob\n",
      "form data\n",
      "populate\n",
      "basic\n",
      "chown\n",
      "rename-fail\n",
      "slow-close\n",
      "toolong\n",
      "old\n",
      "ignore\n",
      "filter-pipe\n",
      "symlink-write\n",
      "fstream\n",
      "abstract\n",
      "dir-reader\n",
      "dir-writer\n",
      "file-reader\n",
      "file-writer\n",
      "get-type\n",
      "link-reader\n",
      "link-writer\n",
      "proxy-reader\n",
      "proxy-writer\n",
      "socket-reader\n",
      "routes\n",
      "authorization\n",
      "authorization Test\n",
      "events\n",
      "events Test\n",
      "gists\n",
      "gists Test\n",
      "gitdata\n",
      "gitdata Test\n",
      "gitignore\n",
      "gitignore Test\n",
      "issues\n",
      "issues Test\n",
      "markdown\n",
      "markdown Test\n",
      "misc Test\n",
      "orgs\n",
      "orgs Test\n",
      "pull Requests\n",
      "pull Requests Test\n",
      "releases\n",
      "releases Test\n",
      "repos\n",
      "repos Test\n",
      "search Test\n",
      "statuses\n",
      "statuses Test\n",
      "user\n",
      "user Test\n",
      "generate\n",
      "seed\n",
      "after request.js\n",
      "handler.js\n",
      "section.js\n",
      "test handler.js\n",
      "test section.js\n",
      "client test\n",
      "oauth\n",
      "oauth server\n",
      "minimatch\n",
      "fs\n",
      "graceful-fs\n",
      "legacy-streams\n",
      "polyfills\n",
      ".istanbul\n",
      "FAQ\n",
      "compiler-api\n",
      "decorators-api\n",
      "handlebars\n",
      "handlebars.runtime\n",
      "ast\n",
      "code-gen\n",
      "compiler\n",
      "helpers\n",
      "javascript-compiler\n",
      "parser\n",
      "printer\n",
      "visitor\n",
      "whitespace-control\n",
      "decorators\n",
      "inline\n",
      "exception\n",
      "block-helper-missing\n",
      "helper-missing\n",
      "if\n",
      "with\n",
      "logger\n",
      "no-conflict\n",
      "runtime\n",
      "safe-string\n",
      "precompiler\n",
      "release-notes\n",
      "cache\n",
      "cache Entry\n",
      "content\n",
      "cookie\n",
      "creator\n",
      "entry\n",
      "har\n",
      "page\n",
      "page Timings\n",
      "post Data\n",
      "record\n",
      "request\n",
      "response\n",
      "timings\n",
      "usage\n",
      "hawk\n",
      "logo\n",
      "client\n",
      "crypto\n",
      "server\n",
      "uri\n",
      "hoek\n",
      "escape\n",
      "escaper\n",
      "test1\n",
      "test2\n",
      "test3\n",
      "git-host-info\n",
      "git-host\n",
      ".dir-locals\n",
      "http signing\n",
      "signer\n",
      "verify\n",
      "mocha\n",
      "imurmurhash\n",
      "imurmurhash.min\n",
      "http\n",
      "https\n",
      "inflight\n",
      "inherits\n",
      "inherits browser\n",
      "ini\n",
      "inquirer\n",
      "choices\n",
      "separator\n",
      "checkbox\n",
      "confirm\n",
      "input\n",
      "password\n",
      "rawlist\n",
      "base UI\n",
      "bottom-bar\n",
      "paginator\n",
      "readline\n",
      "screen-manager\n",
      "chunk\n",
      "drop\n",
      "drop Right\n",
      "drop Right While\n",
      "drop While\n",
      "fill\n",
      "first\n",
      "flatten Deep\n",
      "head\n",
      "initial\n",
      "pull\n",
      "pull At\n",
      "sorted Index\n",
      "sorted Last Index\n",
      "tail\n",
      "take Right\n",
      "take Right While\n",
      "take While\n",
      "uniq\n",
      "unzip\n",
      "unzip With\n",
      "without\n",
      "zip Object\n",
      "zip With\n",
      "chain\n",
      "commit\n",
      "lodash\n",
      "plant\n",
      "tap\n",
      "thru\n",
      "to JSON\n",
      "value\n",
      "value Of\n",
      "wrapper Chain\n",
      "wrapper Commit\n",
      "wrapper Concat\n",
      "wrapper Plant\n",
      "wrapper Reverse\n",
      "wrapper To String\n",
      "wrapper Value\n",
      "all\n",
      "at\n",
      "count By\n",
      "each Right\n",
      "find Where\n",
      "foldl\n",
      "foldr\n",
      "for Each Right\n",
      "include\n",
      "includes\n",
      "index By\n",
      "inject\n",
      "partition\n",
      "sample\n",
      "select\n",
      "sort By All\n",
      "sort By Order\n",
      "where\n",
      "ary\n",
      "backflow\n",
      "before\n",
      "bind Key\n",
      "curry\n",
      "curry Right\n",
      "delay\n",
      "flow\n",
      "flow Right\n",
      "mod Args\n",
      "negate\n",
      "partial Right\n",
      "rearg\n",
      "rest Param\n",
      "spread\n",
      "Lazy Wrapper\n",
      "Lodash Wrapper\n",
      "Map Cache\n",
      "Set Cache\n",
      "array Concat\n",
      "array Copy\n",
      "array Each\n",
      "array Each Right\n",
      "array Every\n",
      "array Extremum\n",
      "array Filter\n",
      "array Map\n",
      "array Push\n",
      "array Reduce\n",
      "array Reduce Right\n",
      "array Some\n",
      "array Sum\n",
      "assign Defaults\n",
      "assign Own Defaults\n",
      "assign With\n",
      "base Assign\n",
      "base At\n",
      "base Callback\n",
      "base Clone\n",
      "base Compare Ascending\n",
      "base Copy\n",
      "base Create\n",
      "base Delay\n",
      "base Difference\n",
      "base Each\n",
      "base Each Right\n",
      "base Every\n",
      "base Extremum\n",
      "base Fill\n",
      "base Filter\n",
      "base Find\n",
      "base Find Index\n",
      "base Flatten\n",
      "base For\n",
      "base For In\n",
      "base For Own\n",
      "base For Own Right\n",
      "base For Right\n",
      "base Functions\n",
      "base Get\n",
      "base Index Of\n",
      "base Is Equal\n",
      "base Is Equal Deep\n",
      "base Is Function\n",
      "base Is Match\n",
      "base Lodash\n",
      "base Map\n",
      "base Matches\n",
      "base Matches Property\n",
      "base Merge\n",
      "base Merge Deep\n",
      "base Property\n",
      "base Property Deep\n",
      "base Pull At\n",
      "base Random\n",
      "base Reduce\n",
      "base Set Data\n",
      "base Slice\n",
      "base Some\n",
      "base Sort By\n",
      "base Sort By Order\n",
      "base Sum\n",
      "base To String\n",
      "base Uniq\n",
      "base Values\n",
      "base While\n",
      "base Wrapper Value\n",
      "binary Index\n",
      "binary Index By\n",
      "bind Callback\n",
      "buffer Clone\n",
      "cache Index Of\n",
      "cache Push\n",
      "chars Left Index\n",
      "chars Right Index\n",
      "compare Ascending\n",
      "compare Multiple\n",
      "compose Args\n",
      "compose Args Right\n",
      "create Aggregator\n",
      "create Assigner\n",
      "create Base Each\n",
      "create Base For\n",
      "create Bind Wrapper\n",
      "create Cache\n",
      "create Compounder\n",
      "create Ctor Wrapper\n",
      "create Curry\n",
      "create Defaults\n",
      "create Extremum\n",
      "create Find\n",
      "create Find Index\n",
      "create Find Key\n",
      "create Flow\n",
      "create For Each\n",
      "create For In\n",
      "create For Own\n",
      "create Hybrid Wrapper\n",
      "create Object Mapper\n",
      "create Pad Dir\n",
      "create Padding\n",
      "create Partial\n",
      "create Partial Wrapper\n",
      "create Reduce\n",
      "create Round\n",
      "create Sorted Index\n",
      "create Wrapper\n",
      "deburr Letter\n",
      "equal Arrays\n",
      "equal By Tag\n",
      "equal Objects\n",
      "escape Html Char\n",
      "escape Reg Exp Char\n",
      "escape String Char\n",
      "get Data\n",
      "get Func Name\n",
      "get Length\n",
      "get Match Data\n",
      "get Native\n",
      "get View\n",
      "index Of Na N\n",
      "init Clone Array\n",
      "init Clone By Tag\n",
      "init Clone Object\n",
      "invoke Path\n",
      "is Array Like\n",
      "is Index\n",
      "is Iteratee Call\n",
      "is Key\n",
      "is Laziable\n",
      "is Length\n",
      "is Object Like\n",
      "is Space\n",
      "is Strict Comparable\n",
      "lazy Clone\n",
      "lazy Reverse\n",
      "lazy Value\n",
      "map Delete\n",
      "map Get\n",
      "map Has\n",
      "map Set\n",
      "merge Data\n",
      "merge Defaults\n",
      "meta Map\n",
      "pick By Array\n",
      "pick By Callback\n",
      "re Escape\n",
      "re Evaluate\n",
      "re Interpolate\n",
      "real Names\n",
      "reorder\n",
      "replace Holders\n",
      "set Data\n",
      "shim Keys\n",
      "sorted Uniq\n",
      "to Iterable\n",
      "to Object\n",
      "to Path\n",
      "trimmed Left Index\n",
      "trimmed Right Index\n",
      "unescape Html Char\n",
      "wrapper Clone\n",
      "clone Deep\n",
      "eq\n",
      "gt\n",
      "gte\n",
      "is Element\n",
      "is Equal\n",
      "is Error\n",
      "is Match\n",
      "is Native\n",
      "is Typed Array\n",
      "lt\n",
      "lte\n",
      "to Plain Object\n",
      "assign\n",
      "create\n",
      "defaults Deep\n",
      "extend\n",
      "find Key\n",
      "find Last Key\n",
      "for In Right\n",
      "for Own Right\n",
      "invert\n",
      "keys In\n",
      "map Keys\n",
      "methods\n",
      "pairs\n",
      "values In\n",
      "capitalize\n",
      "deburr\n",
      "kebab Case\n",
      "pad Left\n",
      "pad Right\n",
      "parse Int\n",
      "snake Case\n",
      "start Case\n",
      "template\n",
      "template Settings\n",
      "trim Left\n",
      "trim Right\n",
      "trunc\n",
      "unescape\n",
      "words\n",
      "support\n",
      "utility\n",
      "attempt\n",
      "callback\n",
      "iteratee\n",
      "matches Property\n",
      "method Of\n",
      "mixin\n",
      "noop\n",
      "property\n",
      "property Of\n",
      "unique Id\n",
      "require\n",
      "cosmic\n",
      "additional Items\n",
      "additional Properties\n",
      "all Of\n",
      "any Of\n",
      "bignum\n",
      "definitions\n",
      "dependencies\n",
      "enum\n",
      "format\n",
      "items\n",
      "max Items\n",
      "max Length\n",
      "max Properties\n",
      "maximum\n",
      "min Items\n",
      "min Length\n",
      "min Properties\n",
      "minimum\n",
      "multiple Of\n",
      "not\n",
      "null And Format\n",
      "null And Object\n",
      "one Of\n",
      "pattern\n",
      "pattern Properties\n",
      "properties\n",
      "ref\n",
      "ref Remote\n",
      "required\n",
      "type\n",
      "unique Items\n",
      "json-schema\n",
      "is-property\n",
      "is-utf8\n",
      "access\n",
      "mode\n",
      "windows\n",
      "isstream\n",
      "AUTHORS\n",
      "almond\n",
      "jsdoc\n",
      "curve255\n",
      "dh\n",
      "eddsa\n",
      "draft-zyp-json-schema-03\n",
      "draft-zyp-json-schema-04\n",
      "links\n",
      "validate\n",
      "stringify test\n",
      "benchmark\n",
      "jsonpointer\n",
      "jsprim\n",
      "gen-changelog\n",
      "lockfile\n",
      "bad-child\n",
      "child\n",
      "retry-time\n",
      "stale-contention\n",
      " Data View\n",
      " Hash\n",
      " Lazy Wrapper\n",
      " List Cache\n",
      " Lodash Wrapper\n",
      " Map\n",
      " Map Cache\n",
      " Promise\n",
      " Set\n",
      " Set Cache\n",
      " Stack\n",
      " Symbol\n",
      " Uint8Array\n",
      " Weak Map\n",
      " add Map Entry\n",
      " add Set Entry\n",
      " apply\n",
      " array Aggregator\n",
      " array Each\n",
      " array Each Right\n",
      " array Every\n",
      " array Filter\n",
      " array Includes\n",
      " array Includes With\n",
      " array Like Keys\n",
      " array Map\n",
      " array Push\n",
      " array Reduce\n",
      " array Reduce Right\n",
      " array Sample\n",
      " array Sample Size\n",
      " array Shuffle\n",
      " array Some\n",
      " ascii Size\n",
      " ascii To Array\n",
      " ascii Words\n",
      " assign In Defaults\n",
      " assign Merge Value\n",
      " assign Value\n",
      " assoc Index Of\n",
      " base Aggregator\n",
      " base Assign\n",
      " base Assign Value\n",
      " base At\n",
      " base Clamp\n",
      " base Clone\n",
      " base Conforms\n",
      " base Conforms To\n",
      " base Create\n",
      " base Delay\n",
      " base Difference\n",
      " base Each\n",
      " base Each Right\n",
      " base Every\n",
      " base Extremum\n",
      " base Fill\n",
      " base Filter\n",
      " base Find Index\n",
      " base Find Key\n",
      " base Flatten\n",
      " base For\n",
      " base For Own\n",
      " base For Own Right\n",
      " base For Right\n",
      " base Functions\n",
      " base Get\n",
      " base Get All Keys\n",
      " base Get Tag\n",
      " base Gt\n",
      " base Has\n",
      " base Has In\n",
      " base In Range\n",
      " base Index Of\n",
      " base Index Of With\n",
      " base Intersection\n",
      " base Inverter\n",
      " base Invoke\n",
      " base Is Arguments\n",
      " base Is Array Buffer\n",
      " base Is Date\n",
      " base Is Equal\n",
      " base Is Equal Deep\n",
      " base Is Map\n",
      " base Is Match\n",
      " base Is Na N\n",
      " base Is Native\n",
      " base Is Reg Exp\n",
      " base Is Set\n",
      " base Is Typed Array\n",
      " base Iteratee\n",
      " base Keys\n",
      " base Keys In\n",
      " base Lodash\n",
      " base Lt\n",
      " base Map\n",
      " base Matches\n",
      " base Matches Property\n",
      " base Mean\n",
      " base Merge\n",
      " base Merge Deep\n",
      " base Nth\n",
      " base Order By\n",
      " base Pick\n",
      " base Pick By\n",
      " base Property\n",
      " base Property Deep\n",
      " base Property Of\n",
      " base Pull All\n",
      " base Pull At\n",
      " base Random\n",
      " base Range\n",
      " base Reduce\n",
      " base Repeat\n",
      " base Rest\n",
      " base Sample\n",
      " base Sample Size\n",
      " base Set\n",
      " base Set Data\n",
      " base Set To String\n",
      " base Shuffle\n",
      " base Slice\n",
      " base Some\n",
      " base Sort By\n",
      " base Sorted Index\n",
      " base Sorted Index By\n",
      " base Sorted Uniq\n",
      " base Sum\n",
      " base Times\n",
      " base To Number\n",
      " base To Pairs\n",
      " base To String\n",
      " base Unary\n",
      " base Uniq\n",
      " base Unset\n",
      " base Update\n",
      " base Values\n",
      " base While\n",
      " base Wrapper Value\n",
      " base Xor\n",
      " base Zip Object\n",
      " cache Has\n",
      " cast Array Like Object\n",
      " cast Function\n",
      " cast Path\n",
      " cast Rest\n",
      " cast Slice\n",
      " chars End Index\n",
      " chars Start Index\n",
      " clone Array Buffer\n",
      " clone Buffer\n",
      " clone Data View\n",
      " clone Map\n",
      " clone Reg Exp\n",
      " clone Set\n",
      " clone Symbol\n",
      " clone Typed Array\n",
      " compare Ascending\n",
      " compare Multiple\n",
      " compose Args\n",
      " compose Args Right\n",
      " copy Array\n",
      " copy Object\n",
      " copy Symbols\n",
      " core Js Data\n",
      " count Holders\n",
      " create Aggregator\n",
      " create Assigner\n",
      " create Base Each\n",
      " create Base For\n",
      " create Bind\n",
      " create Case First\n",
      " create Compounder\n",
      " create Ctor\n",
      " create Curry\n",
      " create Find\n",
      " create Flow\n",
      " create Hybrid\n",
      " create Inverter\n",
      " create Math Operation\n",
      " create Over\n",
      " create Padding\n",
      " create Partial\n",
      " create Range\n",
      " create Recurry\n",
      " create Relational Operation\n",
      " create Round\n",
      " create Set\n",
      " create To Pairs\n",
      " create Wrap\n",
      " deburr Letter\n",
      " define Property\n",
      " equal Arrays\n",
      " equal By Tag\n",
      " equal Objects\n",
      " escape Html Char\n",
      " escape String Char\n",
      " flat Rest\n",
      " free Global\n",
      " get All Keys\n",
      " get All Keys In\n",
      " get Data\n",
      " get Func Name\n",
      " get Holder\n",
      " get Map Data\n",
      " get Match Data\n",
      " get Native\n",
      " get Prototype\n",
      " get Raw Tag\n",
      " get Symbols\n",
      " get Symbols In\n",
      " get Tag\n",
      " get Value\n",
      " get View\n",
      " get Wrap Details\n",
      " has Path\n",
      " has Unicode\n",
      " has Unicode Word\n",
      " hash Clear\n",
      " hash Delete\n",
      " hash Get\n",
      " hash Has\n",
      " hash Set\n",
      " init Clone Array\n",
      " init Clone By Tag\n",
      " init Clone Object\n",
      " insert Wrap Details\n",
      " is Flattenable\n",
      " is Index\n",
      " is Iteratee Call\n",
      " is Key\n",
      " is Keyable\n",
      " is Laziable\n",
      " is Maskable\n",
      " is Masked\n",
      " is Prototype\n",
      " is Strict Comparable\n",
      " iterator To Array\n",
      " lazy Clone\n",
      " lazy Reverse\n",
      " lazy Value\n",
      " list Cache Clear\n",
      " list Cache Delete\n",
      " list Cache Get\n",
      " list Cache Has\n",
      " list Cache Set\n",
      " map Cache Clear\n",
      " map Cache Delete\n",
      " map Cache Get\n",
      " map Cache Has\n",
      " map Cache Set\n",
      " map To Array\n",
      " matches Strict Comparable\n",
      " memoize Capped\n",
      " merge Data\n",
      " merge Defaults\n",
      " meta Map\n",
      " native Create\n",
      " native Keys\n",
      " native Keys In\n",
      " node Util\n",
      " object To String\n",
      " over Arg\n",
      " over Rest\n",
      " parent\n",
      " re Escape\n",
      " re Evaluate\n",
      " re Interpolate\n",
      " real Names\n",
      " reorder\n",
      " replace Holders\n",
      " root\n",
      " set Cache Add\n",
      " set Cache Has\n",
      " set Data\n",
      " set To Array\n",
      " set To Pairs\n",
      " set To String\n",
      " set Wrap To String\n",
      " short Out\n",
      " shuffle Self\n",
      " stack Clear\n",
      " stack Delete\n",
      " stack Get\n",
      " stack Has\n",
      " stack Set\n",
      " strict Index Of\n",
      " strict Last Index Of\n",
      " string Size\n",
      " string To Array\n",
      " string To Path\n",
      " to Key\n",
      " to Source\n",
      " unescape Html Char\n",
      " unicode Size\n",
      " unicode To Array\n",
      " unicode Words\n",
      " update Wrap Details\n",
      " wrapper Clone\n",
      "assign In\n",
      "assign In With\n",
      "cast Array\n",
      "clone Deep With\n",
      "clone With\n",
      "cond\n",
      "conforms\n",
      "conforms To\n",
      "core.min\n",
      "default To\n",
      "difference By\n",
      "difference With\n",
      "divide\n",
      "entries\n",
      "entries In\n",
      "extend With\n",
      "flat Map\n",
      "flat Map Deep\n",
      "flat Map Depth\n",
      "flatten Depth\n",
      "flip\n",
      "fp\n",
      "F\n",
      "T\n",
      "  \n",
      " base Convert\n",
      " convert Browser\n",
      " false Options\n",
      " mapping\n",
      " util\n",
      "all Pass\n",
      "always\n",
      "any Pass\n",
      "assign All\n",
      "assign All With\n",
      "assign In All\n",
      "assign In All With\n",
      "assoc\n",
      "assoc Path\n",
      "complement\n",
      "curry N\n",
      "curry Right N\n",
      "defaults All\n",
      "defaults Deep All\n",
      "dissoc\n",
      "dissoc Path\n",
      "drop Last\n",
      "drop Last While\n",
      "extend All\n",
      "extend All With\n",
      "find From\n",
      "find Index From\n",
      "find Last From\n",
      "find Last Index From\n",
      "from Pairs\n",
      "functions In\n",
      "get Or\n",
      "has In\n",
      "identical\n",
      "includes From\n",
      "index Of From\n",
      "intersection By\n",
      "intersection With\n",
      "invert By\n",
      "invert Obj\n",
      "invoke Args\n",
      "invoke Args Map\n",
      "invoke Map\n",
      "is Array Buffer\n",
      "is Array Like Object\n",
      "is Buffer\n",
      "is Equal With\n",
      "is Map\n",
      "is Match With\n",
      "is Nil\n",
      "is Safe Integer\n",
      "is Set\n",
      "is Symbol\n",
      "is Weak Map\n",
      "is Weak Set\n",
      "juxt\n",
      "key By\n",
      "last Index Of From\n",
      "lower First\n",
      "max By\n",
      "mean\n",
      "mean By\n",
      "merge All\n",
      "merge All With\n",
      "merge With\n",
      "min By\n",
      "multiply\n",
      "n Ary\n",
      "next\n",
      "nth Arg\n",
      "omit All\n",
      "omit By\n",
      "order By\n",
      "over\n",
      "over Args\n",
      "over Every\n",
      "over Some\n",
      "pad Chars\n",
      "pad Chars End\n",
      "pad Chars Start\n",
      "pad End\n",
      "pad Start\n",
      "path\n",
      "path Eq\n",
      "path Or\n",
      "pick All\n",
      "pick By\n",
      "placeholder\n",
      "prop Eq\n",
      "prop Or\n",
      "pull All\n",
      "pull All By\n",
      "pull All With\n",
      "range Right\n",
      "range Step\n",
      "range Step Right\n",
      "rest From\n",
      "sample Size\n",
      "set With\n",
      "sorted Index By\n",
      "sorted Index Of\n",
      "sorted Last Index By\n",
      "sorted Last Index Of\n",
      "sorted Uniq By\n",
      "spread From\n",
      "stub Array\n",
      "stub False\n",
      "stub Object\n",
      "stub String\n",
      "stub True\n",
      "subtract\n",
      "sum By\n",
      "symmetric Difference\n",
      "symmetric Difference By\n",
      "symmetric Difference With\n",
      "take Last\n",
      "take Last While\n",
      "to Finite\n",
      "to Integer\n",
      "to Iterator\n",
      "to Length\n",
      "to Lower\n",
      "to Pairs\n",
      "to Pairs In\n",
      "to Safe Integer\n",
      "to Upper\n",
      "trim Chars\n",
      "trim Chars End\n",
      "trim Chars Start\n",
      "trim End\n",
      "trim Start\n",
      "unapply\n",
      "unary\n",
      "union By\n",
      "union With\n",
      "uniq By\n",
      "uniq With\n",
      "unnest\n",
      "update With\n",
      "upper First\n",
      "use With\n",
      "where Eq\n",
      "wrapper At\n",
      "wrapper Lodash\n",
      "xor By\n",
      "xor With\n",
      "zip All\n",
      "zip Obj\n",
      "zip Object Deep\n",
      "lodash.min\n",
      "api\n",
      "lru-cache\n",
      "foreach\n",
      "memory-leak\n",
      "serialize\n",
      "md5omatic\n",
      "all bool\n",
      "bool\n",
      "dash\n",
      "default bool\n",
      "dotted\n",
      "kv short\n",
      "long\n",
      "num\n",
      "parse modified\n",
      "short\n",
      "stop early\n",
      "unknown\n",
      "whitespace\n",
      "db\n",
      "mime\n",
      "cmd\n",
      "opts fs\n",
      "opts fs sync\n",
      "mkpath\n",
      "mute\n",
      "benchmark-native\n",
      "compare v1\n",
      "uuid\n",
      "nopt\n",
      "my-program\n",
      "extract description\n",
      "fixer\n",
      "make warning\n",
      "normalize\n",
      "safe format\n",
      "typos\n",
      "warning messages\n",
      "consistency\n",
      "badscripts\n",
      "bcrypt\n",
      "coffee-script\n",
      "http-server\n",
      "movefile\n",
      "no-description\n",
      "node-module exist\n",
      "npm\n",
      "read-package-json\n",
      "github-urls\n",
      "mixedcase-names\n",
      "scoped\n",
      "strict\n",
      "typo\n",
      "boolean double\n",
      "boolean single\n",
      "default hash\n",
      "default singles\n",
      "line count\n",
      "line count options\n",
      "line count wrap\n",
      "nonopt\n",
      "usage-options\n",
      "xup\n",
      " \n",
      "argv\n",
      "bin\n",
      "osenv\n",
      "unix\n",
      "x\n",
      "array Remove\n",
      "compare-with-callbacks\n",
      "scenarios\n",
      "q\n",
      "semver\n",
      "unicode\n",
      "index.spec\n",
      "nested-env-vars\n",
      "Buffer List\n",
      "Changelog\n",
      "sample-config\n",
      "replace-log\n",
      "redeyed\n",
      "redeyed-before-after-config\n",
      "redeyed-browser\n",
      "redeyed-comments\n",
      "redeyed-config-with-undefineds\n",
      "redeyed-function-config-extra-params\n",
      "redeyed-function-config-skipping-tokens\n",
      "redeyed-function-config\n",
      "redeyed-mixed\n",
      "redeyed-result\n",
      "redeyed-script-level-return\n",
      "redeyed-shebang\n",
      "redeyed-smoke\n",
      "redeyed-string-config\n",
      "redeyed-types\n",
      "base64\n",
      "strip-json-comments\n",
      "registry-url\n",
      "auth-token.test\n",
      "registry-url.test\n",
      "auth\n",
      "cookies\n",
      "get Proxy From URI\n",
      "multipart\n",
      "querystring\n",
      "redirect\n",
      "tunnel\n",
      "requireg\n",
      "resolvers\n",
      "caller\n",
      "node-modules-paths\n",
      "faulty basedir\n",
      "filter sync\n",
      "mock\n",
      "mock sync\n",
      "node path\n",
      "doom\n",
      "quux\n",
      "cup\n",
      "mug\n",
      "other-lib\n",
      "mymodule\n",
      "resolver sync\n",
      "requireg Spec\n",
      "dotdot\n",
      "module dir\n",
      "nonstring\n",
      "pathfilter\n",
      "alt\n",
      "precedence\n",
      "aaa\n",
      "bbb\n",
      "subdirs\n",
      "equation\n",
      "dns\n",
      "retry operation\n",
      "test-retry-operation\n",
      "test-timeouts\n",
      "rimraf\n",
      "rx.lite\n",
      "rx.lite.min\n",
      "semver-utils\n",
      "deep Own Equal\n",
      "spec\n",
      "foot\n",
      "semver.browser\n",
      "semver.browser.js\n",
      "semver.min\n",
      "semver.min.js\n",
      "amd\n",
      "gtr\n",
      "ltr\n",
      "no-module\n",
      "env\n",
      "op\n",
      "quote\n",
      "comment\n",
      "env fn\n",
      "signals\n",
      "async-map-ordered\n",
      "async-map\n",
      "bind-actor\n",
      "slide\n",
      "offset\n",
      "source-map\n",
      "array-set\n",
      "base64-vlq\n",
      "binary-search\n",
      "mapping-list\n",
      "quick-sort\n",
      "source-map-consumer\n",
      "source-map-generator\n",
      "source-node\n",
      "spdx-license-ids\n",
      "algs\n",
      "certificate\n",
      "dhe\n",
      "ed-compat\n",
      "fingerprint\n",
      "openssh-cert\n",
      "pem\n",
      "pkcs1\n",
      "pkcs8\n",
      "rfc4253\n",
      "ssh-private\n",
      "ssh\n",
      "x509-pem\n",
      "x509\n",
      "key\n",
      "private-key\n",
      "signature\n",
      "ssh-buffer\n",
      "sshpk-conv\n",
      "sshpk-sign\n",
      "sshpk-verify\n",
      "codes\n",
      "stringstream\n",
      "hello\n",
      "extract\n",
      "headers\n",
      "pack\n",
      "auto-destroy\n",
      "buffering\n",
      "end\n",
      "touch\n",
      "sanity\n",
      "memstore\n",
      "path Match\n",
      "permute Domain\n",
      "pubsuffix\n",
      "store\n",
      "leaves\n",
      "negative\n",
      "circular\n",
      "equal\n",
      "instance\n",
      "interface\n",
      "mutability\n",
      "obj\n",
      "stop\n",
      "super deep\n",
      "COPYING\n",
      "nacl-fast\n",
      "nacl-fast.min\n",
      "nacl\n",
      "nacl.min\n",
      "extract-props\n",
      "compress\n",
      "mozilla-ast\n",
      "output\n",
      "propmangle\n",
      "scope\n",
      "sourcemap\n",
      "check\n",
      "compare\n",
      "perf\n",
      "rng-browser\n",
      "rng\n",
      "levels-verror\n",
      "levels-werror\n",
      "varargs\n",
      "verror\n",
      "werror\n",
      "tst.inherit\n",
      "tst.verror\n",
      "tst.werror\n",
      "which\n",
      "wrappy\n",
      "immutable\n",
      "mutable\n",
      "completion.sh\n",
      "completion\n",
      "validation\n",
      "Json Renderer\n",
      "Standard Renderer\n",
      "colors\n",
      "condense\n",
      "indent\n",
      "help-cache\n",
      "help-home\n",
      "help-info\n",
      "help-init\n",
      "help-install\n",
      "help-link\n",
      "help-list\n",
      "help-login\n",
      "help-lookup\n",
      "help-prune\n",
      "help-register\n",
      "help-search\n",
      "help-uninstall\n",
      "help-unregister\n",
      "help-update\n",
      "help-version\n",
      "conflict-resolved\n",
      "conflict\n",
      "help-generic\n",
      "search-results\n",
      "abbreviations\n",
      "copy\n",
      "create Link\n",
      "download\n",
      "is Path Absolute\n",
      "read Json\n",
      "relative To Base Dir\n",
      "remove Ignores\n",
      "resolve\n",
      "root Check\n",
      "user Agent\n",
      "valid Link\n",
      "fsevents-handler\n",
      "nodefs-handler\n",
      "test-apart-ctx\n",
      "Read Me\n",
      "normal-usage\n",
      "trap\n",
      "zalgo\n",
      "extend String Prototype\n",
      "america\n",
      "rainbow\n",
      "zebra\n",
      "styles\n",
      "supports-colors\n",
      "safe\n",
      "generic-logging\n",
      "inherit\n",
      "Gruntfile\n",
      "core.min.js\n",
      "library\n",
      "library.min\n",
      "library.min.js\n",
      "shim\n",
      "shim.min\n",
      "shim.min.js\n",
      "dict\n",
      "regexp\n",
      "parse-float\n",
      "parse-int\n",
      "symbol\n",
      "typed\n",
      "weak-map\n",
      "weak-set\n",
      "asap\n",
      "observable\n",
      "system\n",
      "copy-within\n",
      "find-index\n",
      "for-each\n",
      "from\n",
      "is-array\n",
      "of\n",
      "pop\n",
      "push\n",
      "reduce-right\n",
      "shift\n",
      "unshift\n",
      "clear-immediate\n",
      "to-iso-string\n",
      "to-json\n",
      "to-primitive\n",
      "to-string\n",
      "is-error\n",
      "has-instance\n",
      "name\n",
      "part\n",
      "get-iterator-method\n",
      "get-iterator\n",
      "is-iterable\n",
      "acosh\n",
      "asinh\n",
      "atanh\n",
      "cbrt\n",
      "clz32\n",
      "cosh\n",
      "expm1\n",
      "fround\n",
      "hypot\n",
      "iaddh\n",
      "imul\n",
      "imulh\n",
      "isubh\n",
      "log10\n",
      "log1p\n",
      "log2\n",
      "sinh\n",
      "tanh\n",
      "umulh\n",
      "constructor\n",
      "epsilon\n",
      "is-finite\n",
      "is-integer\n",
      "is-nan\n",
      "is-safe-integer\n",
      "max-safe-integer\n",
      "min-safe-integer\n",
      "to-fixed\n",
      "to-precision\n",
      "classof\n",
      "define-getter\n",
      "define-properties\n",
      "define-property\n",
      "define-setter\n",
      "define\n",
      "freeze\n",
      "get-own-property-descriptor\n",
      "get-own-property-descriptors\n",
      "get-own-property-names\n",
      "get-own-property-symbols\n",
      "get-prototype-of\n",
      "is-extensible\n",
      "is-frozen\n",
      "is-object\n",
      "is-sealed\n",
      "lookup-getter\n",
      "lookup-setter\n",
      "make\n",
      "prevent-extensions\n",
      "seal\n",
      "set-prototype-of\n",
      "construct\n",
      "define-metadata\n",
      "delete-metadata\n",
      "delete-property\n",
      "enumerate\n",
      "get-metadata-keys\n",
      "get-metadata\n",
      "get-own-metadata-keys\n",
      "get-own-metadata\n",
      "has-metadata\n",
      "has-own-metadata\n",
      "metadata\n",
      "own-keys\n",
      "flags\n",
      "match\n",
      "set-immediate\n",
      "set-interval\n",
      "set-timeout\n",
      "anchor\n",
      "big\n",
      "blink\n",
      "bold\n",
      "code-point-at\n",
      "ends-with\n",
      "escape-html\n",
      "fixed\n",
      "fontcolor\n",
      "fontsize\n",
      "from-code-point\n",
      "italics\n",
      "match-all\n",
      "pad-end\n",
      "pad-start\n",
      "starts-with\n",
      "strike\n",
      "sub\n",
      "sup\n",
      "trim-end\n",
      "trim-left\n",
      "trim-right\n",
      "trim-start\n",
      "unescape-html\n",
      "async-iterator\n",
      "for\n",
      "is-concat-spreadable\n",
      "key-for\n",
      "species\n",
      "to-string-tag\n",
      "unscopables\n",
      "global\n",
      "array-buffer\n",
      "data-view\n",
      "float32-array\n",
      "float64-array\n",
      "int16-array\n",
      "int32-array\n",
      "int8-array\n",
      "uint16-array\n",
      "uint32-array\n",
      "uint8-array\n",
      "uint8-clamped-array\n",
      " a-function\n",
      " a-number-value\n",
      " add-to-unscopables\n",
      " an-instance\n",
      " an-object\n",
      " array-copy-within\n",
      " array-fill\n",
      " array-from-iterable\n",
      " array-includes\n",
      " array-methods\n",
      " array-reduce\n",
      " array-species-constructor\n",
      " array-species-create\n",
      " bind\n",
      " classof\n",
      " cof\n",
      " collection-strong\n",
      " collection-to-json\n",
      " collection-weak\n",
      " collection\n",
      " core\n",
      " create-property\n",
      " ctx\n",
      " date-to-primitive\n",
      " defined\n",
      " descriptors\n",
      " dom-create\n",
      " entry-virtual\n",
      " enum-bug-keys\n",
      " enum-keys\n",
      " export\n",
      " fails-is-regexp\n",
      " fails\n",
      " fix-re-wks\n",
      " flags\n",
      " for-of\n",
      " global\n",
      " has\n",
      " hide\n",
      " html\n",
      " ie8-dom-define\n",
      " inherit-if-required\n",
      " invoke\n",
      " iobject\n",
      " is-array-iter\n",
      " is-array\n",
      " is-integer\n",
      " is-object\n",
      " is-regexp\n",
      " iter-call\n",
      " iter-create\n",
      " iter-define\n",
      " iter-detect\n",
      " iter-step\n",
      " iterators\n",
      " keyof\n",
      " library\n",
      " math-expm1\n",
      " math-log1p\n",
      " math-sign\n",
      " meta\n",
      " metadata\n",
      " microtask\n",
      " object-assign\n",
      " object-create\n",
      " object-define\n",
      " object-dp\n",
      " object-dps\n",
      " object-forced-pam\n",
      " object-gopd\n",
      " object-gopn-ext\n",
      " object-gopn\n",
      " object-gops\n",
      " object-gpo\n",
      " object-keys-internal\n",
      " object-keys\n",
      " object-pie\n",
      " object-sap\n",
      " object-to-array\n",
      " own-keys\n",
      " parse-float\n",
      " parse-int\n",
      " partial\n",
      " path\n",
      " property-desc\n",
      " redefine-all\n",
      " redefine\n",
      " replacer\n",
      " same-value\n",
      " set-proto\n",
      " set-species\n",
      " set-to-string-tag\n",
      " shared-key\n",
      " shared\n",
      " species-constructor\n",
      " strict-method\n",
      " string-at\n",
      " string-context\n",
      " string-html\n",
      " string-pad\n",
      " string-repeat\n",
      " string-trim\n",
      " string-ws\n",
      " task\n",
      " to-index\n",
      " to-integer\n",
      " to-iobject\n",
      " to-length\n",
      " to-object\n",
      " to-primitive\n",
      " typed-array\n",
      " typed-buffer\n",
      " typed\n",
      " uid\n",
      " wks-define\n",
      " wks-ext\n",
      " wks\n",
      "core.delay\n",
      "core.dict\n",
      "core.function.part\n",
      "core.get-iterator-method\n",
      "core.get-iterator\n",
      "core.is-iterable\n",
      "core.number.iterator\n",
      "core.object.classof\n",
      "core.object.define\n",
      "core.object.is-object\n",
      "core.object.make\n",
      "core.regexp.escape\n",
      "core.string.escape-html\n",
      "core.string.unescape-html\n",
      "es6.array.copy-within\n",
      "es6.array.every\n",
      "es6.array.fill\n",
      "es6.array.filter\n",
      "es6.array.find-index\n",
      "es6.array.find\n",
      "es6.array.for-each\n",
      "es6.array.from\n",
      "es6.array.index-of\n",
      "es6.array.is-array\n",
      "es6.array.iterator\n",
      "es6.array.join\n",
      "es6.array.last-index-of\n",
      "es6.array.map\n",
      "es6.array.of\n",
      "es6.array.reduce-right\n",
      "es6.array.reduce\n",
      "es6.array.slice\n",
      "es6.array.some\n",
      "es6.array.sort\n",
      "es6.array.species\n",
      "es6.date.now\n",
      "es6.date.to-iso-string\n",
      "es6.date.to-json\n",
      "es6.date.to-primitive\n",
      "es6.date.to-string\n",
      "es6.function.bind\n",
      "es6.function.has-instance\n",
      "es6.function.name\n",
      "es6.map\n",
      "es6.math.acosh\n",
      "es6.math.asinh\n",
      "es6.math.atanh\n",
      "es6.math.cbrt\n",
      "es6.math.clz32\n",
      "es6.math.cosh\n",
      "es6.math.expm1\n",
      "es6.math.fround\n",
      "es6.math.hypot\n",
      "es6.math.imul\n",
      "es6.math.log10\n",
      "es6.math.log1p\n",
      "es6.math.log2\n",
      "es6.math.sign\n",
      "es6.math.sinh\n",
      "es6.math.tanh\n",
      "es6.math.trunc\n",
      "es6.number.constructor\n",
      "es6.number.epsilon\n",
      "es6.number.is-finite\n",
      "es6.number.is-integer\n",
      "es6.number.is-nan\n",
      "es6.number.is-safe-integer\n",
      "es6.number.max-safe-integer\n",
      "es6.number.min-safe-integer\n",
      "es6.number.parse-float\n",
      "es6.number.parse-int\n",
      "es6.number.to-fixed\n",
      "es6.number.to-precision\n",
      "es6.object.assign\n",
      "es6.object.create\n",
      "es6.object.define-properties\n",
      "es6.object.define-property\n",
      "es6.object.freeze\n",
      "es6.object.get-own-property-descriptor\n",
      "es6.object.get-own-property-names\n",
      "es6.object.get-prototype-of\n",
      "es6.object.is-extensible\n",
      "es6.object.is-frozen\n",
      "es6.object.is-sealed\n",
      "es6.object.is\n",
      "es6.object.keys\n",
      "es6.object.prevent-extensions\n",
      "es6.object.seal\n",
      "es6.object.set-prototype-of\n",
      "es6.object.to-string\n",
      "es6.parse-float\n",
      "es6.parse-int\n",
      "es6.promise\n",
      "es6.reflect.apply\n",
      "es6.reflect.construct\n",
      "es6.reflect.define-property\n",
      "es6.reflect.delete-property\n",
      "es6.reflect.enumerate\n",
      "es6.reflect.get-own-property-descriptor\n",
      "es6.reflect.get-prototype-of\n",
      "es6.reflect.get\n",
      "es6.reflect.has\n",
      "es6.reflect.is-extensible\n",
      "es6.reflect.own-keys\n",
      "es6.reflect.prevent-extensions\n",
      "es6.reflect.set-prototype-of\n",
      "es6.reflect.set\n",
      "es6.regexp.constructor\n",
      "es6.regexp.flags\n",
      "es6.regexp.match\n",
      "es6.regexp.replace\n",
      "es6.regexp.search\n",
      "es6.regexp.split\n",
      "es6.regexp.to-string\n",
      "es6.set\n",
      "es6.string.anchor\n",
      "es6.string.big\n",
      "es6.string.blink\n",
      "es6.string.bold\n",
      "es6.string.code-point-at\n",
      "es6.string.ends-with\n",
      "es6.string.fixed\n",
      "es6.string.fontcolor\n",
      "es6.string.fontsize\n",
      "es6.string.from-code-point\n",
      "es6.string.includes\n",
      "es6.string.italics\n",
      "es6.string.iterator\n",
      "es6.string.link\n",
      "es6.string.raw\n",
      "es6.string.repeat\n",
      "es6.string.small\n",
      "es6.string.starts-with\n",
      "es6.string.strike\n",
      "es6.string.sub\n",
      "es6.string.sup\n",
      "es6.string.trim\n",
      "es6.symbol\n",
      "es6.typed.array-buffer\n",
      "es6.typed.data-view\n",
      "es6.typed.float32-array\n",
      "es6.typed.float64-array\n",
      "es6.typed.int16-array\n",
      "es6.typed.int32-array\n",
      "es6.typed.int8-array\n",
      "es6.typed.uint16-array\n",
      "es6.typed.uint32-array\n",
      "es6.typed.uint8-array\n",
      "es6.typed.uint8-clamped-array\n",
      "es6.weak-map\n",
      "es6.weak-set\n",
      "es7.array.includes\n",
      "es7.asap\n",
      "es7.error.is-error\n",
      "es7.map.to-json\n",
      "es7.math.iaddh\n",
      "es7.math.imulh\n",
      "es7.math.isubh\n",
      "es7.math.umulh\n",
      "es7.object.define-getter\n",
      "es7.object.define-setter\n",
      "es7.object.entries\n",
      "es7.object.enumerable-entries\n",
      "es7.object.enumerable-keys\n",
      "es7.object.enumerable-values\n",
      "es7.object.get-own-property-descriptors\n",
      "es7.object.lookup-getter\n",
      "es7.object.lookup-setter\n",
      "es7.object.values\n",
      "es7.observable\n",
      "es7.reflect.define-metadata\n",
      "es7.reflect.delete-metadata\n",
      "es7.reflect.get-metadata-keys\n",
      "es7.reflect.get-metadata\n",
      "es7.reflect.get-own-metadata-keys\n",
      "es7.reflect.get-own-metadata\n",
      "es7.reflect.has-metadata\n",
      "es7.reflect.has-own-metadata\n",
      "es7.reflect.metadata\n",
      "es7.set.to-json\n",
      "es7.string.at\n",
      "es7.string.match-all\n",
      "es7.string.pad-end\n",
      "es7.string.pad-start\n",
      "es7.string.trim-left\n",
      "es7.string.trim-right\n",
      "es7.symbol.async-iterator\n",
      "es7.symbol.observable\n",
      "es7.system.global\n",
      "web.dom.iterable\n",
      "web.immediate\n",
      "web.timers\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "pre\n",
      "dom-collections\n",
      "dateformat\n",
      "buffer-concat\n",
      "callsite-tostring\n",
      "event-listener-count\n",
      "field\n",
      "annotation\n",
      "injector\n",
      "engine.io\n",
      "socket\n",
      "transport\n",
      "polling-jsonp\n",
      "polling-xhr\n",
      "polling\n",
      "websocket\n",
      "xmlhttprequest\n",
      "entities\n",
      "reversed\n",
      "hex\n",
      "es6-promise.d\n",
      "es6-promise\n",
      "-internal\n",
      "enumerator\n",
      "polyfill\n",
      "then\n",
      ".verb\n",
      "expand-basic\n",
      "expand-nested\n",
      "expand-range\n",
      "brace-expansion\n",
      "braces\n",
      "pathname-expansion\n",
      "examples\n",
      "alpha-lower\n",
      "alpha-upper\n",
      "padded\n",
      "respawn\n",
      "exit code\n",
      "respawner\n",
      "signal\n",
      "copy-file-sync\n",
      "copy-sync\n",
      "ncp\n",
      "file\n",
      "symlink-paths\n",
      "symlink-type\n",
      "symlink\n",
      "jsonfile\n",
      "output-json-sync\n",
      "output-json\n",
      "mkdirs-sync\n",
      "mkdirs\n",
      "create-output-stream\n",
      "utimes\n",
      "gaze\n",
      "helper\n",
      "through2\n",
      "globule\n",
      "g\n",
      "usr-local\n",
      "00-setup\n",
      "bash-comparison\n",
      "bash-results\n",
      "cwd-test\n",
      "mark\n",
      "nocase-nomagic\n",
      "pause-resume\n",
      "root-nomount\n",
      "zz-cleanup\n",
      "open\n",
      "ulimit\n",
      "brace-expand\n",
      "caching\n",
      "extglob-ending-with-state-char\n",
      "baz\n",
      "qux\n",
      "deep\n",
      "deeper\n",
      "deepest\n",
      "bar\n",
      "globule test\n",
      "Plugin Error\n",
      "buffer\n",
      "is Stream\n",
      "gulp\n",
      "task Tree\n",
      "http-proxy\n",
      "web-incoming\n",
      "web-outgoing\n",
      "ws-incoming\n",
      "dbcs-codec\n",
      "dbcs-data\n",
      "internal\n",
      "sbcs-codec\n",
      "sbcs-data-generated\n",
      "sbcs-data\n",
      "big5-added\n",
      "cp936\n",
      "cp949\n",
      "cp950\n",
      "eucjp\n",
      "gb18030-ranges\n",
      "gbk-added\n",
      "shiftjis\n",
      "utf16\n",
      "utf7\n",
      "bom-handling\n",
      "extend-node\n",
      "index.d\n",
      "streams\n",
      "json3\n",
      "json3.min\n",
      "appveyor\n",
      "capture.template\n",
      "gruntfile\n",
      "win32\n",
      "location\n",
      "arguments\n",
      "child process-examples\n",
      "colorwheel\n",
      "countdown\n",
      "detectsniff\n",
      "echo To File\n",
      "features\n",
      "fibo\n",
      "injectme\n",
      "loadspeed\n",
      "loadurlwithoutcss\n",
      "modernizr\n",
      "netlog\n",
      "netsniff\n",
      "openurlwithproxy\n",
      "output Encoding\n",
      "page events\n",
      "pagecallback\n",
      "phantomwebintro\n",
      "post\n",
      "postjson\n",
      "postserver\n",
      "printenv\n",
      "printheaderfooter\n",
      "printmargins\n",
      "rasterize\n",
      "render multi url\n",
      "responsive-screenshot\n",
      "run-jasmine\n",
      "run-jasmine2\n",
      "run-qunit\n",
      "scandir\n",
      "serverkeepalive\n",
      "simpleserver\n",
      "sleepsort\n",
      "stdin-stdout-stderr\n",
      "universe\n",
      "unrandomize\n",
      "useragent\n",
      "waitfor\n",
      "walk through frames\n",
      "third-party\n",
      "phantomjs\n",
      "exit\n",
      "bytes To Uuid\n",
      "v1\n",
      "v4\n",
      "add.spec\n",
      "CODE OF CONDUCT\n",
      "ISSUE TEMPLATE\n",
      "config.tpl\n",
      "console\n",
      "karma\n",
      "browser collection\n",
      "browser result\n",
      "constants\n",
      "detached\n",
      "emitter wrapper\n",
      "executor\n",
      "file-list\n",
      "color schemes\n",
      "formatters\n",
      "state machine\n",
      "launcher\n",
      "capture timeout\n",
      "source files\n",
      "stopper\n",
      "strip host\n",
      "plugin\n",
      "preprocessor\n",
      "reporter\n",
      "base color\n",
      "dots color\n",
      "multi\n",
      "progress\n",
      "progress color\n",
      "temp dir\n",
      "watcher\n",
      "web-server\n",
      "requirejs.config.tpl\n",
      "integration-tests\n",
      "karma-completion\n",
      "validate-commit-msg\n",
      "client with context\n",
      "favicon\n",
      "wallaby\n",
      "kew\n",
      "closure test\n",
      "externs node\n",
      "later\n",
      "scopes\n",
      "UPGRADING\n",
      "build config name\n",
      "file search\n",
      "find config\n",
      "find cwd\n",
      "parse options\n",
      "register loader\n",
      "silent require\n",
      " base Assign In\n",
      " copy Symbols In\n",
      " custom Defaults Assign In\n",
      " custom Defaults Merge\n",
      " custom Omit Clone\n",
      ".bob\n",
      "double-stack\n",
      "example-connect-logger\n",
      "example-socket\n",
      "flush-on-exit\n",
      "fromreadme\n",
      "hipchat-appender\n",
      "log-rolling\n",
      "log Faces-appender\n",
      "loggly-appender\n",
      "logstash UDP\n",
      "memory-test\n",
      "pattern Layout-tokens\n",
      "slack-appender\n",
      "smtp-appender\n",
      "category Filter\n",
      "clustered\n",
      "date File\n",
      "file Sync\n",
      "gelf\n",
      "hipchat\n",
      "log Faces Appender\n",
      "log Level Filter\n",
      "loggly\n",
      "mailgun\n",
      "multiprocess\n",
      "slack\n",
      "smtp\n",
      "stderr\n",
      "connect-logger\n",
      "date format\n",
      "layouts\n",
      "levels\n",
      "log4js\n",
      "Base Rolling File Stream\n",
      "Date Rolling File Stream\n",
      "Rolling File Stream\n",
      "category Filter-test\n",
      "clustered Appender-test\n",
      "configuration-test\n",
      "configure No Levels-test\n",
      "connect-logger-test\n",
      "console Appender-test\n",
      "date File Appender-test\n",
      "date format-test\n",
      "debug-test\n",
      "file Appender-test\n",
      "file Sync Appender-test\n",
      "gelf Appender-test\n",
      "global-log-level-test\n",
      "hipchat Appender-test\n",
      "layouts-test\n",
      "levels-test\n",
      "log-abspath-test\n",
      "log Faces Appender-test\n",
      "log Level Filter-test\n",
      "logger-test\n",
      "logging-test\n",
      "loggly Appender-test\n",
      "logstash UDP-test\n",
      "mailgun Appender-test\n",
      "multiprocess-test\n",
      "new Level-test\n",
      "nolog-test\n",
      "reload Configuration-test\n",
      "set Level-asymmetry-test\n",
      "slack Appender-test\n",
      "smtp Appender-test\n",
      "stderr Appender-test\n",
      "Base Rolling File Stream-test\n",
      "Date Rolling File Stream-test\n",
      "rolling File Stream-test\n",
      "subcategories-test\n",
      "with-category Filter\n",
      "with-date File\n",
      "with-log-rolling\n",
      "with-log Level Filter\n",
      "s\n",
      "chars\n",
      "multipipe\n",
      "charset\n",
      "language\n",
      "media Type\n",
      "options\n",
      "run Task\n",
      "index.min\n",
      "test.min\n",
      "phantomjs-2.1.1-linux-x86 64.tar\n",
      "node-progress\n",
      "LICENSE-MIT\n",
      "punycode\n",
      "qjobs\n",
      "pause\n",
      "callback-api\n",
      "grep\n",
      "stream-api-pipe\n",
      "stream-api\n",
      "readdirp\n",
      "root dir1 file1\n",
      "root dir1 file2\n",
      "root dir1 file3\n",
      "root1 dir1 subdir1 file1\n",
      "root dir2 file1\n",
      "root dir2 file2\n",
      "root file1\n",
      "root file2\n",
      "root file3\n",
      "readdirp-stream\n",
      "extension\n",
      "foot.js\n",
      "head.js\n",
      "big-numbers\n",
      "major-minor-patch\n",
      "sigmund\n",
      "manager\n",
      "on\n",
      "binary\n",
      "is-buffer\n",
      "GOVERNANCE\n",
      "PULL REQUEST TEMPLATE\n",
      "nacl.d\n",
      "tarray\n",
      "undef globals\n",
      "testfiles\n",
      "regexps\n",
      "user agent.after\n",
      "user agent.before\n",
      "write Buffer\n",
      "write Dir\n",
      "write Stream\n",
      "buffer File\n",
      "read Dir\n",
      "stream File\n",
      "get Stats\n",
      "max-open\n",
      "readdir-sort\n",
      "write-then-read\n",
      "clone Buffer\n",
      "inspect Stream\n",
      "pre-publish\n",
      "SECURITY\n",
      "Buffer Pool\n",
      "Buffer Util.fallback\n",
      "Buffer Util\n",
      "Error Codes\n",
      "Extensions\n",
      "Per Message Deflate\n",
      "Receiver.hixie\n",
      "Receiver\n",
      "Sender.hixie\n",
      "Sender\n",
      "Validation.fallback\n",
      "Validation\n",
      "Web Socket\n",
      "Web Socket Server\n",
      "wtf-8\n",
      "autotest\n",
      "demo\n",
      "XMLHttp Request\n",
      "test-constants\n",
      "test-events\n",
      "test-exceptions\n",
      "test-headers\n",
      "test-redirect-302\n",
      "test-redirect-303\n",
      "test-redirect-307\n",
      "test-request-methods\n",
      "test-request-protocols\n",
      "testdata\n",
      "refine\n",
      "property preview\n",
      "resource preview\n",
      "resource preview template\n",
      "type preview\n",
      "nbbuild\n",
      "jdatapath-alpha2-sources\n",
      "jetty-6.1.22-sources\n",
      "jetty-util-6.1.22-sources\n",
      "servlet-api-2.5-sources\n",
      "jdatapath-alpha2\n",
      "jetty-6.1.22\n",
      "jetty-util-6.1.22\n",
      "jdatapath\n",
      "servlet-api-2.5\n",
      "Configurations\n",
      "Thread Pool Executor Adapter\n",
      "Urlify.java\n",
      "jackson-core-asl-1.5.6\n",
      "jackson-mapper-asl-1.5.6\n",
      "org.springframework.core-3.0.4.RELEASE\n",
      "org.springframework.test-3.0.4.RELEASE\n",
      "Regression1\n",
      "classes\n",
      "groups\n",
      "methods-alphabetical\n",
      "methods-not-run\n",
      "reporter-output\n",
      "testng-failed\n",
      "testng.xml\n",
      "toc\n",
      "emailable-report\n",
      "com.google.refine.test.org.deri.reconcile.factories.Big Owl Im Sparql Query Factory Test\n",
      "com.google.refine.test.org.deri.reconcile.sindice.Delete Me\n",
      "com.google.refine.test.org.deri.reconcile.sindice.Sindice Service Test\n",
      "com.google.refine.test.rdf.vocab.Add Prefix Test\n",
      "com.google.refine.tests.rdf.Rdf Schema Serialization Test\n",
      "com.google.refine.tests.rdf.Rdf Schema Test\n",
      "com.google.refine.tests.rdf.exporters.Rdf Exporter Faculty Data Test\n",
      "com.google.refine.tests.rdf.exporters.Rdf Exporter Multi Root Nodes Test\n",
      "com.google.refine.tests.rdf.exporters.Rdf Exporter Payment Data Test\n",
      "com.google.refine.tests.rdf.exporters.Rdf Exporter Test\n",
      "testng-results\n",
      "testng\n",
      "GRefine Service Manager Test\n",
      "Larq Sparql Endpoint Test\n",
      "Plain Sparql Endpoint Test\n",
      "Larq Sparql Query Executor Test\n",
      "Plain Sparql Query Executor Test\n",
      "Big Owl Im Sparql Query Factory Test\n",
      "Larq Sparql Query Factory Test\n",
      "Plain Sparql Query Factory Test\n",
      "Preview Resource Canned Query Test\n",
      "Virtuoso Sparql Query Factory Test\n",
      "derians\n",
      "factbook-countries\n",
      "films\n",
      "foaf\n",
      "Sindice Service Test\n",
      "Add Prefix Command Test\n",
      "Add Prefix Test\n",
      "Import Prefix Test\n",
      "Project Fake\n",
      "Rdf Schema Serialization Test\n",
      "Rdf Schema Test\n",
      "Rdf Exporter Faculty Data Test.java\n",
      "Rdf Exporter Test.java\n",
      "Rdf Exporter Faculty Data Test\n",
      "Rdf Exporter Multi Root Nodes Test\n",
      "Rdf Exporter Payment Data Test\n",
      "Rdf Exporter Test\n",
      "non-unit-testing\n",
      "rdfschema-payment\n",
      "reconcile-test-suite\n",
      "rdfschema1\n",
      "rdfschema2\n",
      " 0\n",
      "segments\n",
      "write\n",
      "rdf-test\n",
      "GDP-in-2009.google-refine.tar\n",
      "GDP-in-2009\n",
      "GDPS\n",
      "deri logo\n",
      "details\n",
      "gdps\n",
      "node config\n",
      "preview uri\n",
      "reconciliation\n",
      "schema\n",
      "node config example\n",
      "preview uri example\n",
      "rdf button\n",
      "skeleton example\n",
      "skeleton example annotated\n",
      "style\n",
      "404\n",
      "docs\n",
      "dump-recon\n",
      "ext Resources\n",
      "faq\n",
      "home-intro\n",
      "home-text\n",
      "installation\n",
      "publications\n",
      "rdf-export-docs\n",
      "rdf-export\n",
      "reconciliation-docs\n",
      "requirements\n",
      "search-recon-doc\n",
      "showcases\n",
      "sindice-docs\n",
      "sindice-recon\n",
      "sparql-recon-doc\n",
      "sparql-recon\n",
      "support-dev\n",
      "team\n",
      "add-service\n",
      "preview\n",
      "results\n",
      "universities\n",
      "earners\n",
      "export\n",
      "operation\n",
      "preview-fb\n",
      "reconcile-fb\n",
      "workspace\n",
      "add-service-2\n",
      "datasets\n",
      "discover datasets\n",
      "autocomplete\n",
      "popup\n",
      "grefine-stuff\n",
      "button-dark-whitebg\n",
      "button-dark\n",
      "icon attention\n",
      "lidrc-logo\n",
      "nuig-logo\n",
      "number1\n",
      "number2\n",
      "number3\n",
      "number4\n",
      "number5\n",
      "number6\n",
      "schema3\n",
      "sfi-logo\n",
      "tabs-dark\n",
      "tabs\n",
      "uri expression\n"
     ]
    }
   ],
   "source": [
    "print(df['filenames'][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the output above that there are 7 repositories which do not have a description. We are going to replace those null values by an empty string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(value=\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to see know how many columns have an empty value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gh_id\n",
      "-----\n",
      "0 articles have no value for column gh_id\n",
      "Int64Index([], dtype='int64')\n",
      "\n",
      "\n",
      "name\n",
      "----\n",
      "0 articles have no value for column name\n",
      "Int64Index([], dtype='int64')\n",
      "\n",
      "\n",
      "description\n",
      "-----------\n",
      "7 articles have no value for column description\n",
      "Int64Index([11, 23, 24, 29, 39, 40, 41], dtype='int64')\n",
      "\n",
      "\n",
      "owner_name\n",
      "----------\n",
      "0 articles have no value for column owner_name\n",
      "Int64Index([], dtype='int64')\n",
      "\n",
      "\n",
      "languages\n",
      "---------\n",
      "0 articles have no value for column languages\n",
      "Int64Index([], dtype='int64')\n",
      "\n",
      "\n",
      "readme_text\n",
      "-----------\n",
      "2 articles have no value for column readme_text\n",
      "Int64Index([8, 39], dtype='int64')\n",
      "\n",
      "\n",
      "issues_text\n",
      "-----------\n",
      "45 articles have no value for column issues_text\n",
      "Int64Index([ 0,  2,  3,  4,  5,  6,  8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20,\n",
      "            21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,\n",
      "            39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
      "           dtype='int64')\n",
      "\n",
      "\n",
      "commits_text\n",
      "------------\n",
      "0 articles have no value for column commits_text\n",
      "Int64Index([], dtype='int64')\n",
      "\n",
      "\n",
      "filenames\n",
      "---------\n",
      "0 articles have no value for column filenames\n",
      "Int64Index([], dtype='int64')\n",
      "\n",
      "\n",
      "comments_text\n",
      "-------------\n",
      "24 articles have no value for column comments_text\n",
      "Int64Index([ 1,  3,  6,  7,  9, 10, 11, 12, 13, 15, 16, 20, 22, 23, 24, 25, 28,\n",
      "            31, 33, 34, 36, 47, 48, 49],\n",
      "           dtype='int64')\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/.envs/edma/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "print_empty_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the repositories (45 out of 50) don't have any issues, and 3 of them don't have a readme.\n",
    "\n",
    "Finally, we are going to join both the description and the readme of each repository into a new column, and remove all extra spaces from that column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LIkelihood Ratio Interpretation of Clinical AbnormaLities. LIRICAL. LIkelihood Ratio Interpretation of Clinical AbnormaLities. LIRICAL is designed to provide clincially interpretable computational analysis of phenotypic abnormalities (encoded using the Human Phenotype Ontology), optionally combined with an analysis of variants and genotypes if a VCF file is provided with the results of diagnostic gene panel, exome, or genome sequencing. Detailed documentation is available This is a useful websit'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean(text):\n",
    "    return re.sub('\\s+', ' ', text).strip()\n",
    "\n",
    "df['full_text'] = df[\"description\"] + \". \" + df[\"readme_text\"]\n",
    "            #\". \" + df[\"comments_text\"] + \\\n",
    "            #\". \" + df[\"commits_text\"]\n",
    "empty_idx = df[df['full_text'] == '. '].index\n",
    "df.loc[empty_idx, 'full_text'] = df.loc[empty_idx, 'commits_text']\n",
    "df['full_text_cleaned'] = df['full_text'].apply(lambda x: clean(x))\n",
    "df['full_text_cleaned'].loc[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish with the contents of this notebook, we will make an initial exploration of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to add a new column to the DataFrame with the length in number of characters of each repo's full text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       50.000000\n",
       "mean      2348.480000\n",
       "std       3235.137547\n",
       "min         12.000000\n",
       "25%        337.250000\n",
       "50%       1751.500000\n",
       "75%       2906.000000\n",
       "max      19317.000000\n",
       "Name: num_chars_text, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['num_chars_text'] = df['full_text_cleaned'].apply(lambda x: len(x))\n",
    "df['num_chars_text'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the average number of characters in the readme + description is about 2471, and the maximum length is 20382 characters. However, 75% of the repositories have a number of characters lower than 3027.\n",
    "\n",
    "We are going to plot this distribution and save it to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"034fe9a1-506d-4c90-819f-26c8ac3aaa41\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"085d4266-a9bb-4d1d-885a-2a989db46006\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\"}],\"center\":[{\"id\":\"1016\"},{\"id\":\"1020\"}],\"left\":[{\"id\":\"1017\"}],\"renderers\":[{\"id\":\"1040\"}],\"title\":{\"id\":\"1003\"},\"toolbar\":{\"id\":\"1028\"},\"x_range\":{\"id\":\"1005\"},\"x_scale\":{\"id\":\"1009\"},\"y_range\":{\"id\":\"1007\"},\"y_scale\":{\"id\":\"1011\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1022\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.7},\"fill_color\":{\"value\":\"mediumslateblue\"},\"left\":{\"field\":\"left\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"num_chars_text\"}},\"id\":\"1037\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1025\"},{\"id\":\"1026\"},{\"id\":\"1042\"}]},\"id\":\"1028\",\"type\":\"Toolbar\"},{\"attributes\":{\"text\":\"Readme + Description length distribution\"},\"id\":\"1003\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1050\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"PanTool\"},{\"attributes\":{\"axis\":{\"id\":\"1013\"},\"ticker\":null},\"id\":\"1016\",\"type\":\"Grid\"},{\"attributes\":{\"axis\":{\"id\":\"1017\"},\"dimension\":1,\"ticker\":null},\"id\":\"1020\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1027\"}},\"id\":\"1023\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1027\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1018\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1046\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"data\":{\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],\"interval\":[\"12 to 784\",\"784 to 1556\",\"1556 to 2328\",\"2328 to 3100\",\"3100 to 3873\",\"3873 to 4645\",\"4645 to 5417\",\"5417 to 6189\",\"6189 to 6961\",\"6961 to 7734\",\"7734 to 8506\",\"8506 to 9278\",\"9278 to 10050\",\"10050 to 10822\",\"10822 to 11595\",\"11595 to 12367\",\"12367 to 13139\",\"13139 to 13911\",\"13911 to 14683\",\"14683 to 15456\",\"15456 to 16228\",\"16228 to 17000\",\"17000 to 17772\",\"17772 to 18544\",\"18544 to 19317\"],\"left\":{\"__ndarray__\":\"AAAAAAAAKECamZmZmYGIQJqZmZmZUZhANDMzMzMxokCamZmZmTmoQAAAAAAAQq5ANDMzMzMlskBnZmZmZim1QJqZmZmZLbhAzczMzMwxu0AAAAAAADa+QJqZmZkZncBANDMzMzMfwkDNzMzMTKHDQGdmZmZmI8VAAAAAAIClxkCamZmZmSfIQDQzMzOzqclAzczMzMwry0BnZmZm5q3MQAAAAAAAMM5AmpmZmRmyz0CamZmZGZrQQGdmZmYmW9FANDMzMzMc0kA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[25]},\"num_chars_text\":[19,5,10,4,5,1,2,0,1,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1],\"right\":{\"__ndarray__\":\"mpmZmZmBiECamZmZmVGYQDQzMzMzMaJAmpmZmZk5qEAAAAAAAEKuQDQzMzMzJbJAZ2ZmZmYptUCamZmZmS24QM3MzMzMMbtAAAAAAAA2vkCamZmZGZ3AQDQzMzMzH8JAzczMzEyhw0BnZmZmZiPFQAAAAACApcZAmpmZmZknyEA0MzMzs6nJQM3MzMzMK8tAZ2ZmZuatzEAAAAAAADDOQJqZmZkZss9AmpmZmRma0EBnZmZmJlvRQDQzMzMzHNJAAAAAAEDd0kA=\",\"dtype\":\"float64\",\"order\":\"little\",\"shape\":[25]}},\"selected\":{\"id\":\"1049\"},\"selection_policy\":{\"id\":\"1050\"}},\"id\":\"1035\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"ResetTool\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"Interval\",\"@interval\"],[\"Count\",\"@num_chars_text\"]]},\"id\":\"1042\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1049\",\"type\":\"Selection\"},{\"attributes\":{\"data_source\":{\"id\":\"1035\"},\"glyph\":{\"id\":\"1037\"},\"hover_glyph\":{\"id\":\"1039\"},\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1038\"},\"selection_glyph\":null,\"view\":{\"id\":\"1041\"}},\"id\":\"1040\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"BasicTicker\"},{\"attributes\":{\"axis_label\":\"Readme and description length (# of characters)\",\"formatter\":{\"id\":\"1048\"},\"ticker\":{\"id\":\"1014\"}},\"id\":\"1013\",\"type\":\"LinearAxis\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_color\":{\"value\":\"slateblue\"},\"left\":{\"field\":\"left\"},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"num_chars_text\"}},\"id\":\"1039\",\"type\":\"Quad\"},{\"attributes\":{\"axis_label\":\"Number of repositories\",\"formatter\":{\"id\":\"1046\"},\"ticker\":{\"id\":\"1018\"}},\"id\":\"1017\",\"type\":\"LinearAxis\"},{\"attributes\":{\"bottom\":{\"value\":0},\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"mediumslateblue\"},\"left\":{\"field\":\"left\"},\"line_alpha\":{\"value\":0.1},\"right\":{\"field\":\"right\"},\"top\":{\"field\":\"num_chars_text\"}},\"id\":\"1038\",\"type\":\"Quad\"},{\"attributes\":{},\"id\":\"1048\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"source\":{\"id\":\"1035\"}},\"id\":\"1041\",\"type\":\"CDSView\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"2.1.1\"}};\n",
       "  var render_items = [{\"docid\":\"085d4266-a9bb-4d1d-885a-2a989db46006\",\"notebook_comms_target\":\"1052\",\"root_ids\":[\"1002\"],\"roots\":{\"1002\":\"034fe9a1-506d-4c90-819f-26c8ac3aaa41\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "GIT_HIST_COLUMN = \"num_chars_text\"\n",
    "GIT_HIST_TITLE = \"Readme + Description length distribution\"\n",
    "GIT_HIST_XLABEL = \"Readme and description length (# of characters)\"\n",
    "GIT_HIST_YLABEL = \"Number of repositories\"\n",
    "\n",
    "hist.load_plot(df, GIT_HIST_COLUMN, GIT_HIST_TITLE,\n",
    "          GIT_HIST_XLABEL, GIT_HIST_YLABEL, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.save_plot(os.path.join(NOTEBOOK_1_RESULTS_DIR, '1_Repo_text_length.svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Languages used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are going to also explore the most used programming languages for each repository.\n",
    "\n",
    "We will begin by creating an auxiliary function that will create an horizontal bar chart with the given data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.palettes import Category20b_20\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "def plot_horizontal_bar_chart(x_data, y_data, title, tooltip_x, tooltip_y,\n",
    "                              sort=True, color_palette=Category20b_20):\n",
    "    sorted_y_data = sorted(y_data, key=lambda x: x_data[y_data.index(x)]) if sort else y_data\n",
    "    source = ColumnDataSource(data=dict(y_data=y_data, x_data=x_data, color=color_palette))\n",
    "    p = figure(y_range=sorted_y_data, x_range=(0, max(x_data) * 1.1), plot_height=750, title=title,\n",
    "               toolbar_location='right')\n",
    "    p.hbar(y='y_data', right='x_data', height=0.7, color='color', legend_field=\"y_data\",\n",
    "           fill_alpha=0.75, hover_fill_alpha=1.0, source=source)\n",
    "    p.ygrid.grid_line_color = None\n",
    "    p.legend.orientation = \"vertical\"\n",
    "    p.legend.location = \"bottom_right\"\n",
    "    p.add_tools(HoverTool(tooltips=[(tooltip_y, \"@y_data\"), (tooltip_x, \"@x_data\")],\n",
    "                          point_policy=\"follow_mouse\"))\n",
    "\n",
    "    show(p, notebook_handle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create new dataframe with each different programming language used in the dataset and the number of bytes belonging to that language for each repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Java</th>\n",
       "      <th>FreeMarker</th>\n",
       "      <th>Python</th>\n",
       "      <th>Prolog</th>\n",
       "      <th>Makefile</th>\n",
       "      <th>Dockerfile</th>\n",
       "      <th>Shell</th>\n",
       "      <th>Ruby</th>\n",
       "      <th>HTML</th>\n",
       "      <th>JavaScript</th>\n",
       "      <th>...</th>\n",
       "      <th>Raku</th>\n",
       "      <th>TSQL</th>\n",
       "      <th>PowerShell</th>\n",
       "      <th>Game Maker Language</th>\n",
       "      <th>Web Ontology Language</th>\n",
       "      <th>PLpgSQL</th>\n",
       "      <th>Gherkin</th>\n",
       "      <th>Common Lisp</th>\n",
       "      <th>ActionScript</th>\n",
       "      <th>C#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>492423.0</td>\n",
       "      <td>13149.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14691.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52724.0</td>\n",
       "      <td>1319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15815.0</td>\n",
       "      <td>9445.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3514431.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28836.0</td>\n",
       "      <td>2559.0</td>\n",
       "      <td>333450.0</td>\n",
       "      <td>967765.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Java  FreeMarker  Python   Prolog  Makefile  Dockerfile    Shell  \\\n",
       "0   492423.0     13149.0   849.0      0.0       0.0         0.0      0.0   \n",
       "1        0.0         0.0     0.0  14691.0    1472.0       700.0    278.0   \n",
       "2        0.0         0.0     0.0      0.0       0.0         0.0      0.0   \n",
       "3        0.0         0.0     0.0      0.0       0.0         0.0  15815.0   \n",
       "4  3514431.0         0.0     0.0      0.0       0.0         0.0  28836.0   \n",
       "\n",
       "      Ruby      HTML  JavaScript  ...  Raku  TSQL  PowerShell  \\\n",
       "0      0.0       0.0         0.0  ...   0.0   0.0         0.0   \n",
       "1      0.0       0.0         0.0  ...   0.0   0.0         0.0   \n",
       "2  52724.0    1319.0         0.0  ...   0.0   0.0         0.0   \n",
       "3   9445.0       0.0         0.0  ...   0.0   0.0         0.0   \n",
       "4   2559.0  333450.0    967765.0  ...   0.0   0.0         0.0   \n",
       "\n",
       "   Game Maker Language  Web Ontology Language  PLpgSQL  Gherkin  Common Lisp  \\\n",
       "0                  0.0                    0.0      0.0      0.0          0.0   \n",
       "1                  0.0                    0.0      0.0      0.0          0.0   \n",
       "2                  0.0                    0.0      0.0      0.0          0.0   \n",
       "3                  0.0                    0.0      0.0      0.0          0.0   \n",
       "4                  0.0                    0.0      0.0      0.0          0.0   \n",
       "\n",
       "   ActionScript   C#  \n",
       "0           0.0  0.0  \n",
       "1           0.0  0.0  \n",
       "2           0.0  0.0  \n",
       "3           0.0  0.0  \n",
       "4           0.0  0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages_df = pd.DataFrame(df['languages'].values.tolist()).fillna(value=0, inplace=False)\n",
    "languages_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By making use of the previously defined function and the new DataFrame we can plot the top 15 languages with the most number of bytes written in each repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"e8c81c01-f115-4a2d-8572-903edac5096b\" data-root-id=\"1207\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"7034d307-2dda-410f-9e39-0487aebca2cb\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1218\"}],\"center\":[{\"id\":\"1221\"},{\"id\":\"1224\"},{\"id\":\"1253\"}],\"left\":[{\"id\":\"1222\"}],\"plot_height\":750,\"renderers\":[{\"id\":\"1243\"}],\"title\":{\"id\":\"1208\"},\"toolbar\":{\"id\":\"1232\"},\"x_range\":{\"id\":\"1210\"},\"x_scale\":{\"id\":\"1214\"},\"y_range\":{\"id\":\"1212\"},\"y_scale\":{\"id\":\"1216\"}},\"id\":\"1207\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"height\":{\"value\":0.7},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"color\"},\"right\":{\"field\":\"x_data\"},\"y\":{\"field\":\"y_data\"}},\"id\":\"1241\",\"type\":\"HBar\"},{\"attributes\":{\"factors\":[\"Vim script\",\"CSS\",\"C++\",\"Game Maker Language\",\"PHP\",\"XSLT\",\"Go\",\"HTML\",\"Ruby\",\"Python\",\"Coq\",\"PostScript\",\"Java\",\"JavaScript\",\"Jupyter Notebook\"]},\"id\":\"1212\",\"type\":\"FactorRange\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1231\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.75},\"fill_color\":{\"field\":\"color\"},\"height\":{\"value\":0.7},\"line_color\":{\"field\":\"color\"},\"right\":{\"field\":\"x_data\"},\"y\":{\"field\":\"y_data\"}},\"id\":\"1240\",\"type\":\"HBar\"},{\"attributes\":{},\"id\":\"1223\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"1226\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1228\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1249\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"items\":[{\"id\":\"1254\"}],\"location\":\"bottom_right\"},\"id\":\"1253\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"1214\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1247\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"text\":\"Languages with the most number of bytes\"},\"id\":\"1208\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1216\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"formatter\":{\"id\":\"1249\"},\"ticker\":{\"id\":\"1219\"}},\"id\":\"1218\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1229\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1230\",\"type\":\"HelpTool\"},{\"attributes\":{\"callback\":null,\"point_policy\":\"follow_mouse\",\"tooltips\":[[\"Language\",\"@y_data\"],[\"Number of bytes\",\"@x_data\"]]},\"id\":\"1255\",\"type\":\"HoverTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1231\"}},\"id\":\"1227\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1219\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"1206\"},\"glyph\":{\"id\":\"1240\"},\"hover_glyph\":{\"id\":\"1242\"},\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1241\"},\"selection_glyph\":null,\"view\":{\"id\":\"1244\"}},\"id\":\"1243\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"axis\":{\"id\":\"1222\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"1224\",\"type\":\"Grid\"},{\"attributes\":{\"data\":{\"color\":[\"#1f77b4\",\"#aec7e8\",\"#ff7f0e\",\"#ffbb78\",\"#2ca02c\",\"#98df8a\",\"#d62728\",\"#ff9896\",\"#9467bd\",\"#c5b0d5\",\"#8c564b\",\"#c49c94\",\"#e377c2\",\"#f7b6d2\",\"#7f7f7f\"],\"x_data\":[43415315.0,36100093.0,24041579.0,20338860.0,7736194.0,4990542.0,3476871.0,2349685.0,2297972.0,1479237.0,1231995.0,1100389.0,989242.0,734741.0,694233.0],\"y_data\":[\"Jupyter Notebook\",\"JavaScript\",\"Java\",\"PostScript\",\"Coq\",\"Python\",\"Ruby\",\"HTML\",\"Go\",\"XSLT\",\"PHP\",\"Game Maker Language\",\"C++\",\"CSS\",\"Vim script\"]},\"selected\":{\"id\":\"1250\"},\"selection_policy\":{\"id\":\"1251\"}},\"id\":\"1206\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"formatter\":{\"id\":\"1247\"},\"ticker\":{\"id\":\"1223\"}},\"id\":\"1222\",\"type\":\"CategoricalAxis\"},{\"attributes\":{},\"id\":\"1225\",\"type\":\"PanTool\"},{\"attributes\":{\"source\":{\"id\":\"1206\"}},\"id\":\"1244\",\"type\":\"CDSView\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1225\"},{\"id\":\"1226\"},{\"id\":\"1227\"},{\"id\":\"1228\"},{\"id\":\"1229\"},{\"id\":\"1230\"},{\"id\":\"1255\"}]},\"id\":\"1232\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1250\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1251\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"fill_color\":{\"field\":\"color\"},\"height\":{\"value\":0.7},\"line_color\":{\"field\":\"color\"},\"right\":{\"field\":\"x_data\"},\"y\":{\"field\":\"y_data\"}},\"id\":\"1242\",\"type\":\"HBar\"},{\"attributes\":{\"axis\":{\"id\":\"1218\"},\"ticker\":null},\"id\":\"1221\",\"type\":\"Grid\"},{\"attributes\":{\"end\":47756846.50000001},\"id\":\"1210\",\"type\":\"Range1d\"},{\"attributes\":{\"label\":{\"field\":\"y_data\"},\"renderers\":[{\"id\":\"1243\"}]},\"id\":\"1254\",\"type\":\"LegendItem\"}],\"root_ids\":[\"1207\"]},\"title\":\"Bokeh Application\",\"version\":\"2.1.1\"}};\n",
       "  var render_items = [{\"docid\":\"7034d307-2dda-410f-9e39-0487aebca2cb\",\"notebook_comms_target\":\"1273\",\"root_ids\":[\"1207\"],\"roots\":{\"1207\":\"e8c81c01-f115-4a2d-8572-903edac5096b\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1207"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.palettes import Category20_15\n",
    "\n",
    "NUM_LANGUAGES = 15\n",
    "\n",
    "languages_sum = languages_df.sum().sort_values(ascending=False)\n",
    "num_bytes = languages_df.sum()[:NUM_LANGUAGES]\n",
    "\n",
    "plot_horizontal_bar_chart(list(languages_sum)[:NUM_LANGUAGES],\n",
    "                          list(languages_sum.keys())[:NUM_LANGUAGES],\n",
    "                          \"Languages with the most number of bytes\",\n",
    "                          \"Number of bytes\", \"Language\",\n",
    "                          color_palette=Category20_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most repositories have code written in Jupyter Notebooks, JavaScript and Java.\n",
    "\n",
    "Although the number of bytes is an interesting measure, some languages tend to have a bigger repository size by nature. In the following cell we are going to select the most prominent language for each repository and plot the most used languages in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"0d16c84f-b39f-46f8-b0a5-06718903f432\" data-root-id=\"1323\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"21676cca-bf2d-4bba-abcc-84ce1ccd40e7\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1334\"}],\"center\":[{\"id\":\"1337\"},{\"id\":\"1340\"},{\"id\":\"1369\"}],\"left\":[{\"id\":\"1338\"}],\"plot_height\":750,\"renderers\":[{\"id\":\"1359\"}],\"title\":{\"id\":\"1324\"},\"toolbar\":{\"id\":\"1348\"},\"x_range\":{\"id\":\"1326\"},\"x_scale\":{\"id\":\"1330\"},\"y_range\":{\"id\":\"1328\"},\"y_scale\":{\"id\":\"1332\"}},\"id\":\"1323\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis\":{\"id\":\"1338\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"1340\",\"type\":\"Grid\"},{\"attributes\":{\"items\":[{\"id\":\"1370\"}],\"location\":\"bottom_right\"},\"id\":\"1369\",\"type\":\"Legend\"},{\"attributes\":{},\"id\":\"1346\",\"type\":\"HelpTool\"},{\"attributes\":{},\"id\":\"1366\",\"type\":\"Selection\"},{\"attributes\":{\"axis\":{\"id\":\"1334\"},\"ticker\":null},\"id\":\"1337\",\"type\":\"Grid\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.75},\"fill_color\":{\"field\":\"color\"},\"height\":{\"value\":0.7},\"line_color\":{\"field\":\"color\"},\"right\":{\"field\":\"x_data\"},\"y\":{\"field\":\"y_data\"}},\"id\":\"1356\",\"type\":\"HBar\"},{\"attributes\":{},\"id\":\"1367\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1363\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1347\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1341\"},{\"id\":\"1342\"},{\"id\":\"1343\"},{\"id\":\"1344\"},{\"id\":\"1345\"},{\"id\":\"1346\"},{\"id\":\"1371\"}]},\"id\":\"1348\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1339\",\"type\":\"CategoricalTicker\"},{\"attributes\":{},\"id\":\"1365\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"text\":\"Top 10 most used languages\"},\"id\":\"1324\",\"type\":\"Title\"},{\"attributes\":{\"fill_color\":{\"field\":\"color\"},\"height\":{\"value\":0.7},\"line_color\":{\"field\":\"color\"},\"right\":{\"field\":\"x_data\"},\"y\":{\"field\":\"y_data\"}},\"id\":\"1358\",\"type\":\"HBar\"},{\"attributes\":{},\"id\":\"1335\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"1322\"},\"glyph\":{\"id\":\"1356\"},\"hover_glyph\":{\"id\":\"1358\"},\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1357\"},\"selection_glyph\":null,\"view\":{\"id\":\"1360\"}},\"id\":\"1359\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null,\"point_policy\":\"follow_mouse\",\"tooltips\":[[\"Language\",\"@y_data\"],[\"Number of repositories\",\"@x_data\"]]},\"id\":\"1371\",\"type\":\"HoverTool\"},{\"attributes\":{\"factors\":[\"Perl\",\"Shell\",\"Prolog\",\"C\",\"C++\",\"Ruby\",\"JavaScript\",\"Python\",\"Jupyter Notebook\",\"Java\"]},\"id\":\"1328\",\"type\":\"FactorRange\"},{\"attributes\":{\"formatter\":{\"id\":\"1365\"},\"ticker\":{\"id\":\"1335\"}},\"id\":\"1334\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1330\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1341\",\"type\":\"PanTool\"},{\"attributes\":{\"overlay\":{\"id\":\"1347\"}},\"id\":\"1343\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"source\":{\"id\":\"1322\"}},\"id\":\"1360\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1342\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1344\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1332\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"data\":{\"color\":[\"#1f77b4\",\"#aec7e8\",\"#ff7f0e\",\"#ffbb78\",\"#2ca02c\",\"#98df8a\",\"#d62728\",\"#ff9896\",\"#9467bd\",\"#c5b0d5\"],\"x_data\":[9,6,6,5,4,3,2,1,1,1],\"y_data\":[\"Java\",\"Python\",\"Jupyter Notebook\",\"JavaScript\",\"Ruby\",\"C++\",\"C\",\"Perl\",\"Shell\",\"Prolog\"]},\"selected\":{\"id\":\"1366\"},\"selection_policy\":{\"id\":\"1367\"}},\"id\":\"1322\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"label\":{\"field\":\"y_data\"},\"renderers\":[{\"id\":\"1359\"}]},\"id\":\"1370\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"1345\",\"type\":\"ResetTool\"},{\"attributes\":{\"end\":9.9},\"id\":\"1326\",\"type\":\"Range1d\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"height\":{\"value\":0.7},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"color\"},\"right\":{\"field\":\"x_data\"},\"y\":{\"field\":\"y_data\"}},\"id\":\"1357\",\"type\":\"HBar\"},{\"attributes\":{\"formatter\":{\"id\":\"1363\"},\"ticker\":{\"id\":\"1339\"}},\"id\":\"1338\",\"type\":\"CategoricalAxis\"}],\"root_ids\":[\"1323\"]},\"title\":\"Bokeh Application\",\"version\":\"2.1.1\"}};\n",
       "  var render_items = [{\"docid\":\"21676cca-bf2d-4bba-abcc-84ce1ccd40e7\",\"notebook_comms_target\":\"1397\",\"root_ids\":[\"1323\"],\"roots\":{\"1323\":\"0d16c84f-b39f-46f8-b0a5-06718903f432\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1323"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.palettes import Category20_10\n",
    "\n",
    "most_used_languages = languages_df.idxmax(axis=1).value_counts()[:10]\n",
    "plot_horizontal_bar_chart(list(most_used_languages),\n",
    "                          list(most_used_languages.keys()),\n",
    "                          \"Top 10 most used languages\",\n",
    "                          \"Number of repositories\", \"Language\",\n",
    "                          color_palette=Category20_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this new measure the top order has changed a bit. Both JavaScript and Jupyter Notebooks remain in the top 5, but they have fallen some positions to both Java and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are going to serialize the dataframe so we can load it later on in the following notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIT_DF_FILE_PATH = os.path.join(NOTEBOOK_1_RESULTS_DIR, 'git_dataframe.pkl')\n",
    "\n",
    "df.to_pickle(GIT_DF_FILE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
