{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluation of results\n",
    "In this final notebook we will propose an evaluation metric to check the performance and our final systems on the git track. Since none of the track repositories had a category to use as ground truth to compare our results against, a manual labelling of the repositories was made by an external group of people. This labelled data will be used as ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run __init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "GIT_FILE_PATH = os.path.join(NOTEBOOK_1_RESULTS_DIR, 'git_dataframe.pkl')\n",
    "\n",
    "git_df = pd.read_pickle(GIT_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo_url</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/cmungall/LIRICAL/</td>\n",
       "      <td>Java, diagnosis, human phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/cmungall/wikidata_ontomatcher</td>\n",
       "      <td>Prolog, Wikidata, ontology matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/markwilkinson/ro-crate-ruby</td>\n",
       "      <td>Ruby, RO Crate, Research Objects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/markwilkinson/Misc_Training...</td>\n",
       "      <td>database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/mikel-egana-aranguren/FAIRi...</td>\n",
       "      <td>FAIR data, OpenRefine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            repo_url  \\\n",
       "0               https://github.com/cmungall/LIRICAL/   \n",
       "1   https://github.com/cmungall/wikidata_ontomatcher   \n",
       "2     https://github.com/markwilkinson/ro-crate-ruby   \n",
       "3  https://github.com/markwilkinson/Misc_Training...   \n",
       "4  https://github.com/mikel-egana-aranguren/FAIRi...   \n",
       "\n",
       "                                topics  \n",
       "0     Java, diagnosis, human phenotype  \n",
       "1  Prolog, Wikidata, ontology matching  \n",
       "2     Ruby, RO Crate, Research Objects  \n",
       "3                             database  \n",
       "4                FAIR data, OpenRefine  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "LABELLED_GIT_FILE_PATH = os.path.join(NOTEBOOK_7_RESULTS_DIR, 'labelled_git_repos.csv')\n",
    "\n",
    "labelled_git_df = pd.read_csv(LABELLED_GIT_FILE_PATH, sep=';')\n",
    "labelled_git_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the categories\n",
    "We will begin by selecting a subset of the protocols dataframe with just the id of the protocol and its categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gh_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>owner_name</th>\n",
       "      <th>languages</th>\n",
       "      <th>readme_text</th>\n",
       "      <th>issues_text</th>\n",
       "      <th>commits_text</th>\n",
       "      <th>filenames</th>\n",
       "      <th>comments_text</th>\n",
       "      <th>full_text</th>\n",
       "      <th>full_text_cleaned</th>\n",
       "      <th>num_chars_text</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216602979</td>\n",
       "      <td>LIRICAL</td>\n",
       "      <td>LIkelihood Ratio Interpretation of Clinical Ab...</td>\n",
       "      <td>cmungall</td>\n",
       "      <td>{'Java': 492423, 'FreeMarker': 13149, 'Python'...</td>\n",
       "      <td>LIRICAL.  LIkelihood Ratio Interpretation of C...</td>\n",
       "      <td></td>\n",
       "      <td>Merge pull request #442 from TheJacksonLaborat...</td>\n",
       "      <td>\\nCHANGELOG\\nREADME\\nhoxc13 output\\nlirical to...</td>\n",
       "      <td>note that the Jannovar dependency does not nee...</td>\n",
       "      <td>LIkelihood Ratio Interpretation of Clinical Ab...</td>\n",
       "      <td>LIkelihood Ratio Interpretation of Clinical Ab...</td>\n",
       "      <td>3770</td>\n",
       "      <td>https://github.com/cmungall/LIRICAL/</td>\n",
       "      <td>Java, diagnosis, human phenotype</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199330464</td>\n",
       "      <td>wikidata_ontomatcher</td>\n",
       "      <td>Matches ontology classes against wikidata</td>\n",
       "      <td>cmungall</td>\n",
       "      <td>{'Prolog': 14691, 'Makefile': 1472, 'Dockerfil...</td>\n",
       "      <td>Match an ontology to Wikidata. This applicatio...</td>\n",
       "      <td>Will help with #1 and with https://github.com/...</td>\n",
       "      <td>Adding skos:altLabel\\n\\nhttps://github.com/cmu...</td>\n",
       "      <td>\\nREADME\\ninstall\\npack\\nwikidata ontomatcher\\...</td>\n",
       "      <td></td>\n",
       "      <td>Matches ontology classes against wikidata. Mat...</td>\n",
       "      <td>Matches ontology classes against wikidata. Mat...</td>\n",
       "      <td>519</td>\n",
       "      <td>https://github.com/cmungall/wikidata_ontomatcher</td>\n",
       "      <td>Prolog, Wikidata, ontology matching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253207181</td>\n",
       "      <td>ro-crate-ruby</td>\n",
       "      <td>A Ruby gem for creating, manipulating and read...</td>\n",
       "      <td>markwilkinson</td>\n",
       "      <td>{'Ruby': 52724, 'HTML': 1319}</td>\n",
       "      <td>ro-crate-ruby. This is a WIP gem for creating,...</td>\n",
       "      <td></td>\n",
       "      <td>Update LICENSE\\nBump version\\nTidy up and chec...</td>\n",
       "      <td>\\n travis\\nGemfile\\nREADME\\nROCrate\\nContact P...</td>\n",
       "      <td>*\\n * Expands the tree to the target element a...</td>\n",
       "      <td>A Ruby gem for creating, manipulating and read...</td>\n",
       "      <td>A Ruby gem for creating, manipulating and read...</td>\n",
       "      <td>2559</td>\n",
       "      <td>https://github.com/markwilkinson/ro-crate-ruby</td>\n",
       "      <td>Ruby, RO Crate, Research Objects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212556220</td>\n",
       "      <td>Misc_Training_scripts</td>\n",
       "      <td>A place for me to keep various miscellanelous ...</td>\n",
       "      <td>markwilkinson</td>\n",
       "      <td>{'Shell': 15815, 'Ruby': 9445}</td>\n",
       "      <td>Misc_Training_scripts. A place for me to keep ...</td>\n",
       "      <td></td>\n",
       "      <td>added new cool 3-federated query\\nfinished edi...</td>\n",
       "      <td>README\\nSpecies Abundance Pub2015\\nSpecies Inf...</td>\n",
       "      <td></td>\n",
       "      <td>A place for me to keep various miscellanelous ...</td>\n",
       "      <td>A place for me to keep various miscellanelous ...</td>\n",
       "      <td>545</td>\n",
       "      <td>https://github.com/markwilkinson/Misc_Training...</td>\n",
       "      <td>database</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gh_id                   name  \\\n",
       "0  216602979                LIRICAL   \n",
       "1  199330464   wikidata_ontomatcher   \n",
       "2  253207181          ro-crate-ruby   \n",
       "3  212556220  Misc_Training_scripts   \n",
       "\n",
       "                                         description     owner_name  \\\n",
       "0  LIkelihood Ratio Interpretation of Clinical Ab...       cmungall   \n",
       "1          Matches ontology classes against wikidata       cmungall   \n",
       "2  A Ruby gem for creating, manipulating and read...  markwilkinson   \n",
       "3  A place for me to keep various miscellanelous ...  markwilkinson   \n",
       "\n",
       "                                           languages  \\\n",
       "0  {'Java': 492423, 'FreeMarker': 13149, 'Python'...   \n",
       "1  {'Prolog': 14691, 'Makefile': 1472, 'Dockerfil...   \n",
       "2                      {'Ruby': 52724, 'HTML': 1319}   \n",
       "3                     {'Shell': 15815, 'Ruby': 9445}   \n",
       "\n",
       "                                         readme_text  \\\n",
       "0  LIRICAL.  LIkelihood Ratio Interpretation of C...   \n",
       "1  Match an ontology to Wikidata. This applicatio...   \n",
       "2  ro-crate-ruby. This is a WIP gem for creating,...   \n",
       "3  Misc_Training_scripts. A place for me to keep ...   \n",
       "\n",
       "                                         issues_text  \\\n",
       "0                                                      \n",
       "1  Will help with #1 and with https://github.com/...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "\n",
       "                                        commits_text  \\\n",
       "0  Merge pull request #442 from TheJacksonLaborat...   \n",
       "1  Adding skos:altLabel\\n\\nhttps://github.com/cmu...   \n",
       "2  Update LICENSE\\nBump version\\nTidy up and chec...   \n",
       "3  added new cool 3-federated query\\nfinished edi...   \n",
       "\n",
       "                                           filenames  \\\n",
       "0  \\nCHANGELOG\\nREADME\\nhoxc13 output\\nlirical to...   \n",
       "1  \\nREADME\\ninstall\\npack\\nwikidata ontomatcher\\...   \n",
       "2  \\n travis\\nGemfile\\nREADME\\nROCrate\\nContact P...   \n",
       "3  README\\nSpecies Abundance Pub2015\\nSpecies Inf...   \n",
       "\n",
       "                                       comments_text  \\\n",
       "0  note that the Jannovar dependency does not nee...   \n",
       "1                                                      \n",
       "2  *\\n * Expands the tree to the target element a...   \n",
       "3                                                      \n",
       "\n",
       "                                           full_text  \\\n",
       "0  LIkelihood Ratio Interpretation of Clinical Ab...   \n",
       "1  Matches ontology classes against wikidata. Mat...   \n",
       "2  A Ruby gem for creating, manipulating and read...   \n",
       "3  A place for me to keep various miscellanelous ...   \n",
       "\n",
       "                                   full_text_cleaned  num_chars_text  \\\n",
       "0  LIkelihood Ratio Interpretation of Clinical Ab...            3770   \n",
       "1  Matches ontology classes against wikidata. Mat...             519   \n",
       "2  A Ruby gem for creating, manipulating and read...            2559   \n",
       "3  A place for me to keep various miscellanelous ...             545   \n",
       "\n",
       "                                            repo_url  \\\n",
       "0               https://github.com/cmungall/LIRICAL/   \n",
       "1   https://github.com/cmungall/wikidata_ontomatcher   \n",
       "2     https://github.com/markwilkinson/ro-crate-ruby   \n",
       "3  https://github.com/markwilkinson/Misc_Training...   \n",
       "\n",
       "                                topics  \n",
       "0     Java, diagnosis, human phenotype  \n",
       "1  Prolog, Wikidata, ontology matching  \n",
       "2     Ruby, RO Crate, Research Objects  \n",
       "3                             database  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "categories_df = pd.concat([git_df, labelled_git_df], axis=1)\n",
    "categories_df['topics'].replace('', np.nan, inplace=True)\n",
    "categories_df.dropna(subset=['topics'], inplace=True)\n",
    "categories_df.head(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ruby', 'RO Crate', 'Research Objects']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_categories = {str(aid): [t.strip() for t in categories.split(',')]\n",
    "                    for aid, categories in zip(categories_df['gh_id'].values,\n",
    "                                               categories_df['topics'].values)}\n",
    "repos_categories['253207181']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, each protocol is composed of a variable sized list of category terms.\n",
    "\n",
    "In the following cell we are going to perform a cleaning of the categories to remove those that will not be useful for the evaluation of our models. We will remove those words that do not have a match to WordNet, which will be used later on to perform the evaluation of the models. Finally, those rows that do not have any caetgory will be removed from the final sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from herc_common.evaluation import _get_synset\n",
    "\n",
    "\n",
    "filtered_repos_categories = {\n",
    "    k: set([el for el in v if not el.isnumeric()\n",
    "            and _get_synset(el) is not None])\n",
    "    for k, v in repos_categories.items()\n",
    "}\n",
    "\n",
    "final_repos_categories = {\n",
    "    k: v\n",
    "    for k, v in filtered_repos_categories.items()\n",
    "    if len(v) != 0\n",
    "}\n",
    "\n",
    "len(final_repos_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'216602979': {'Java', 'diagnosis'},\n",
       " '199330464': {'Prolog'},\n",
       " '253207181': {'Ruby'},\n",
       " '212556220': {'database'},\n",
       " '90349931': {'Java'},\n",
       " '126633812': {'classification', 'music'},\n",
       " '173520377': {'Python'},\n",
       " '103798851': {'Algorithms', 'C'},\n",
       " '153249816': {'Python'},\n",
       " '170129937': {'R', 'evaluation'},\n",
       " '57412597': {'R'},\n",
       " '46532803': {'C', 'DNA'},\n",
       " '95547920': {'Python'},\n",
       " '94098106': {'Java'},\n",
       " '83849237': {'vim'},\n",
       " '83414669': {'teaching'},\n",
       " '56680034': {'Python', 'genetics'},\n",
       " '231038084': {'R', 'correlation'},\n",
       " '14387064': {'Ruby'},\n",
       " '212904362': {'mathematics'},\n",
       " '113264497': {'reasoner'},\n",
       " '260889871': {'Rust', 'algorithms'},\n",
       " '161862375': {'Groovy', 'plants', 'plots', 'proteins'},\n",
       " '171842501': {'Ruby', 'docker'},\n",
       " '257154635': {'HTML', 'Python'},\n",
       " '260966843': {'genome', 'graphs'},\n",
       " '257545116': {'Docker', 'biomedicine'},\n",
       " '150747903': {'Python', 'TERMite'},\n",
       " '151696606': {'Java', 'Termite'},\n",
       " '126086017': {'Python'},\n",
       " '150911020': {'Python'},\n",
       " '254755549': {'Python', 'annotation'},\n",
       " '3103186': {'libraries'},\n",
       " '3103225': {'Java'},\n",
       " '22713247': {'English', 'Shell'},\n",
       " '21820701': {'Java', 'score'},\n",
       " '34799405': {'Java', 'OWL'},\n",
       " '42526998': {'Python', 'ontology', 'searching'},\n",
       " '238953196': {'React', 'demo', 'forms'},\n",
       " '157134523': {'Python', 'teaching'},\n",
       " '193684604': {'Ruby'},\n",
       " '33901216': {'reasoning'},\n",
       " '13978110': {'Java'},\n",
       " '258719463': {'spreadsheet', 'web'},\n",
       " '113915480': {'ASP'},\n",
       " '223272173': {'Python', 'generalization', 'psychology'},\n",
       " '248895581': {'tools'},\n",
       " '223627473': {'Python', 'basketball'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_repos_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, from the initial 100 protocols in the dataframe 96 have at least a category to be compared against."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "For the evaluation of our system we will use WordNet to obtain a semantic similarity score between the topics predicted by our system and those used as ground truth.\n",
    "\n",
    "Before we can start calculating these similarity scores, we will obtain the topics predicted by our system. First, we will be loading the final pipeline that has been saved in our previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1fa6b9ef708>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "import en_core_sci_lg\n",
    "import en_core_web_md\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "en_core_web_md.load()\n",
    "en_core_sci_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from herc_common.utils import load_object\n",
    "\n",
    "final_pipe = load_object(os.path.join(NOTEBOOK_6_RESULTS_DIR, 'final_pipe.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will select the sample of publications with at least one ground truth subject, and obtain the output of our system for those articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_keys = [int(k) for k in final_repos_categories.keys()]\n",
    "X = categories_df.set_index('gh_id', inplace=False).loc[repos_keys]['full_text_cleaned'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e528370620d041eea639c0ce845beb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f060ea820ebd4f72b48106fe0ace55d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_base = final_repos_categories.values()\n",
    "y_pred = final_pipe.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['computer science',\n",
       "  'software',\n",
       "  'artificial intelligence',\n",
       "  'interaction science',\n",
       "  'engineering',\n",
       "  'automation',\n",
       "  'statistics'],\n",
       " ['Wikidata',\n",
       "  'online database',\n",
       "  'knowledge base',\n",
       "  'semantic wiki',\n",
       "  'knowledge graph',\n",
       "  'Linked Open Data cloud diagram',\n",
       "  'Semantic Web'],\n",
       " ['information',\n",
       "  'abstract object',\n",
       "  'advertising',\n",
       "  'data',\n",
       "  'creative work',\n",
       "  'level',\n",
       "  'message'],\n",
       " ['species',\n",
       "  'taxonomic rank',\n",
       "  'subgenus',\n",
       "  'rank',\n",
       "  'subseries',\n",
       "  'rank',\n",
       "  'population'],\n",
       " ['minute',\n",
       "  'branch of science',\n",
       "  'construction',\n",
       "  'specialty',\n",
       "  'occupation',\n",
       "  'education',\n",
       "  'statistics']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [[str(topic[0]) for topic in doc] for doc in y_pred]\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity\n",
    "In this section we will be calculating the similarity scores between the topics inferred by the model and the ones used as ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max similarity': 1.4403615823901665,\n",
       "  'min similarity': 1.072636802264849,\n",
       "  'mean similarity': 1.2564991923275077,\n",
       "  'median similarity': 1.2564991923275077},\n",
       " {'max similarity': 1.3350010667323402,\n",
       "  'min similarity': 1.3350010667323402,\n",
       "  'mean similarity': 1.3350010667323402,\n",
       "  'median similarity': 1.3350010667323402},\n",
       " {'max similarity': 1.072636802264849,\n",
       "  'min similarity': 1.072636802264849,\n",
       "  'mean similarity': 1.072636802264849,\n",
       "  'median similarity': 1.072636802264849},\n",
       " {'max similarity': 1.55814461804655,\n",
       "  'min similarity': 1.55814461804655,\n",
       "  'mean similarity': 1.55814461804655,\n",
       "  'median similarity': 1.55814461804655},\n",
       " {'max similarity': 1.3350010667323402,\n",
       "  'min similarity': 1.3350010667323402,\n",
       "  'mean similarity': 1.3350010667323402,\n",
       "  'median similarity': 1.3350010667323402}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus.reader.wordnet import WordNetError\n",
    "import pdb\n",
    "\n",
    "\n",
    "def compute_similarity_scores(topics_base, topics_pred, similarity_func):\n",
    "    scores_matrix = get_scores_matrix(topics_base, topics_pred, similarity_func)\n",
    "    return obtain_associations_scores(scores_matrix)\n",
    "        \n",
    "\n",
    "def get_scores_matrix(topics_base, topics_pred, similarity_func):\n",
    "    sim_measures = []\n",
    "    for topic_p in topics_pred:\n",
    "        p_synset = _get_synset(topic_p)\n",
    "        if p_synset is None:\n",
    "            array_len = len(topics_base)\n",
    "            a = np.empty(array_len)\n",
    "            a[:] = np.nan\n",
    "            sim_measures.append(a)\n",
    "            continue\n",
    "\n",
    "        topic_sim_measures = []\n",
    "        for topic_b in topics_base:\n",
    "            b_synset = _get_synset(topic_b)\n",
    "            if b_synset is None:\n",
    "                topic_sim_measures.append(np.nan)\n",
    "                continue\n",
    "            try:\n",
    "                similarity = getattr(p_synset, similarity_func)(b_synset)\n",
    "                topic_sim_measures.append(similarity)\n",
    "            except WordNetError:\n",
    "                # comparing synsets with different POS\n",
    "                topic_sim_measures.append(np.nan)\n",
    "                continue\n",
    "        sim_measures.append(topic_sim_measures)\n",
    "    return np.array(sim_measures)\n",
    "\n",
    "def obtain_associations_scores(scores_matrix):\n",
    "    scores_matrix = _remove_nan_rows(scores_matrix)\n",
    "    scores_matrix = _remove_nan_cols(scores_matrix)\n",
    "    n = scores_matrix.shape[0]\n",
    "    m = scores_matrix.shape[1]\n",
    "    if n < m:\n",
    "        sim_measures = np.nanmax(scores_matrix, axis=1)\n",
    "    else:\n",
    "        sim_measures = np.nanmax(scores_matrix, axis=0)\n",
    "    return {\n",
    "        'max similarity': np.max(sim_measures),\n",
    "        'min similarity': np.min(sim_measures),\n",
    "        'mean similarity': np.mean(sim_measures),\n",
    "        'median similarity': np.median(sim_measures)\n",
    "    }\n",
    "\n",
    "def _get_synset(word):\n",
    "    try:\n",
    "        word = '_'.join(word.split(' '))\n",
    "        return wn.synsets(word)[0]\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "def _remove_nan_rows(m):\n",
    "    return m[~np.all(np.isnan(m), axis=1), :]\n",
    "\n",
    "def _remove_nan_cols(m):\n",
    "    return m[:, ~np.all(np.isnan(m), axis=0)]\n",
    "\n",
    "\n",
    "scores = [compute_similarity_scores(y_b, y_p, 'lch_similarity')\n",
    "          for y_b, y_p in zip(y_base, y_pred)]\n",
    "scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.31958798808627"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_similarity = np.mean([score['mean similarity'] for score in scores])\n",
    "final_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the results\n",
    "Finally, we are going to save the results. First of all, the predictions will be saved to a new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>topics</th>\n",
       "      <th>Topics Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gh_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216602979</th>\n",
       "      <td>LIRICAL</td>\n",
       "      <td>Java\\ndiagnosis</td>\n",
       "      <td>computer science\\nsoftware\\nartificial intelli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199330464</th>\n",
       "      <td>wikidata_ontomatcher</td>\n",
       "      <td>Prolog</td>\n",
       "      <td>Wikidata\\nonline database\\nknowledge base\\nsem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253207181</th>\n",
       "      <td>ro-crate-ruby</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>information\\nabstract object\\nadvertising\\ndat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212556220</th>\n",
       "      <td>Misc_Training_scripts</td>\n",
       "      <td>database</td>\n",
       "      <td>species\\ntaxonomic rank\\nsubgenus\\nrank\\nsubse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90349931</th>\n",
       "      <td>elda</td>\n",
       "      <td>Java</td>\n",
       "      <td>minute\\nbranch of science\\nconstruction\\nspeci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name           topics  \\\n",
       "gh_id                                               \n",
       "216602979                LIRICAL  Java\\ndiagnosis   \n",
       "199330464   wikidata_ontomatcher           Prolog   \n",
       "253207181          ro-crate-ruby             Ruby   \n",
       "212556220  Misc_Training_scripts         database   \n",
       "90349931                    elda             Java   \n",
       "\n",
       "                                            Topics Predicted  \n",
       "gh_id                                                         \n",
       "216602979  computer science\\nsoftware\\nartificial intelli...  \n",
       "199330464  Wikidata\\nonline database\\nknowledge base\\nsem...  \n",
       "253207181  information\\nabstract object\\nadvertising\\ndat...  \n",
       "212556220  species\\ntaxonomic rank\\nsubgenus\\nrank\\nsubse...  \n",
       "90349931   minute\\nbranch of science\\nconstruction\\nspeci...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_subset = ['name', 'topics']\n",
    "\n",
    "results_df = categories_df.set_index('gh_id', inplace=False).loc[repos_keys][cols_subset]\n",
    "results_df['Topics Predicted'] = ['\\n'.join(topics) for topics in y_pred]\n",
    "results_df['topics'] = ['\\n'.join(topics) for topics in y_base]\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max similarity</th>\n",
       "      <th>min similarity</th>\n",
       "      <th>mean similarity</th>\n",
       "      <th>median similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gh_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216602979</th>\n",
       "      <td>1.440362</td>\n",
       "      <td>1.072637</td>\n",
       "      <td>1.256499</td>\n",
       "      <td>1.256499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199330464</th>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.335001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253207181</th>\n",
       "      <td>1.072637</td>\n",
       "      <td>1.072637</td>\n",
       "      <td>1.072637</td>\n",
       "      <td>1.072637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212556220</th>\n",
       "      <td>1.558145</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>1.558145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90349931</th>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.335001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           max similarity  min similarity  mean similarity  median similarity\n",
       "gh_id                                                                        \n",
       "216602979        1.440362        1.072637         1.256499           1.256499\n",
       "199330464        1.335001        1.335001         1.335001           1.335001\n",
       "253207181        1.072637        1.072637         1.072637           1.072637\n",
       "212556220        1.558145        1.558145         1.558145           1.558145\n",
       "90349931         1.335001        1.335001         1.335001           1.335001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame.from_records(scores)\n",
    "scores_df.set_index(results_df.index, inplace=True)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the scores obtained for each protocol will be saved too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>topics</th>\n",
       "      <th>Topics Predicted</th>\n",
       "      <th>max similarity</th>\n",
       "      <th>min similarity</th>\n",
       "      <th>mean similarity</th>\n",
       "      <th>median similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gh_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216602979</th>\n",
       "      <td>LIRICAL</td>\n",
       "      <td>Java\\ndiagnosis</td>\n",
       "      <td>computer science\\nsoftware\\nartificial intelli...</td>\n",
       "      <td>1.440362</td>\n",
       "      <td>1.072637</td>\n",
       "      <td>1.256499</td>\n",
       "      <td>1.256499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199330464</th>\n",
       "      <td>wikidata_ontomatcher</td>\n",
       "      <td>Prolog</td>\n",
       "      <td>Wikidata\\nonline database\\nknowledge base\\nsem...</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.335001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253207181</th>\n",
       "      <td>ro-crate-ruby</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>information\\nabstract object\\nadvertising\\ndat...</td>\n",
       "      <td>1.072637</td>\n",
       "      <td>1.072637</td>\n",
       "      <td>1.072637</td>\n",
       "      <td>1.072637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212556220</th>\n",
       "      <td>Misc_Training_scripts</td>\n",
       "      <td>database</td>\n",
       "      <td>species\\ntaxonomic rank\\nsubgenus\\nrank\\nsubse...</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>1.558145</td>\n",
       "      <td>1.558145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90349931</th>\n",
       "      <td>elda</td>\n",
       "      <td>Java</td>\n",
       "      <td>minute\\nbranch of science\\nconstruction\\nspeci...</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.335001</td>\n",
       "      <td>1.335001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name           topics  \\\n",
       "gh_id                                               \n",
       "216602979                LIRICAL  Java\\ndiagnosis   \n",
       "199330464   wikidata_ontomatcher           Prolog   \n",
       "253207181          ro-crate-ruby             Ruby   \n",
       "212556220  Misc_Training_scripts         database   \n",
       "90349931                    elda             Java   \n",
       "\n",
       "                                            Topics Predicted  max similarity  \\\n",
       "gh_id                                                                          \n",
       "216602979  computer science\\nsoftware\\nartificial intelli...        1.440362   \n",
       "199330464  Wikidata\\nonline database\\nknowledge base\\nsem...        1.335001   \n",
       "253207181  information\\nabstract object\\nadvertising\\ndat...        1.072637   \n",
       "212556220  species\\ntaxonomic rank\\nsubgenus\\nrank\\nsubse...        1.558145   \n",
       "90349931   minute\\nbranch of science\\nconstruction\\nspeci...        1.335001   \n",
       "\n",
       "           min similarity  mean similarity  median similarity  \n",
       "gh_id                                                          \n",
       "216602979        1.072637         1.256499           1.256499  \n",
       "199330464        1.335001         1.335001           1.335001  \n",
       "253207181        1.072637         1.072637           1.072637  \n",
       "212556220        1.558145         1.558145           1.558145  \n",
       "90349931         1.335001         1.335001           1.335001  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = results_df.join(scores_df)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(os.path.join(NOTEBOOK_7_RESULTS_DIR, 'repos_scores.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
