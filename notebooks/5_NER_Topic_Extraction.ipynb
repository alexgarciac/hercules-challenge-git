{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Topic extraction from NER\n",
    "In this notebook we are going to perform a selection of topics from the entities recognized in each article. The process will be as follows:\n",
    "* The Named Entity Recognizer object created in notebook _4_Named_Entity_Recognition_ will be loaded.\n",
    "* The list of entities for a given text will be retrieved.\n",
    "* After we have the list of entities, they will be linked to Wikidata.\n",
    "* From the list of linked entities, we will create a graph with the Wikidata entities obtained by expanding some of their properties.\n",
    "* Once the graph has been obtained, we will apply centrality algotihms to select the most representative entities from  it, which will serve as topics for the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run __init__.py\n",
    "\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/.envs/edma/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "We will start by loading the agriculture dataframe created in notebook 2. After that, we will select the last article to demonstrate what the main data workflow will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "GIT_FILE_PATH = os.path.join(NOTEBOOK_1_RESULTS_DIR, 'git_dataframe.pkl')\n",
    "\n",
    "git_df = pd.read_pickle(GIT_FILE_PATH)\n",
    "git_repositories = git_df['full_text_cleaned'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gh_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>owner_name</th>\n",
       "      <th>languages</th>\n",
       "      <th>readme_text</th>\n",
       "      <th>issues_text</th>\n",
       "      <th>commits_text</th>\n",
       "      <th>filenames</th>\n",
       "      <th>comments_text</th>\n",
       "      <th>full_text</th>\n",
       "      <th>full_text_cleaned</th>\n",
       "      <th>num_chars_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216602979</td>\n",
       "      <td>LIRICAL</td>\n",
       "      <td>LIkelihood Ratio Interpretation of Clinical Ab...</td>\n",
       "      <td>cmungall</td>\n",
       "      <td>{'Java': 492423, 'FreeMarker': 13149, 'Python'...</td>\n",
       "      <td>LIRICAL.  LIkelihood Ratio Interpretation of C...</td>\n",
       "      <td></td>\n",
       "      <td>Merge pull request #442 from TheJacksonLaborat...</td>\n",
       "      <td>\\nCHANGELOG\\nREADME\\nhoxc13 output\\nlirical to...</td>\n",
       "      <td>note that the Jannovar dependency does not nee...</td>\n",
       "      <td>LIkelihood Ratio Interpretation of Clinical Ab...</td>\n",
       "      <td>LIkelihood Ratio Interpretation of Clinical Ab...</td>\n",
       "      <td>3770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199330464</td>\n",
       "      <td>wikidata_ontomatcher</td>\n",
       "      <td>Matches ontology classes against wikidata</td>\n",
       "      <td>cmungall</td>\n",
       "      <td>{'Prolog': 14691, 'Makefile': 1472, 'Dockerfil...</td>\n",
       "      <td>Match an ontology to Wikidata. This applicatio...</td>\n",
       "      <td>Will help with #1 and with https://github.com/...</td>\n",
       "      <td>Adding skos:altLabel\\n\\nhttps://github.com/cmu...</td>\n",
       "      <td>\\nREADME\\ninstall\\npack\\nwikidata ontomatcher\\...</td>\n",
       "      <td></td>\n",
       "      <td>Matches ontology classes against wikidata. Mat...</td>\n",
       "      <td>Matches ontology classes against wikidata. Mat...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253207181</td>\n",
       "      <td>ro-crate-ruby</td>\n",
       "      <td>A Ruby gem for creating, manipulating and read...</td>\n",
       "      <td>markwilkinson</td>\n",
       "      <td>{'Ruby': 52724, 'HTML': 1319}</td>\n",
       "      <td>ro-crate-ruby. This is a WIP gem for creating,...</td>\n",
       "      <td></td>\n",
       "      <td>Update LICENSE\\nBump version\\nTidy up and chec...</td>\n",
       "      <td>\\n travis\\nGemfile\\nREADME\\nROCrate\\nContact P...</td>\n",
       "      <td>*\\n * Expands the tree to the target element a...</td>\n",
       "      <td>A Ruby gem for creating, manipulating and read...</td>\n",
       "      <td>A Ruby gem for creating, manipulating and read...</td>\n",
       "      <td>2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212556220</td>\n",
       "      <td>Misc_Training_scripts</td>\n",
       "      <td>A place for me to keep various miscellanelous ...</td>\n",
       "      <td>markwilkinson</td>\n",
       "      <td>{'Shell': 15815, 'Ruby': 9445}</td>\n",
       "      <td>Misc_Training_scripts. A place for me to keep ...</td>\n",
       "      <td></td>\n",
       "      <td>added new cool 3-federated query\\nfinished edi...</td>\n",
       "      <td>README\\nSpecies Abundance Pub2015\\nSpecies Inf...</td>\n",
       "      <td></td>\n",
       "      <td>A place for me to keep various miscellanelous ...</td>\n",
       "      <td>A place for me to keep various miscellanelous ...</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155879756</td>\n",
       "      <td>FAIRifier</td>\n",
       "      <td>A tool to make data FAIR</td>\n",
       "      <td>mikel-egana-aranguren</td>\n",
       "      <td>{'Java': 3514431, 'JavaScript': 967765, 'HTML'...</td>\n",
       "      <td>Dependencies: Java 8. Apache Ant. Building. in...</td>\n",
       "      <td></td>\n",
       "      <td>Merge pull request #16 from Shamanou/developme...</td>\n",
       "      <td>\\norg eclipse core resources\\norg eclipse jdt ...</td>\n",
       "      <td>*\\n * Main class for Refine server application...</td>\n",
       "      <td>A tool to make data FAIR. Dependencies: Java 8...</td>\n",
       "      <td>A tool to make data FAIR. Dependencies: Java 8...</td>\n",
       "      <td>57859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90349931</td>\n",
       "      <td>elda</td>\n",
       "      <td>Epimorphics implementation of the Linked Data API</td>\n",
       "      <td>mikel-egana-aranguren</td>\n",
       "      <td>{'Java': 1892893, 'JavaScript': 1757647, 'XSLT...</td>\n",
       "      <td>Elda, an implementation of the Linked Data API...</td>\n",
       "      <td></td>\n",
       "      <td>Proper reference Config\\nConfiguracion ELDA de...</td>\n",
       "      <td>\\nCONTRIBUTING\\nLICENCE\\nREADME demo\\nREADME\\n...</td>\n",
       "      <td>Everything that's part of the resource set is ...</td>\n",
       "      <td>Epimorphics implementation of the Linked Data ...</td>\n",
       "      <td>Epimorphics implementation of the Linked Data ...</td>\n",
       "      <td>15907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>126633812</td>\n",
       "      <td>music-genre-classification</td>\n",
       "      <td>Recognizing the genre of music files using mac...</td>\n",
       "      <td>HareeshBahuleyan</td>\n",
       "      <td>{'Jupyter Notebook': 7532041, 'Python': 8296}</td>\n",
       "      <td>Music Genre Classification.  \\n Overview. Reco...</td>\n",
       "      <td></td>\n",
       "      <td>Update LICENSE\\nUpdate README.md\\nUpdate READM...</td>\n",
       "      <td>1 audio retrieval\\n2 plot spectrogram\\n3 1 vgg...</td>\n",
       "      <td></td>\n",
       "      <td>Recognizing the genre of music files using mac...</td>\n",
       "      <td>Recognizing the genre of music files using mac...</td>\n",
       "      <td>3078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>173520377</td>\n",
       "      <td>probabilistic_nlg</td>\n",
       "      <td>Tensorflow Implementation of Stochastic Wasser...</td>\n",
       "      <td>HareeshBahuleyan</td>\n",
       "      <td>{'Python': 303839}</td>\n",
       "      <td>Stochastic Wasserstein Autoencoder for Probabi...</td>\n",
       "      <td>Bumps [tensorflow-gpu](https://github.com/tens...</td>\n",
       "      <td>Update LICENSE\\nUpdate requirements.txt\\nUpdat...</td>\n",
       "      <td>README\\n  init  \\ndf movie test\\ndf movie trai...</td>\n",
       "      <td></td>\n",
       "      <td>Tensorflow Implementation of Stochastic Wasser...</td>\n",
       "      <td>Tensorflow Implementation of Stochastic Wasser...</td>\n",
       "      <td>3725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>103798851</td>\n",
       "      <td>DataStructures-Algorithms-InC</td>\n",
       "      <td>Programs of Data Structures and Algorithms in ...</td>\n",
       "      <td>gauravtheP</td>\n",
       "      <td>{'C': 117644, 'Makefile': 54504, 'C++': 9409, ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Minor modification is done in chainingInHashin...</td>\n",
       "      <td>dep\\n01Knapsack Problem\\nFloyd Warshall Algor...</td>\n",
       "      <td>Time Complexity: O(nlogn)\\nTime Complexity\\n W...</td>\n",
       "      <td>Programs of Data Structures and Algorithms in ...</td>\n",
       "      <td>Programs of Data Structures and Algorithms in ...</td>\n",
       "      <td>1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>153249816</td>\n",
       "      <td>Music-Generation-Using-Deep-Learning</td>\n",
       "      <td>A Deep Learning Case Study to Generate Music S...</td>\n",
       "      <td>gauravtheP</td>\n",
       "      <td>{'Jupyter Notebook': 52835}</td>\n",
       "      <td>Music Generation Using Deep-Learning. Check ou...</td>\n",
       "      <td>Does this model also include chord generation?...</td>\n",
       "      <td>Blog Link Updated\\nUpdate README.md\\nUpdate RE...</td>\n",
       "      <td>Generate Music\\nMusic Generation Train1\\nMusic...</td>\n",
       "      <td></td>\n",
       "      <td>A Deep Learning Case Study to Generate Music S...</td>\n",
       "      <td>A Deep Learning Case Study to Generate Music S...</td>\n",
       "      <td>3922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>170129937</td>\n",
       "      <td>evaluomeR</td>\n",
       "      <td>The evaluomeR package is an R package which pe...</td>\n",
       "      <td>neobernad</td>\n",
       "      <td>{'R': 244510, 'PostScript': 77446, 'TeX': 5333}</td>\n",
       "      <td>evaluomeR. The evaluomeR package permits to ev...</td>\n",
       "      <td></td>\n",
       "      <td>Fixing sorting in usecase\\nFixing warnings in ...</td>\n",
       "      <td>\\ncorrelation\\ndata\\nhelpers\\ninternal Cluster...</td>\n",
       "      <td></td>\n",
       "      <td>The evaluomeR package is an R package which pe...</td>\n",
       "      <td>The evaluomeR package is an R package which pe...</td>\n",
       "      <td>4598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>57412597</td>\n",
       "      <td>hemodonacion</td>\n",
       "      <td></td>\n",
       "      <td>fanavarro</td>\n",
       "      <td>{'Perl': 97370, 'R': 36211}</td>\n",
       "      <td>Lost in Translation. Structure. This repositor...</td>\n",
       "      <td></td>\n",
       "      <td>delete files\\nnew execution\\nReadme updated\\nr...</td>\n",
       "      <td>\\nREADME\\n11 12 2016\\n19 04 2018\\n26 04 2017\\n...</td>\n",
       "      <td></td>\n",
       "      <td>. Lost in Translation. Structure. This reposit...</td>\n",
       "      <td>. Lost in Translation. Structure. This reposit...</td>\n",
       "      <td>9027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>46532803</td>\n",
       "      <td>DnaCompress</td>\n",
       "      <td>Dna sequence compressor.</td>\n",
       "      <td>fanavarro</td>\n",
       "      <td>{'C': 55602, 'Makefile': 2779}</td>\n",
       "      <td>To encode a file you only have to write the fo...</td>\n",
       "      <td></td>\n",
       "      <td>ultima version\\nTest para diferentes valores d...</td>\n",
       "      <td>\\ncoder\\ndecode\\nencode\\nhuffman\\nhuffman tabl...</td>\n",
       "      <td></td>\n",
       "      <td>Dna sequence compressor.. To encode a file you...</td>\n",
       "      <td>Dna sequence compressor.. To encode a file you...</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>95547920</td>\n",
       "      <td>trackhub-creator</td>\n",
       "      <td>Trackhub creation tool</td>\n",
       "      <td>Proteogenomics</td>\n",
       "      <td>{'Python': 311918, 'Shell': 7633, 'Makefile': ...</td>\n",
       "      <td>How to set up the application. First thing, ch...</td>\n",
       "      <td>The current pipeline generates only the exact ...</td>\n",
       "      <td>PoGo timeout increased to 24 hours\\nprovide mo...</td>\n",
       "      <td>\\nREADME\\nconfig default\\nconfig ensembl data ...</td>\n",
       "      <td></td>\n",
       "      <td>Trackhub creation tool. How to set up the appl...</td>\n",
       "      <td>Trackhub creation tool. How to set up the appl...</td>\n",
       "      <td>9668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>94098106</td>\n",
       "      <td>libpogo</td>\n",
       "      <td>Library for working with PoGo tool</td>\n",
       "      <td>Proteogenomics</td>\n",
       "      <td>{'Java': 16608}</td>\n",
       "      <td>Introduction. This is small library implementi...</td>\n",
       "      <td></td>\n",
       "      <td>PoGoEntry visitor exception added\\nremoved dep...</td>\n",
       "      <td>\\nREADME\\npom\\nPo Go Entry\\nPo Go Entry Factor...</td>\n",
       "      <td>*\\n * Project: libpogo\\n * Package: uk.ac.ebi....</td>\n",
       "      <td>Library for working with PoGo tool. Introducti...</td>\n",
       "      <td>Library for working with PoGo tool. Introducti...</td>\n",
       "      <td>4865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>83849237</td>\n",
       "      <td>vimrc</td>\n",
       "      <td>My Vim setup</td>\n",
       "      <td>mbdebian</td>\n",
       "      <td>{'Vim script': 694233, 'Ruby': 57910, 'C': 238...</td>\n",
       "      <td>The Best .vimrc Ever (tm)\\n\\n\\n\\n===\\n\\n\\n\\n\\n...</td>\n",
       "      <td></td>\n",
       "      <td>Changed line numbers to gray.\\nRemoved tm's lo...</td>\n",
       "      <td>\\ntogglebg\\njellybeans\\nsolarized\\ncommand t\\n...</td>\n",
       "      <td></td>\n",
       "      <td>My Vim setup. The Best .vimrc Ever (tm)\\n\\n\\n\\...</td>\n",
       "      <td>My Vim setup. The Best .vimrc Ever (tm) === Re...</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>83414669</td>\n",
       "      <td>cpp-playground</td>\n",
       "      <td>Supporting material for teaching C++</td>\n",
       "      <td>mbdebian</td>\n",
       "      <td>{'C++': 6455, 'Makefile': 458, 'C': 141, 'CMak...</td>\n",
       "      <td>cpp-playground. Supporting material for teachi...</td>\n",
       "      <td></td>\n",
       "      <td>gitignore file for clion files\\nCLion hello wo...</td>\n",
       "      <td>README\\n\\nCMake Lists\\nmain\\ncmd args\\ngeometr...</td>\n",
       "      <td></td>\n",
       "      <td>Supporting material for teaching C++. cpp-play...</td>\n",
       "      <td>Supporting material for teaching C++. cpp-play...</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>56680034</td>\n",
       "      <td>genenetwork2</td>\n",
       "      <td>GeneNetwork (2nd generation)</td>\n",
       "      <td>pjotrp</td>\n",
       "      <td>{'JavaScript': 1832208, 'Python': 960886, 'HTM...</td>\n",
       "      <td>GeneNetwork. This repository contains the sour...</td>\n",
       "      <td></td>\n",
       "      <td>Redis setting\\nRemove old menu file\\nMerge wit...</td>\n",
       "      <td>\\nLICENSE\\nMANIFEST\\nREADME\\nRELEASE NOTES\\nAP...</td>\n",
       "      <td>&lt;font size=\"2\"&gt;&lt;b&gt;-1 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;...</td>\n",
       "      <td>GeneNetwork (2nd generation). GeneNetwork. Thi...</td>\n",
       "      <td>GeneNetwork (2nd generation). GeneNetwork. Thi...</td>\n",
       "      <td>11344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>231038084</td>\n",
       "      <td>MPCC</td>\n",
       "      <td>Optimized Parallelized Matrix Pearsons Correla...</td>\n",
       "      <td>pjotrp</td>\n",
       "      <td>{'PostScript': 20261414, 'TeX': 322960, 'C++':...</td>\n",
       "      <td>MPCC. Optimized Parallelized Matrix Pearsons C...</td>\n",
       "      <td></td>\n",
       "      <td>Minor stuff\\nChanges based on Mitch his commen...</td>\n",
       "      <td>\\nGN378 df Known\\nGN378 df Un\\nPCC\\ngen AB\\nin...</td>\n",
       "      <td>printf(\"Error, no correlation possible for row...</td>\n",
       "      <td>Optimized Parallelized Matrix Pearsons Correla...</td>\n",
       "      <td>Optimized Parallelized Matrix Pearsons Correla...</td>\n",
       "      <td>2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14387064</td>\n",
       "      <td>pubannotation</td>\n",
       "      <td>shareable literature annotation repository system</td>\n",
       "      <td>jdkim</td>\n",
       "      <td>{'Ruby': 658326, 'JavaScript': 41788, 'CSS': 9...</td>\n",
       "      <td>pubannotation. shareable literature annotation...</td>\n",
       "      <td></td>\n",
       "      <td>Merge branch 'development' of https://github.c...</td>\n",
       "      <td>\\nGemfile\\nREADME\\najax loader\\nhint\\nlist sty...</td>\n",
       "      <td>* Unobtrusive autocomplete\\n*\\n* To use it, yo...</td>\n",
       "      <td>shareable literature annotation repository sys...</td>\n",
       "      <td>shareable literature annotation repository sys...</td>\n",
       "      <td>5190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>212904362</td>\n",
       "      <td>UniMath</td>\n",
       "      <td>This coq library aims to formalize a substanti...</td>\n",
       "      <td>NuriaQueralt</td>\n",
       "      <td>{'Coq': 7736194, 'Emacs Lisp': 36844, 'Makefil...</td>\n",
       "      <td>Univalent Mathematics. This Coq library aims t...</td>\n",
       "      <td></td>\n",
       "      <td>Merge pull request #1287 from nmvdw/aps\\n\\nSma...</td>\n",
       "      <td>\\n travis\\nINSTALL\\nINSTALL COQIDE\\nINSTALL MA...</td>\n",
       "      <td></td>\n",
       "      <td>This coq library aims to formalize a substanti...</td>\n",
       "      <td>This coq library aims to formalize a substanti...</td>\n",
       "      <td>7813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>113264497</td>\n",
       "      <td>neo4j-to-reasoner</td>\n",
       "      <td>Translate neo4j query output to YAML file suit...</td>\n",
       "      <td>NuriaQueralt</td>\n",
       "      <td>{'JavaScript': 30000901, 'HTML': 34905, 'Pytho...</td>\n",
       "      <td>neo4j-to-reasoner. Translate neo4j query outpu...</td>\n",
       "      <td></td>\n",
       "      <td>don't lower-case middle node label in queries\\...</td>\n",
       "      <td>\\nAuthentication\\nNOTES\\nREADME\\ncypher to rea...</td>\n",
       "      <td>@open=\"handleOpen\"\\r\\n              @close=\"ha...</td>\n",
       "      <td>Translate neo4j query output to YAML file suit...</td>\n",
       "      <td>Translate neo4j query output to YAML file suit...</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>260889871</td>\n",
       "      <td>dl-reasoner</td>\n",
       "      <td>Tableau-based reasoner for ALCQ description logic</td>\n",
       "      <td>leechuck</td>\n",
       "      <td>{'Rust': 62072}</td>\n",
       "      <td>Tableau algorithm for ALCQ. This is a tableau-...</td>\n",
       "      <td></td>\n",
       "      <td>chore: a remark on how to use a non-empty tbox...</td>\n",
       "      <td>\\nCargo\\nREADME\\nabox\\ntbox\\nconcept\\nmain\\nre...</td>\n",
       "      <td></td>\n",
       "      <td>Tableau-based reasoner for ALCQ description lo...</td>\n",
       "      <td>Tableau-based reasoner for ALCQ description lo...</td>\n",
       "      <td>5243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>161862375</td>\n",
       "      <td>biohack18</td>\n",
       "      <td></td>\n",
       "      <td>leechuck</td>\n",
       "      <td>{'Groovy': 14573}</td>\n",
       "      <td>biohack18.</td>\n",
       "      <td></td>\n",
       "      <td>initial commit\\nInitial commit</td>\n",
       "      <td>Clean OPA\\nFLOPOTsne\\nMake Plants Plot\\nMake P...</td>\n",
       "      <td></td>\n",
       "      <td>. biohack18.Clean OPA\\nFLOPOTsne\\nMake Plants ...</td>\n",
       "      <td>. biohack18.Clean OPA FLOPOTsne Make Plants Pl...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>171842501</td>\n",
       "      <td>biosample_jsonld</td>\n",
       "      <td></td>\n",
       "      <td>inutano</td>\n",
       "      <td>{'Ruby': 9183, 'Shell': 3171, 'Dockerfile': 226}</td>\n",
       "      <td>BioSample records in JSON-LD. BioSample is a d...</td>\n",
       "      <td></td>\n",
       "      <td>mkdir\\nremove postgres lib\\nremove comment whi...</td>\n",
       "      <td>\\nGemfile\\nREADME\\nbiosample ld\\ndocker compos...</td>\n",
       "      <td></td>\n",
       "      <td>. BioSample records in JSON-LD. BioSample is a...</td>\n",
       "      <td>. BioSample records in JSON-LD. BioSample is a...</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gh_id                                  name  \\\n",
       "0   216602979                               LIRICAL   \n",
       "1   199330464                  wikidata_ontomatcher   \n",
       "2   253207181                         ro-crate-ruby   \n",
       "3   212556220                 Misc_Training_scripts   \n",
       "4   155879756                             FAIRifier   \n",
       "5    90349931                                  elda   \n",
       "6   126633812            music-genre-classification   \n",
       "7   173520377                     probabilistic_nlg   \n",
       "8   103798851         DataStructures-Algorithms-InC   \n",
       "9   153249816  Music-Generation-Using-Deep-Learning   \n",
       "10  170129937                             evaluomeR   \n",
       "11   57412597                          hemodonacion   \n",
       "12   46532803                           DnaCompress   \n",
       "13   95547920                      trackhub-creator   \n",
       "14   94098106                               libpogo   \n",
       "15   83849237                                 vimrc   \n",
       "16   83414669                        cpp-playground   \n",
       "17   56680034                          genenetwork2   \n",
       "18  231038084                                  MPCC   \n",
       "19   14387064                         pubannotation   \n",
       "20  212904362                               UniMath   \n",
       "21  113264497                     neo4j-to-reasoner   \n",
       "22  260889871                           dl-reasoner   \n",
       "23  161862375                             biohack18   \n",
       "24  171842501                      biosample_jsonld   \n",
       "\n",
       "                                          description             owner_name  \\\n",
       "0   LIkelihood Ratio Interpretation of Clinical Ab...               cmungall   \n",
       "1           Matches ontology classes against wikidata               cmungall   \n",
       "2   A Ruby gem for creating, manipulating and read...          markwilkinson   \n",
       "3   A place for me to keep various miscellanelous ...          markwilkinson   \n",
       "4                            A tool to make data FAIR  mikel-egana-aranguren   \n",
       "5   Epimorphics implementation of the Linked Data API  mikel-egana-aranguren   \n",
       "6   Recognizing the genre of music files using mac...       HareeshBahuleyan   \n",
       "7   Tensorflow Implementation of Stochastic Wasser...       HareeshBahuleyan   \n",
       "8   Programs of Data Structures and Algorithms in ...             gauravtheP   \n",
       "9   A Deep Learning Case Study to Generate Music S...             gauravtheP   \n",
       "10  The evaluomeR package is an R package which pe...              neobernad   \n",
       "11                                                                 fanavarro   \n",
       "12                           Dna sequence compressor.              fanavarro   \n",
       "13                             Trackhub creation tool         Proteogenomics   \n",
       "14                 Library for working with PoGo tool         Proteogenomics   \n",
       "15                                       My Vim setup               mbdebian   \n",
       "16               Supporting material for teaching C++               mbdebian   \n",
       "17                       GeneNetwork (2nd generation)                 pjotrp   \n",
       "18  Optimized Parallelized Matrix Pearsons Correla...                 pjotrp   \n",
       "19  shareable literature annotation repository system                  jdkim   \n",
       "20  This coq library aims to formalize a substanti...           NuriaQueralt   \n",
       "21  Translate neo4j query output to YAML file suit...           NuriaQueralt   \n",
       "22  Tableau-based reasoner for ALCQ description logic               leechuck   \n",
       "23                                                                  leechuck   \n",
       "24                                                                   inutano   \n",
       "\n",
       "                                            languages  \\\n",
       "0   {'Java': 492423, 'FreeMarker': 13149, 'Python'...   \n",
       "1   {'Prolog': 14691, 'Makefile': 1472, 'Dockerfil...   \n",
       "2                       {'Ruby': 52724, 'HTML': 1319}   \n",
       "3                      {'Shell': 15815, 'Ruby': 9445}   \n",
       "4   {'Java': 3514431, 'JavaScript': 967765, 'HTML'...   \n",
       "5   {'Java': 1892893, 'JavaScript': 1757647, 'XSLT...   \n",
       "6       {'Jupyter Notebook': 7532041, 'Python': 8296}   \n",
       "7                                  {'Python': 303839}   \n",
       "8   {'C': 117644, 'Makefile': 54504, 'C++': 9409, ...   \n",
       "9                         {'Jupyter Notebook': 52835}   \n",
       "10    {'R': 244510, 'PostScript': 77446, 'TeX': 5333}   \n",
       "11                        {'Perl': 97370, 'R': 36211}   \n",
       "12                     {'C': 55602, 'Makefile': 2779}   \n",
       "13  {'Python': 311918, 'Shell': 7633, 'Makefile': ...   \n",
       "14                                    {'Java': 16608}   \n",
       "15  {'Vim script': 694233, 'Ruby': 57910, 'C': 238...   \n",
       "16  {'C++': 6455, 'Makefile': 458, 'C': 141, 'CMak...   \n",
       "17  {'JavaScript': 1832208, 'Python': 960886, 'HTM...   \n",
       "18  {'PostScript': 20261414, 'TeX': 322960, 'C++':...   \n",
       "19  {'Ruby': 658326, 'JavaScript': 41788, 'CSS': 9...   \n",
       "20  {'Coq': 7736194, 'Emacs Lisp': 36844, 'Makefil...   \n",
       "21  {'JavaScript': 30000901, 'HTML': 34905, 'Pytho...   \n",
       "22                                    {'Rust': 62072}   \n",
       "23                                  {'Groovy': 14573}   \n",
       "24   {'Ruby': 9183, 'Shell': 3171, 'Dockerfile': 226}   \n",
       "\n",
       "                                          readme_text  \\\n",
       "0   LIRICAL.  LIkelihood Ratio Interpretation of C...   \n",
       "1   Match an ontology to Wikidata. This applicatio...   \n",
       "2   ro-crate-ruby. This is a WIP gem for creating,...   \n",
       "3   Misc_Training_scripts. A place for me to keep ...   \n",
       "4   Dependencies: Java 8. Apache Ant. Building. in...   \n",
       "5   Elda, an implementation of the Linked Data API...   \n",
       "6   Music Genre Classification.  \\n Overview. Reco...   \n",
       "7   Stochastic Wasserstein Autoencoder for Probabi...   \n",
       "8                                                       \n",
       "9   Music Generation Using Deep-Learning. Check ou...   \n",
       "10  evaluomeR. The evaluomeR package permits to ev...   \n",
       "11  Lost in Translation. Structure. This repositor...   \n",
       "12  To encode a file you only have to write the fo...   \n",
       "13  How to set up the application. First thing, ch...   \n",
       "14  Introduction. This is small library implementi...   \n",
       "15  The Best .vimrc Ever (tm)\\n\\n\\n\\n===\\n\\n\\n\\n\\n...   \n",
       "16  cpp-playground. Supporting material for teachi...   \n",
       "17  GeneNetwork. This repository contains the sour...   \n",
       "18  MPCC. Optimized Parallelized Matrix Pearsons C...   \n",
       "19  pubannotation. shareable literature annotation...   \n",
       "20  Univalent Mathematics. This Coq library aims t...   \n",
       "21  neo4j-to-reasoner. Translate neo4j query outpu...   \n",
       "22  Tableau algorithm for ALCQ. This is a tableau-...   \n",
       "23                                         biohack18.   \n",
       "24  BioSample records in JSON-LD. BioSample is a d...   \n",
       "\n",
       "                                          issues_text  \\\n",
       "0                                                       \n",
       "1   Will help with #1 and with https://github.com/...   \n",
       "2                                                       \n",
       "3                                                       \n",
       "4                                                       \n",
       "5                                                       \n",
       "6                                                       \n",
       "7   Bumps [tensorflow-gpu](https://github.com/tens...   \n",
       "8                                                       \n",
       "9   Does this model also include chord generation?...   \n",
       "10                                                      \n",
       "11                                                      \n",
       "12                                                      \n",
       "13  The current pipeline generates only the exact ...   \n",
       "14                                                      \n",
       "15                                                      \n",
       "16                                                      \n",
       "17                                                      \n",
       "18                                                      \n",
       "19                                                      \n",
       "20                                                      \n",
       "21                                                      \n",
       "22                                                      \n",
       "23                                                      \n",
       "24                                                      \n",
       "\n",
       "                                         commits_text  \\\n",
       "0   Merge pull request #442 from TheJacksonLaborat...   \n",
       "1   Adding skos:altLabel\\n\\nhttps://github.com/cmu...   \n",
       "2   Update LICENSE\\nBump version\\nTidy up and chec...   \n",
       "3   added new cool 3-federated query\\nfinished edi...   \n",
       "4   Merge pull request #16 from Shamanou/developme...   \n",
       "5   Proper reference Config\\nConfiguracion ELDA de...   \n",
       "6   Update LICENSE\\nUpdate README.md\\nUpdate READM...   \n",
       "7   Update LICENSE\\nUpdate requirements.txt\\nUpdat...   \n",
       "8   Minor modification is done in chainingInHashin...   \n",
       "9   Blog Link Updated\\nUpdate README.md\\nUpdate RE...   \n",
       "10  Fixing sorting in usecase\\nFixing warnings in ...   \n",
       "11  delete files\\nnew execution\\nReadme updated\\nr...   \n",
       "12  ultima version\\nTest para diferentes valores d...   \n",
       "13  PoGo timeout increased to 24 hours\\nprovide mo...   \n",
       "14  PoGoEntry visitor exception added\\nremoved dep...   \n",
       "15  Changed line numbers to gray.\\nRemoved tm's lo...   \n",
       "16  gitignore file for clion files\\nCLion hello wo...   \n",
       "17  Redis setting\\nRemove old menu file\\nMerge wit...   \n",
       "18  Minor stuff\\nChanges based on Mitch his commen...   \n",
       "19  Merge branch 'development' of https://github.c...   \n",
       "20  Merge pull request #1287 from nmvdw/aps\\n\\nSma...   \n",
       "21  don't lower-case middle node label in queries\\...   \n",
       "22  chore: a remark on how to use a non-empty tbox...   \n",
       "23                     initial commit\\nInitial commit   \n",
       "24  mkdir\\nremove postgres lib\\nremove comment whi...   \n",
       "\n",
       "                                            filenames  \\\n",
       "0   \\nCHANGELOG\\nREADME\\nhoxc13 output\\nlirical to...   \n",
       "1   \\nREADME\\ninstall\\npack\\nwikidata ontomatcher\\...   \n",
       "2   \\n travis\\nGemfile\\nREADME\\nROCrate\\nContact P...   \n",
       "3   README\\nSpecies Abundance Pub2015\\nSpecies Inf...   \n",
       "4   \\norg eclipse core resources\\norg eclipse jdt ...   \n",
       "5   \\nCONTRIBUTING\\nLICENCE\\nREADME demo\\nREADME\\n...   \n",
       "6   1 audio retrieval\\n2 plot spectrogram\\n3 1 vgg...   \n",
       "7   README\\n  init  \\ndf movie test\\ndf movie trai...   \n",
       "8    dep\\n01Knapsack Problem\\nFloyd Warshall Algor...   \n",
       "9   Generate Music\\nMusic Generation Train1\\nMusic...   \n",
       "10  \\ncorrelation\\ndata\\nhelpers\\ninternal Cluster...   \n",
       "11  \\nREADME\\n11 12 2016\\n19 04 2018\\n26 04 2017\\n...   \n",
       "12  \\ncoder\\ndecode\\nencode\\nhuffman\\nhuffman tabl...   \n",
       "13  \\nREADME\\nconfig default\\nconfig ensembl data ...   \n",
       "14  \\nREADME\\npom\\nPo Go Entry\\nPo Go Entry Factor...   \n",
       "15  \\ntogglebg\\njellybeans\\nsolarized\\ncommand t\\n...   \n",
       "16  README\\n\\nCMake Lists\\nmain\\ncmd args\\ngeometr...   \n",
       "17  \\nLICENSE\\nMANIFEST\\nREADME\\nRELEASE NOTES\\nAP...   \n",
       "18  \\nGN378 df Known\\nGN378 df Un\\nPCC\\ngen AB\\nin...   \n",
       "19  \\nGemfile\\nREADME\\najax loader\\nhint\\nlist sty...   \n",
       "20  \\n travis\\nINSTALL\\nINSTALL COQIDE\\nINSTALL MA...   \n",
       "21  \\nAuthentication\\nNOTES\\nREADME\\ncypher to rea...   \n",
       "22  \\nCargo\\nREADME\\nabox\\ntbox\\nconcept\\nmain\\nre...   \n",
       "23  Clean OPA\\nFLOPOTsne\\nMake Plants Plot\\nMake P...   \n",
       "24  \\nGemfile\\nREADME\\nbiosample ld\\ndocker compos...   \n",
       "\n",
       "                                        comments_text  \\\n",
       "0   note that the Jannovar dependency does not nee...   \n",
       "1                                                       \n",
       "2   *\\n * Expands the tree to the target element a...   \n",
       "3                                                       \n",
       "4   *\\n * Main class for Refine server application...   \n",
       "5   Everything that's part of the resource set is ...   \n",
       "6                                                       \n",
       "7                                                       \n",
       "8   Time Complexity: O(nlogn)\\nTime Complexity\\n W...   \n",
       "9                                                       \n",
       "10                                                      \n",
       "11                                                      \n",
       "12                                                      \n",
       "13                                                      \n",
       "14  *\\n * Project: libpogo\\n * Package: uk.ac.ebi....   \n",
       "15                                                      \n",
       "16                                                      \n",
       "17  <font size=\"2\"><b>-1 &nbsp;&nbsp;&nbsp;&nbsp;&...   \n",
       "18  printf(\"Error, no correlation possible for row...   \n",
       "19  * Unobtrusive autocomplete\\n*\\n* To use it, yo...   \n",
       "20                                                      \n",
       "21  @open=\"handleOpen\"\\r\\n              @close=\"ha...   \n",
       "22                                                      \n",
       "23                                                      \n",
       "24                                                      \n",
       "\n",
       "                                            full_text  \\\n",
       "0   LIkelihood Ratio Interpretation of Clinical Ab...   \n",
       "1   Matches ontology classes against wikidata. Mat...   \n",
       "2   A Ruby gem for creating, manipulating and read...   \n",
       "3   A place for me to keep various miscellanelous ...   \n",
       "4   A tool to make data FAIR. Dependencies: Java 8...   \n",
       "5   Epimorphics implementation of the Linked Data ...   \n",
       "6   Recognizing the genre of music files using mac...   \n",
       "7   Tensorflow Implementation of Stochastic Wasser...   \n",
       "8   Programs of Data Structures and Algorithms in ...   \n",
       "9   A Deep Learning Case Study to Generate Music S...   \n",
       "10  The evaluomeR package is an R package which pe...   \n",
       "11  . Lost in Translation. Structure. This reposit...   \n",
       "12  Dna sequence compressor.. To encode a file you...   \n",
       "13  Trackhub creation tool. How to set up the appl...   \n",
       "14  Library for working with PoGo tool. Introducti...   \n",
       "15  My Vim setup. The Best .vimrc Ever (tm)\\n\\n\\n\\...   \n",
       "16  Supporting material for teaching C++. cpp-play...   \n",
       "17  GeneNetwork (2nd generation). GeneNetwork. Thi...   \n",
       "18  Optimized Parallelized Matrix Pearsons Correla...   \n",
       "19  shareable literature annotation repository sys...   \n",
       "20  This coq library aims to formalize a substanti...   \n",
       "21  Translate neo4j query output to YAML file suit...   \n",
       "22  Tableau-based reasoner for ALCQ description lo...   \n",
       "23  . biohack18.Clean OPA\\nFLOPOTsne\\nMake Plants ...   \n",
       "24  . BioSample records in JSON-LD. BioSample is a...   \n",
       "\n",
       "                                    full_text_cleaned  num_chars_text  \n",
       "0   LIkelihood Ratio Interpretation of Clinical Ab...            3770  \n",
       "1   Matches ontology classes against wikidata. Mat...             519  \n",
       "2   A Ruby gem for creating, manipulating and read...            2559  \n",
       "3   A place for me to keep various miscellanelous ...             545  \n",
       "4   A tool to make data FAIR. Dependencies: Java 8...           57859  \n",
       "5   Epimorphics implementation of the Linked Data ...           15907  \n",
       "6   Recognizing the genre of music files using mac...            3078  \n",
       "7   Tensorflow Implementation of Stochastic Wasser...            3725  \n",
       "8   Programs of Data Structures and Algorithms in ...            1330  \n",
       "9   A Deep Learning Case Study to Generate Music S...            3922  \n",
       "10  The evaluomeR package is an R package which pe...            4598  \n",
       "11  . Lost in Translation. Structure. This reposit...            9027  \n",
       "12  Dna sequence compressor.. To encode a file you...            1996  \n",
       "13  Trackhub creation tool. How to set up the appl...            9668  \n",
       "14  Library for working with PoGo tool. Introducti...            4865  \n",
       "15  My Vim setup. The Best .vimrc Ever (tm) === Re...             664  \n",
       "16  Supporting material for teaching C++. cpp-play...             315  \n",
       "17  GeneNetwork (2nd generation). GeneNetwork. Thi...           11344  \n",
       "18  Optimized Parallelized Matrix Pearsons Correla...            2376  \n",
       "19  shareable literature annotation repository sys...            5190  \n",
       "20  This coq library aims to formalize a substanti...            7813  \n",
       "21  Translate neo4j query output to YAML file suit...             541  \n",
       "22  Tableau-based reasoner for ALCQ description lo...            5243  \n",
       "23  . biohack18.Clean OPA FLOPOTsne Make Plants Pl...             116  \n",
       "24  . BioSample records in JSON-LD. BioSample is a...            1050  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_df.head(n=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = git_repositories[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the NER model\n",
    "The named entity recognition model created in notebook 4 will now be loaded and used to obtain the entities of the article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_sci_lg\n",
    "\n",
    "from herc_common.utils import load_object\n",
    "from collections import Counter\n",
    "\n",
    "ner = load_object(os.path.join(NOTEBOOK_4_RESULTS_DIR, 'ner_system.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Repository',\n",
       " 'scripts',\n",
       " 'basketball',\n",
       " 'Basketball Analytics',\n",
       " 'repository',\n",
       " 'scripts',\n",
       " 'statistics',\n",
       " 'NBA',\n",
       " 'basketball',\n",
       " 'code']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = en_core_sci_lg.load()\n",
    "entities = ner.transform([text])\n",
    "entities[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity linking\n",
    "Now, we will be making use of the WikidataEntityLinker class to obtain the Wikidata URI of each entity recognized before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "DBPEDIA_BASE = 'http://dbpedia.org'\n",
    "DBPEDIA_SPOTLIGHT_BASE = 'http://api.dbpedia-spotlight.org/en'\n",
    "OWL_SAME_AS = 'http://www.w3.org/2002/07/owl#sameAs'\n",
    "\n",
    "class DBPediaEntityLinker():\n",
    "    def __init__(self, confidence_threshold=0.4):\n",
    "        self.confidence = confidence_threshold\n",
    "    \n",
    "    def link_entities(self, text):\n",
    "        payload = {'confidence': self.confidence, 'text': text}\n",
    "        reqheaders = {'accept': 'application/json'}\n",
    "        res = requests.post(f\"{DBPEDIA_SPOTLIGHT_BASE}/annotate\",\n",
    "                            data=payload,\n",
    "                            headers={\"accept\": \"application/json\"})\n",
    "        if res.status_code != 200:\n",
    "            print(res.content)\n",
    "            print(\"Error annotating text with DBPedia Spotlight: \", res)\n",
    "            return []\n",
    "        \n",
    "        res_dict = json.loads(res.content)\n",
    "        if 'Resources' not in res_dict:\n",
    "            return []\n",
    "        \n",
    "        return [(resource['@surfaceForm'], resource['@URI'])\n",
    "                for resource in res_dict['Resources']]\n",
    "\n",
    "\n",
    "def _convert_to_wd(dbpedia_linked_entities):\n",
    "    wd_entities = []\n",
    "    for name, url in dbpedia_linked_entities:\n",
    "        resource_url = url.replace(f\"{DBPEDIA_BASE}/resource\", f\"{DBPEDIA_BASE}/data\")\n",
    "        resource_url += \".json\"\n",
    "        res = requests.get(resource_url)\n",
    "        if res.status_code != 200:\n",
    "            print(f\"Error loading resource '{resource_url}': \", res)\n",
    "            continue\n",
    "\n",
    "        res_dict = json.loads(res.content)\n",
    "        try:\n",
    "            mappings = res_dict[url][OWL_SAME_AS]\n",
    "        except KeyError:\n",
    "            wd_entities.append((name, None))\n",
    "\n",
    "        for mapping in mappings:\n",
    "            mapping_url = mapping['value']\n",
    "            if 'http://www.wikidata.org/' in mapping_url:\n",
    "                wd_entities.append((name, mapping_url))\n",
    "                break\n",
    "    return wd_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\\n<html><head>\\n<title>500 Internal Error</title>\\n</head><body>\\n<h1>Internal Error</h1>\\n<p>The server encountered an internal error or\\nmisconfiguration and was unable to complete\\nyour request.</p>\\n<p>Please contact the server administrator at \\n [no address given] to inform them of the time this error occurred,\\n and the actions you performed just before this error.</p>\\n<p>More information about this error may be available\\nin the server error log.</p>\\n<hr>\\n<address>Apache/2.4.25 (Debian) Server at api.dbpedia-spotlight.org Port 80</address>\\n</body></html>\\n'\n",
      "Error annotating text with DBPedia Spotlight:  <Response [500]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('phenotypic', 'http://dbpedia.org/resource/Phenotype'),\n",
       " ('Human Phenotype Ontology',\n",
       "  'http://dbpedia.org/resource/Human_Phenotype_Ontology'),\n",
       " ('genotypes', 'http://dbpedia.org/resource/Genotype'),\n",
       " ('VCF', 'http://dbpedia.org/resource/Variant_Call_Format'),\n",
       " ('gene', 'http://dbpedia.org/resource/Gene')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbpedia_linker = DBPediaEntityLinker()\n",
    "dbpedia_linked_entities = [dbpedia_linker.link_entities(text)\n",
    "                           for text in git_repositories]\n",
    "dbpedia_linked_entities[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_entities = [_convert_to_wd(entities)\n",
    "                   for entities in dbpedia_linked_entities]\n",
    "linked_entities[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTINUE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422f433ac02e4926825a7ff459f8f41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Repository', 'http://www.wikidata.org/entity/Q3133368'),\n",
       " ('scripts', 'http://www.wikidata.org/entity/Q187432'),\n",
       " ('basketball', 'http://www.wikidata.org/entity/Q5372'),\n",
       " ('Basketball Analytics', None),\n",
       " ('repository', 'http://www.wikidata.org/entity/Q3133368')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from herc_common.entity_linking import WikidataEntityLinker\n",
    "\n",
    "linker = WikidataEntityLinker()\n",
    "linked_entities = linker.fit_transform(entities)\n",
    "linked_entities[0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the graph\n",
    "After each entity has been linked to Wikidata, w:e will begin exploring their neighbourhood in the knowledge graph to obtain a list of candidates for our final topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from herc_common.graph import WikidataGraphBuilder\n",
    "\n",
    "graph_builder = WikidataGraphBuilder(max_hops=2)\n",
    "entity_graph = graph_builder.build_graph(linked_entities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "from herc_common.bokeh_utils import build_graph_plot\n",
    "\n",
    "plot = build_graph_plot(entity_graph, f\"Linked entities graph\")\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the graph from above is not completely connected, we will be obtaining the largest connected subgraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from herc_common.graph import get_largest_connected_subgraph\n",
    "\n",
    "connected_entity_subgraph = get_largest_connected_subgraph(entity_graph)\n",
    "\n",
    "plot = build_graph_plot(connected_entity_subgraph, f\"Linked entities graph\")\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the Wikidata graph obtained from our initial list of entities from the text, we will be trying out a list of centrality algorithms to obtain the top 9 entities that represent the text. These entities can be seen as potential topics for the publication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx.algorithms as nxa\n",
    "\n",
    "from herc_common.graph import get_centrality_algorithm_results\n",
    "\n",
    "def try_centrality_algorithms(g, algorithms, stop_uris, top_n=9):\n",
    "    for (algorithm, name) in algorithms:\n",
    "        print(f'Algorithm: {name}')\n",
    "        result = get_centrality_algorithm_results(g, algorithm, stop_uris, top_n)\n",
    "        print(f\"Topics:\", [(t[0]['label'], t[1]) for t in result])\n",
    "        print()\n",
    "        \n",
    "algorithms = [\n",
    "    (nxa.centrality.information_centrality, \"Information centrality\"),\n",
    "    (nxa.centrality.eigenvector_centrality_numpy, \"Eigenvector centrality\"),\n",
    "    (nxa.centrality.closeness_centrality, \"Closeness centrality\"),\n",
    "    (nxa.centrality.betweenness_centrality, \"Betweenness centrality\"),\n",
    "    (nxa.centrality.load_centrality, \"Load centrality\")\n",
    "]\n",
    "\n",
    "stop_uris = ['Q4167836', 'Q11862829', 'Q13442814',\n",
    "             'Q17339814', 'Q24017414', 'Q4671286',\n",
    "             'Q47154513']\n",
    "try_centrality_algorithms(connected_entity_subgraph,\n",
    "                          algorithms,\n",
    "                          stop_uris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the pipeline\n",
    "Now that we have seen the main data flow, we will build the final pipeline. This pipeline will receive a list of texts, and return 7 potential topics for each text by executing the steps described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from herc_common.topic import TopicLabeller\n",
    "\n",
    "\n",
    "topic_extractor = TopicLabeller(graph_builder, nxa.centrality.closeness_centrality,\n",
    "                                num_labels_per_topic=7, stop_uris=stop_uris)\n",
    "topic_pipe = Pipeline([('ner', ner),\n",
    "                       ('entity_linker', linker),\n",
    "                       ('topic_extractor', topic_extractor)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline will be now saved for later use in the final system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from herc_common.utils import save_object\n",
    "\n",
    "PIPE_OUTPUT_FILE_NAME = \"topic_extraction_from_ner_pipe.pkl\"\n",
    "\n",
    "save_object(topic_pipe, os.path.join(NOTEBOOK_5_RESULTS_DIR, PIPE_OUTPUT_FILE_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the topics\n",
    "Before finishing with this notebook, we will be obtaining the list of inferred topics for each one of the articles from the agriculture dataset. To do so, we just have to call the _fit_transform_ method of our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b4093db0d24c2998868839e315c723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/indigo-dc/udocker/blob/master/doc/installation_manual.md#22-install-from-indigo-datacloud-repositories\n",
      "Spreadsheet('#x-spreadsheet-demo'\n",
      "Spreadsheet(\"#x-spreadsheet-demo\n",
      "https://github.com/SheetJS/sheetjs/tree/master/demos/xspreadsheet#saving-data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Started building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n",
      "INFO:herc_common.graph:Finished building graph.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[Topic(label='software', qid='Q7397', desc='non-tangible executable component of a computer', score=0.21499176276771004, t_type='ner'),\n",
       "  Topic(label='computer science', qid='Q21198', desc='study of the theoretical foundations of computation', score=0.21150729335494328, t_type='ner'),\n",
       "  Topic(label='artificial intelligence', qid='Q11660', desc='intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals', score=0.2084664536741214, t_type='ner'),\n",
       "  Topic(label='interaction science', qid='Q97008347', desc='scientific discipline', score=0.20841096619643332, t_type='ner'),\n",
       "  Topic(label='engineering', qid='Q11023', desc='applied science', score=0.20621543323676586, t_type='ner'),\n",
       "  Topic(label='automation', qid='Q184199', desc='use of various control systems for operating equipment', score=0.20518867924528303, t_type='ner'),\n",
       "  Topic(label='mathematical analysis', qid='Q7754', desc='', score=0.20438527799530148, t_type='ner')],\n",
       " [Topic(label='Wikidata', qid='Q2013', desc='free knowledge database project hosted by the Wikimedia Foundation and edited by volunteers', score=0.4090909090909091, t_type='ner'),\n",
       "  Topic(label='online database', qid='Q7094076', desc='database accessible from a network, including from the Internet', score=0.3375, t_type='ner'),\n",
       "  Topic(label='knowledge base', qid='Q593744', desc='information repository with multiple applications', score=0.3360995850622407, t_type='ner'),\n",
       "  Topic(label='semantic wiki', qid='Q638153', desc='wiki that has an underlying model of the knowledge described in it', score=0.313953488372093, t_type='ner'),\n",
       "  Topic(label='knowledge graph', qid='Q33002955', desc='information repository structured as a graph', score=0.313953488372093, t_type='ner'),\n",
       "  Topic(label='Linked Open Data cloud diagram', qid='Q43984865', desc='sequence of diagrams, showing the extent and arrangement of the linked open data cloud over time', score=0.30916030534351147, t_type='ner'),\n",
       "  Topic(label='Semantic Web', qid='Q54837', desc='extension of the Web to facilitate data exchange', score=0.3068181818181818, t_type='ner')],\n",
       " [Topic(label='information', qid='Q11028', desc='that which informs; the answer to a question of some kind; that from which data and knowledge can be derived', score=0.20050977060322855, t_type='ner'),\n",
       "  Topic(label='abstract object', qid='Q7184903', desc='object with no physical referents', score=0.1956882255389718, t_type='ner'),\n",
       "  Topic(label='advertising', qid='Q37038', desc='form of communication for marketing, typically paid for', score=0.19032258064516128, t_type='ner'),\n",
       "  Topic(label='data', qid='Q42848', desc='facts represented for handling', score=0.1892542101042502, t_type='ner'),\n",
       "  Topic(label='creative work', qid='Q17537576', desc='distinct artistic creation such as artwork, literature, music, and paintings', score=0.18195836545875096, t_type='ner'),\n",
       "  Topic(label='message', qid='Q628523', desc='discrete unit of communication intended by the source for consumption by some recipient or group of recipients', score=0.18084291187739462, t_type='ner'),\n",
       "  Topic(label='level', qid='Q1046315', desc='in a video game, space available to the player in completing an objective', score=0.18084291187739462, t_type='ner')],\n",
       " [Topic(label='species', qid='Q7432', desc='one of the basic units of biological classification and a taxonomic rank', score=0.6111111111111112, t_type='ner'),\n",
       "  Topic(label='taxonomic rank', qid='Q427626', desc='level in a taxonomic hierarchy', score=0.5116279069767442, t_type='ner'),\n",
       "  Topic(label='subgenus', qid='Q3238261', desc='taxonomic rank', score=0.4888888888888889, t_type='ner'),\n",
       "  Topic(label='rank', qid='Q3100180', desc='taxonomic rank in botany', score=0.46808510638297873, t_type='ner'),\n",
       "  Topic(label='subseries', qid='Q13198444', desc='taxonomic rank', score=0.4583333333333333, t_type='ner'),\n",
       "  Topic(label='rank', qid='Q13578154', desc='taxonomic rank in zoology', score=0.4489795918367347, t_type='ner'),\n",
       "  Topic(label='population', qid='Q2625603', desc='ensemble of individuals of a species in an area, or their number', score=0.4489795918367347, t_type='ner')],\n",
       " [Topic(label='software', qid='Q7397', desc='non-tangible executable component of a computer', score=0.20988078862906923, t_type='ner'),\n",
       "  Topic(label='interaction science', qid='Q97008347', desc='scientific discipline', score=0.2051310777503921, t_type='ner'),\n",
       "  Topic(label='economics', qid='Q8134', desc='social science that analyzes the production, distribution, and consumption of goods and services', score=0.1996293065852595, t_type='ner'),\n",
       "  Topic(label='social science', qid='Q34749', desc='academic discipline concerned with society and the relationships', score=0.19943361289619868, t_type='ner'),\n",
       "  Topic(label='communication medium', qid='Q340169', desc='storage and delivering agent of information or data', score=0.19715731667922903, t_type='ner'),\n",
       "  Topic(label='science', qid='Q336', desc='Systematic enterprise that builds and organizes knowledge', score=0.1969346598547997, t_type='ner'),\n",
       "  Topic(label='philosophy', qid='Q5891', desc='intellectual and/or logical study of general and fundamental problems', score=0.19661744966442954, t_type='ner')]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = topic_pipe.fit_transform(git_repositories)\n",
    "results[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results\n",
    "Now, we will be merging the results into our agriculture dataframe, and save the results to a CSV file. This file will contain the id and title of each article, with their respective topics inferred by the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gh_id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>owner_name</th>\n",
       "      <th>languages</th>\n",
       "      <th>readme_text</th>\n",
       "      <th>issues_text</th>\n",
       "      <th>commits_text</th>\n",
       "      <th>filenames</th>\n",
       "      <th>comments_text</th>\n",
       "      <th>full_text</th>\n",
       "      <th>full_text_cleaned</th>\n",
       "      <th>num_chars_text</th>\n",
       "      <th>topics_from_ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216602979</td>\n",
       "      <td>LIRICAL</td>\n",
       "      <td>LIkelihood Ratio Interpretation of Clinical Ab...</td>\n",
       "      <td>cmungall</td>\n",
       "      <td>{'Java': 492423, 'FreeMarker': 13149, 'Python'...</td>\n",
       "      <td>LIRICAL.  LIkelihood Ratio Interpretation of C...</td>\n",
       "      <td></td>\n",
       "      <td>Merge pull request #442 from TheJacksonLaborat...</td>\n",
       "      <td>\\nCHANGELOG\\nREADME\\nhoxc13 output\\nlirical to...</td>\n",
       "      <td>note that the Jannovar dependency does not nee...</td>\n",
       "      <td>LIkelihood Ratio Interpretation of Clinical Ab...</td>\n",
       "      <td>LIkelihood Ratio Interpretation of Clinical Ab...</td>\n",
       "      <td>3770</td>\n",
       "      <td>software, 0.2150\\ncomputer science, 0.2115\\nar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199330464</td>\n",
       "      <td>wikidata_ontomatcher</td>\n",
       "      <td>Matches ontology classes against wikidata</td>\n",
       "      <td>cmungall</td>\n",
       "      <td>{'Prolog': 14691, 'Makefile': 1472, 'Dockerfil...</td>\n",
       "      <td>Match an ontology to Wikidata. This applicatio...</td>\n",
       "      <td>Will help with #1 and with https://github.com/...</td>\n",
       "      <td>Adding skos:altLabel\\n\\nhttps://github.com/cmu...</td>\n",
       "      <td>\\nREADME\\ninstall\\npack\\nwikidata ontomatcher\\...</td>\n",
       "      <td></td>\n",
       "      <td>Matches ontology classes against wikidata. Mat...</td>\n",
       "      <td>Matches ontology classes against wikidata. Mat...</td>\n",
       "      <td>519</td>\n",
       "      <td>Wikidata, 0.4091\\nonline database, 0.3375\\nkno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253207181</td>\n",
       "      <td>ro-crate-ruby</td>\n",
       "      <td>A Ruby gem for creating, manipulating and read...</td>\n",
       "      <td>markwilkinson</td>\n",
       "      <td>{'Ruby': 52724, 'HTML': 1319}</td>\n",
       "      <td>ro-crate-ruby. This is a WIP gem for creating,...</td>\n",
       "      <td></td>\n",
       "      <td>Update LICENSE\\nBump version\\nTidy up and chec...</td>\n",
       "      <td>\\n travis\\nGemfile\\nREADME\\nROCrate\\nContact P...</td>\n",
       "      <td>*\\n * Expands the tree to the target element a...</td>\n",
       "      <td>A Ruby gem for creating, manipulating and read...</td>\n",
       "      <td>A Ruby gem for creating, manipulating and read...</td>\n",
       "      <td>2559</td>\n",
       "      <td>information, 0.2005\\nabstract object, 0.1957\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212556220</td>\n",
       "      <td>Misc_Training_scripts</td>\n",
       "      <td>A place for me to keep various miscellanelous ...</td>\n",
       "      <td>markwilkinson</td>\n",
       "      <td>{'Shell': 15815, 'Ruby': 9445}</td>\n",
       "      <td>Misc_Training_scripts. A place for me to keep ...</td>\n",
       "      <td></td>\n",
       "      <td>added new cool 3-federated query\\nfinished edi...</td>\n",
       "      <td>README\\nSpecies Abundance Pub2015\\nSpecies Inf...</td>\n",
       "      <td></td>\n",
       "      <td>A place for me to keep various miscellanelous ...</td>\n",
       "      <td>A place for me to keep various miscellanelous ...</td>\n",
       "      <td>545</td>\n",
       "      <td>species, 0.6111\\ntaxonomic rank, 0.5116\\nsubge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155879756</td>\n",
       "      <td>FAIRifier</td>\n",
       "      <td>A tool to make data FAIR</td>\n",
       "      <td>mikel-egana-aranguren</td>\n",
       "      <td>{'Java': 3514431, 'JavaScript': 967765, 'HTML'...</td>\n",
       "      <td>Dependencies: Java 8. Apache Ant. Building. in...</td>\n",
       "      <td></td>\n",
       "      <td>Merge pull request #16 from Shamanou/developme...</td>\n",
       "      <td>\\norg eclipse core resources\\norg eclipse jdt ...</td>\n",
       "      <td>*\\n * Main class for Refine server application...</td>\n",
       "      <td>A tool to make data FAIR. Dependencies: Java 8...</td>\n",
       "      <td>A tool to make data FAIR. Dependencies: Java 8...</td>\n",
       "      <td>57859</td>\n",
       "      <td>software, 0.2099\\ninteraction science, 0.2051\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gh_id                   name  \\\n",
       "0  216602979                LIRICAL   \n",
       "1  199330464   wikidata_ontomatcher   \n",
       "2  253207181          ro-crate-ruby   \n",
       "3  212556220  Misc_Training_scripts   \n",
       "4  155879756              FAIRifier   \n",
       "\n",
       "                                         description             owner_name  \\\n",
       "0  LIkelihood Ratio Interpretation of Clinical Ab...               cmungall   \n",
       "1          Matches ontology classes against wikidata               cmungall   \n",
       "2  A Ruby gem for creating, manipulating and read...          markwilkinson   \n",
       "3  A place for me to keep various miscellanelous ...          markwilkinson   \n",
       "4                           A tool to make data FAIR  mikel-egana-aranguren   \n",
       "\n",
       "                                           languages  \\\n",
       "0  {'Java': 492423, 'FreeMarker': 13149, 'Python'...   \n",
       "1  {'Prolog': 14691, 'Makefile': 1472, 'Dockerfil...   \n",
       "2                      {'Ruby': 52724, 'HTML': 1319}   \n",
       "3                     {'Shell': 15815, 'Ruby': 9445}   \n",
       "4  {'Java': 3514431, 'JavaScript': 967765, 'HTML'...   \n",
       "\n",
       "                                         readme_text  \\\n",
       "0  LIRICAL.  LIkelihood Ratio Interpretation of C...   \n",
       "1  Match an ontology to Wikidata. This applicatio...   \n",
       "2  ro-crate-ruby. This is a WIP gem for creating,...   \n",
       "3  Misc_Training_scripts. A place for me to keep ...   \n",
       "4  Dependencies: Java 8. Apache Ant. Building. in...   \n",
       "\n",
       "                                         issues_text  \\\n",
       "0                                                      \n",
       "1  Will help with #1 and with https://github.com/...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                        commits_text  \\\n",
       "0  Merge pull request #442 from TheJacksonLaborat...   \n",
       "1  Adding skos:altLabel\\n\\nhttps://github.com/cmu...   \n",
       "2  Update LICENSE\\nBump version\\nTidy up and chec...   \n",
       "3  added new cool 3-federated query\\nfinished edi...   \n",
       "4  Merge pull request #16 from Shamanou/developme...   \n",
       "\n",
       "                                           filenames  \\\n",
       "0  \\nCHANGELOG\\nREADME\\nhoxc13 output\\nlirical to...   \n",
       "1  \\nREADME\\ninstall\\npack\\nwikidata ontomatcher\\...   \n",
       "2  \\n travis\\nGemfile\\nREADME\\nROCrate\\nContact P...   \n",
       "3  README\\nSpecies Abundance Pub2015\\nSpecies Inf...   \n",
       "4  \\norg eclipse core resources\\norg eclipse jdt ...   \n",
       "\n",
       "                                       comments_text  \\\n",
       "0  note that the Jannovar dependency does not nee...   \n",
       "1                                                      \n",
       "2  *\\n * Expands the tree to the target element a...   \n",
       "3                                                      \n",
       "4  *\\n * Main class for Refine server application...   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  LIkelihood Ratio Interpretation of Clinical Ab...   \n",
       "1  Matches ontology classes against wikidata. Mat...   \n",
       "2  A Ruby gem for creating, manipulating and read...   \n",
       "3  A place for me to keep various miscellanelous ...   \n",
       "4  A tool to make data FAIR. Dependencies: Java 8...   \n",
       "\n",
       "                                   full_text_cleaned  num_chars_text  \\\n",
       "0  LIkelihood Ratio Interpretation of Clinical Ab...            3770   \n",
       "1  Matches ontology classes against wikidata. Mat...             519   \n",
       "2  A Ruby gem for creating, manipulating and read...            2559   \n",
       "3  A place for me to keep various miscellanelous ...             545   \n",
       "4  A tool to make data FAIR. Dependencies: Java 8...           57859   \n",
       "\n",
       "                                     topics_from_ner  \n",
       "0  software, 0.2150\\ncomputer science, 0.2115\\nar...  \n",
       "1  Wikidata, 0.4091\\nonline database, 0.3375\\nkno...  \n",
       "2  information, 0.2005\\nabstract object, 0.1957\\n...  \n",
       "3  species, 0.6111\\ntaxonomic rank, 0.5116\\nsubge...  \n",
       "4  software, 0.2099\\ninteraction science, 0.2051\\...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_COL_NAME = 'topics_from_ner'\n",
    "\n",
    "git_df[NEW_COL_NAME] = ['\\n'.join([f\"{topic.label}, {topic.score:.4f}\" for topic in result])\n",
    "                        for result in results]\n",
    "git_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gh_id</th>\n",
       "      <th>name</th>\n",
       "      <th>topics_from_ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>216602979</td>\n",
       "      <td>LIRICAL</td>\n",
       "      <td>software, 0.2150\\ncomputer science, 0.2115\\nar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199330464</td>\n",
       "      <td>wikidata_ontomatcher</td>\n",
       "      <td>Wikidata, 0.4091\\nonline database, 0.3375\\nkno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253207181</td>\n",
       "      <td>ro-crate-ruby</td>\n",
       "      <td>information, 0.2005\\nabstract object, 0.1957\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212556220</td>\n",
       "      <td>Misc_Training_scripts</td>\n",
       "      <td>species, 0.6111\\ntaxonomic rank, 0.5116\\nsubge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155879756</td>\n",
       "      <td>FAIRifier</td>\n",
       "      <td>software, 0.2099\\ninteraction science, 0.2051\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gh_id                   name  \\\n",
       "0  216602979                LIRICAL   \n",
       "1  199330464   wikidata_ontomatcher   \n",
       "2  253207181          ro-crate-ruby   \n",
       "3  212556220  Misc_Training_scripts   \n",
       "4  155879756              FAIRifier   \n",
       "\n",
       "                                     topics_from_ner  \n",
       "0  software, 0.2150\\ncomputer science, 0.2115\\nar...  \n",
       "1  Wikidata, 0.4091\\nonline database, 0.3375\\nkno...  \n",
       "2  information, 0.2005\\nabstract object, 0.1957\\n...  \n",
       "3  species, 0.6111\\ntaxonomic rank, 0.5116\\nsubge...  \n",
       "4  software, 0.2099\\ninteraction science, 0.2051\\...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = git_df[['gh_id', 'name', NEW_COL_NAME]]\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE_NAME = \"git_df_with_ner_topics.csv\"\n",
    "\n",
    "results_df.to_csv(os.path.join(NOTEBOOK_5_RESULTS_DIR, OUTPUT_FILE_NAME), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
